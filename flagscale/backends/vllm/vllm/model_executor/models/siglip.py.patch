diff --git a/vllm/model_executor/models/siglip.py b/vllm/model_executor/models/siglip.py
index eb49d6d2c..aed832acf 100644
--- a/vllm/model_executor/models/siglip.py
+++ b/vllm/model_executor/models/siglip.py
@@ -207,26 +207,28 @@ class SiglipMLP(nn.Module):
 
         self.config = config
         self.activation_fn = get_act_fn(config.hidden_act)
-        # Special handling for BNB and torchao quantization
-        if quant_config and quant_config.get_name() in [
-                "bitsandbytes", "torchao"
-        ]:
-            quantizable = True
-        else:
-            # For other quantization, we require the hidden size to be a
-            # multiple of 64
-            quantizable = (config.hidden_size % 64 == 0
-                           and config.intermediate_size % 64 == 0)
+        # --- FLAGSCALE MODIFICATION BEG ---
+        #### Special handling for BNB and torchao quantization
+        ###if quant_config and quant_config.get_name() in [
+        ###        "bitsandbytes", "torchao"
+        ###]:
+        ###    quantizable = True
+        ###else:
+        ###    # For other quantization, we require the hidden size to be a
+        ###    # multiple of 64
+        ###    quantizable = (config.hidden_size % 64 == 0
+        ###                   and config.intermediate_size % 64 == 0)
+        # --- FLAGSCALE MODIFICATION END ---
         self.fc1 = ColumnParallelLinear(
             config.hidden_size,
             config.intermediate_size,
-            quant_config=quant_config if quantizable else None,
+            quant_config=quant_config, # --- FLAGSCALE MODIFICATION ---
             prefix=f"{prefix}.fc1",
         )
         self.fc2 = RowParallelLinear(
             config.intermediate_size,
             config.hidden_size,
-            quant_config=quant_config if quantizable else None,
+            quant_config=quant_config, # --- FLAGSCALE MODIFICATION ---
             prefix=f"{prefix}.fc2",
         )
 
