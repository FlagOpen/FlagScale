diff --git a/vllm/model_executor/layers/logits_processor.py b/vllm/model_executor/layers/logits_processor.py
index e93be9bfb..a23bb4dbe 100644
--- a/vllm/model_executor/layers/logits_processor.py
+++ b/vllm/model_executor/layers/logits_processor.py
@@ -145,18 +145,41 @@ def _apply_logits_processors(
     sampling_metadata: SamplingMetadata,
 ) -> torch.Tensor:
     found_logits_processors = False
+    has_negative = False # --- FLAGSCALE MODIFICATION ---
     logits_processed = 0
     logits_row_ids_and_logits_row_futures = []
     for seq_group in sampling_metadata.seq_groups:
         seq_ids = seq_group.seq_ids
         sampling_params = seq_group.sampling_params
         logits_processors = sampling_params.logits_processors
-        if logits_processors:
+        # --- FLAGSCALE MODIFICATION BEG ---
+        logits_processors = logits_processors or []
+        guidance_scale = sampling_params.guidance_scale
+        # --- FLAGSCALE MODIFICATION END ---
+
+        if logits_processors or guidance_scale is not None: # --- FLAGSCALE MODIFICATION ---
             found_logits_processors = True
 
             for seq_id, logits_row_idx in zip(seq_ids,
                                               seq_group.sample_indices):
-                logits_row = logits[logits_row_idx]
+
+                # --- FLAGSCALE MODIFICATION BEG ---
+                if guidance_scale is not None:
+                    has_negative = True
+                    assert 2 * logits_row_idx + 1 < logits.shape[0]
+                    if guidance_scale != 1.0:
+                        conditional_logits_row = logits[2 * logits_row_idx]
+                        unconditional_logitis_row = logits[2 * logits_row_idx + 1]
+                        conditional_logits_row = torch.nn.functional.log_softmax(conditional_logits_row, dim=-1)
+                        unconditional_logitis_row = torch.nn.functional.log_softmax(unconditional_logitis_row, dim=-1)
+                        logits_row = guidance_scale * (conditional_logits_row - unconditional_logitis_row) + unconditional_logitis_row
+                        logits_row_idx *= 2
+                    else:
+                        logits_row = logits[2 * logits_row_idx]
+                        logits_row_idx *= 2
+                # --- FLAGSCALE MODIFICATION END ---
+                else:
+                    logits_row = logits[logits_row_idx]
                 past_tokens_ids = seq_group.seq_data[seq_id].output_token_ids
                 prompt_tokens_ids = seq_group.seq_data[seq_id].prompt_token_ids
 
@@ -181,8 +204,15 @@ def _apply_logits_processors(
 
     if found_logits_processors:
         # verifies that no rows in logits were missed unexpectedly
-        assert logits_processed == logits.shape[0]
-    return logits
+        if has_negative:
+            assert logits_processed == logits.shape[0] // 2 # --- FLAGSCALE MODIFICATION ---
+        else:
+            assert logits_processed == logits.shape[0]
+
+    if has_negative:
+        return logits[::2, :] # --- FLAGSCALE MODIFICATION ---
+    else:
+        return logits
 
 
 def _apply_logits_processors_single_seq(logits_row, logits_processors,
