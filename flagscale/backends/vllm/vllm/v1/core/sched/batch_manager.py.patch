diff --git a/vllm/v1/core/sched/batch_manager.py b/vllm/v1/core/sched/batch_manager.py
new file mode 100644
index 000000000..0616163f5
--- /dev/null
+++ b/vllm/v1/core/sched/batch_manager.py
@@ -0,0 +1,225 @@
+
+
+import enum
+import msgspec
+import numpy as np
+
+from collections import defaultdict
+
+from vllm.config import VllmConfig
+# from vllm.v1.hybrid_request import HybridRequest
+from vllm.v1.request import Request
+
+
+class CFGStatus(enum.IntEnum):
+    SCHEDULED_ALL = enum.auto()
+
+    def __str__(self):
+        return self.name
+
+
+class HybridSchedulerMetadata(
+        msgspec.Struct,
+        tag=True,  # type: ignore[call-arg]
+        array_like=True,  # type: ignore[call-arg]
+        omit_defaults=True):  # type: ignore[call-arg]
+
+    format_token_ids: list[int] = msgspec.field(default_factory=list)
+    in_image: bool = False
+    in_visual: bool = False
+    img_step: int = 0  # for cfg decay
+
+
+class BatchSchedulerManager:
+    def __init__(
+        self,
+        vllm_config: VllmConfig,
+    ) -> None:
+        self.additional_config = vllm_config.additional_config
+
+        self.batch_size = self.additional_config.get("cfg_batch_size", 2)
+        self.boi = self.additional_config.get("boi_token_id", -1)
+        self.soi = self.additional_config.get("soi_token_id", -1)
+        self.eoi = self.additional_config.get("eoi_token_id", -1)
+        self.eol = self.additional_config.get("eol_token_id", -1)
+        self.resolution_map = self.additional_config.get("resolution_map", {})
+
+        # request_id -> ...
+        self.request_metadata: dict[str, HybridSchedulerMetadata] = {}
+        self.soi_token_idx: dict[str, int] = {}
+        self.boi_token_idx: dict[str, int] = {}
+        self.resolution_token_ids: dict[str, list[int]] = defaultdict(list)
+
+    def start_new_batch(self):
+        self.current_batch = []
+        self.is_valid = []
+
+    def remaining_slots(self):
+        return self.batch_size - len(self.current_batch)
+
+    def get_current_batch(self):
+        return self.current_batch
+
+    def add_request(self, request: Request, is_valid: bool):
+        self.current_batch.append(request)
+        self.is_valid.append(is_valid)
+
+    def set_request_metadata(self, request: Request):
+        req_id = request.request_id
+
+        last_token_id = request.all_token_ids[-1]
+
+        req_metadata = self.get_req_metadata(request)
+        assert req_metadata is None, f"Request {req_id} already exists in BatchSchedulerManager"
+
+        req_metadata = HybridSchedulerMetadata()
+        self.request_metadata[req_id] = req_metadata
+
+        req_metadata.format_token_ids = []
+        self.soi_token_idx[req_id] = -1
+        self.boi_token_idx[req_id] = -1
+
+        if last_token_id == self.boi: # 151852
+            req_metadata.in_image = True
+            req_metadata.in_visual = False
+            self.boi_token_idx[req_id] = len(request.output_token_ids)
+
+        if last_token_id == self.soi: # 151851
+            req_metadata.in_image = True
+            req_metadata.in_visual = True
+            self.soi_token_idx[req_id] = len(request.output_token_ids)
+
+        if last_token_id == self.eoi: # 151853
+            req_metadata.in_image = False
+            req_metadata.in_visual = False
+
+        # in visual area of image area
+        if req_metadata.in_visual is True:
+            h, w = self.parse_token_hw(request)
+
+            assert self.soi_token_idx[req_id] >= 0
+            vis_idx = len(request.output_token_ids) - self.soi_token_idx[req_id]
+            if vis_idx != 0:
+                if (vis_idx + 1) == h * (w + 1): # the previous token of eoi
+                    req_metadata.format_token_ids = [self.eoi] # 151853
+                elif (vis_idx + 1) % (w + 1) == 0: # the pervious token of eol
+                    req_metadata.format_token_ids = [self.eol] # 151846
+
+        # in resolution area of image area
+        elif req_metadata.in_image and req_metadata.in_visual is False:
+            # 151852
+            if len(self.resolution_token_ids[req_id]) > 0:
+                assert self.boi_token_idx[req_id] >= 0
+                hw_idx = len(request.output_token_ids) - self.boi_token_idx[req_id]
+                if hw_idx < len(self.resolution_token_ids[req_id]):
+                    req_metadata.format_token_ids = [self.resolution_token_ids[req_id][hw_idx]]
+                else:
+                    req_metadata.format_token_ids = [self.soi] # 151851
+
+        extra_args = request.sampling_params.extra_args
+        if req_metadata.in_image:
+            request.sampling_params.top_k = extra_args.get("visual_top_k", request.sampling_params.top_k)
+            request.sampling_params.top_p = extra_args.get("visual_top_p", request.sampling_params.top_p)
+            request.sampling_params.temperature = extra_args.get("visual_temperature", request.sampling_params.temperature)
+        else:
+            request.sampling_params.top_k = extra_args.get("text_top_k", request.sampling_params.top_k)
+            request.sampling_params.top_p = extra_args.get("text_top_p", request.sampling_params.top_p)
+            request.sampling_params.temperature = extra_args.get("text_temperature", request.sampling_params.temperature)
+
+    def reset_request_metadata(self, request: str):
+
+        req_id = request.request_id
+
+        self.request_metadata.pop(req_id, None)
+        self.soi_token_idx.pop(req_id, None)
+        self.boi_token_idx.pop(req_id, None)
+        self.resolution_token_ids.pop(req_id, None)
+
+    def get_req_metadata(self, request: Request) -> HybridSchedulerMetadata:
+        return self.request_metadata.get(request.request_id, None)
+
+    def update_metadata_with_output(self, request: Request):
+
+        req_id = request.request_id
+        req_metadata = self.get_req_metadata(request)
+        if req_metadata is None:
+            return req_metadata
+
+        last_token_id = request.all_token_ids[-1]
+
+        if last_token_id == self.boi:
+            req_metadata.in_image = True
+            req_metadata.in_visual = False
+            self.boi_token_idx[req_id] = len(request.output_token_ids)
+
+        if last_token_id == self.soi:
+            req_metadata.format_token_ids = []
+            req_metadata.in_image = True
+            req_metadata.in_visual = True
+            self.soi_token_idx[req_id] = len(request.output_token_ids)
+            self.boi_token_idx[req_id] = -1
+
+        if last_token_id == self.eoi:
+            req_metadata.format_token_ids = []
+            req_metadata.in_image = False
+            req_metadata.in_visual = False
+            self.soi_token_idx[req_id] = -1
+
+        extra_args = request.sampling_params.extra_args
+        if req_metadata.in_image:
+            request.sampling_params.top_k = extra_args.get("visual_top_k", request.sampling_params.top_k)
+            request.sampling_params.top_p = extra_args.get("visual_top_p", request.sampling_params.top_p)
+            request.sampling_params.temperature = extra_args.get("visual_temperature", request.sampling_params.temperature)
+        else:
+            request.sampling_params.top_k = extra_args.get("text_top_k", request.sampling_params.top_k)
+            request.sampling_params.top_p = extra_args.get("text_top_p", request.sampling_params.top_p)
+            request.sampling_params.temperature = extra_args.get("text_temperature", request.sampling_params.temperature)
+
+        if req_metadata.in_visual is True:
+            h, w = self.parse_token_hw(request)
+
+            assert self.soi_token_idx[req_id] >= 0
+            vis_idx = len(request.output_token_ids) - self.soi_token_idx[req_id]
+            if vis_idx != 0:
+                if (vis_idx + 1) == h * (w + 1): # the previous token of eoi
+                    req_metadata.format_token_ids = [self.eoi] # 151853
+                    req_metadata.img_step += 1
+                elif (vis_idx + 1) % (w + 1) == 0: # the pervious token of eol
+                    req_metadata.format_token_ids = [self.eol] # 151846
+                else:
+                    req_metadata.format_token_ids = []
+
+        # in resolution area of image area
+        elif req_metadata.in_image and req_metadata.in_visual is False:
+            # 151852
+            if len(self.resolution_token_ids[req_id]) > 0:
+                assert self.boi_token_idx[req_id] >= 0
+                hw_idx = len(request.output_token_ids) - self.boi_token_idx[req_id]
+                if hw_idx < len(self.resolution_token_ids[req_id]):
+                    req_metadata.format_token_ids = [self.resolution_token_ids[req_id][hw_idx]]
+                else:
+                    req_metadata.format_token_ids = [self.soi] # 151851
+
+        # print(f"_update_metadata_with_output: {req_id=}, {req_metadata=}")
+        return req_metadata
+
+    def parse_token_hw(self, request: Request):
+
+        req_id = request.request_id
+
+        if len(self.resolution_token_ids[req_id]) == 0:
+            last_tokens = np.array(request.all_token_ids)
+            boi_idx = np.where(last_tokens == self.boi)[0][-1] # 151852
+            img_idx = np.where(last_tokens == self.soi)[0][-1] # 151851
+            self.resolution_token_ids[req_id] = last_tokens[boi_idx+1:img_idx].tolist()
+            del last_tokens
+
+        resolution_text = ""
+        for token in self.resolution_token_ids[req_id]:
+            assert token in self.resolution_map, f"{self.resolution_token_ids[req_id]} has unknown token {token}"
+            resolution_text += self.resolution_map[token]
+
+        height_str, width_str = resolution_text.split("*")
+        height = int(height_str.strip())
+        width = int(width_str.strip())
+        return height, width
