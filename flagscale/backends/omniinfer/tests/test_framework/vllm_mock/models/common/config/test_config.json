{
    "model_parallel_config":{
        "dense_mlp_tp_size":2,
        "embedding_tp_size":3,
        "self_attention_dp_size":4,
        "self_attention_tp_size":5,
        "mlaprolog_dp_size":6,
        "mlaprolog_tp_size":7,
        "fa_dp_size":8,
        "fa_tp_size":9,
        "mlaepilog_dp_size":10,
        "mlaepilog_tp_size":11,
        "moe_tp_size":12,
        "moe_ep_size":13,
        "lm_dp_size":14,
        "lm_tp_size":15,
        "pp_size":16,
        "redundancy_expert_num":17,
        "dp_size":18
    },
    "profiling_config":{
        "prof_output_path":".",
        "prof_dump_enable":false,
        "perf_cost_enable":false
    },
    "precision_diff":{
        "diff_enable":false,
        "fx_graph_dump":false,
        "ge_graph_dump":false,
        "dump_path":"."
    },
    "operator_optimizition_config":{
        "enable_kv_rmsnorm_rope_cache":false,
        "prefill_dispatch_combine":false,
        "enable_node_mlp":true,
        "moe_multi_stream_tune":true,
        "best_ep":true,
        "enable_pd_separated":true,
        "merge_qkv":true,
        "two_stage_comm":true,
        "use_chunked_prefill": true,
        "use_w8a8_dynamic_quant": false,
        "use_copy_blocks_op": true,
        "fused_experts_v2": true,
        "gmm_nz": true,
        "moe_dispatch_combine": true,
        "use_omni_placement": true,
        "omni_placement_config_path":".",
        "enable_fusion_spec": true,
        "enable_alltoall": true,
        "enable_moe_expert_parallel": false,
        "decode_gear_list": [17]
    }
}
