#
# Copyright (c) 2025 Huawei Technologies Co., Ltd. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# This file is a part of the vllm-ascend project.
#
import argparse
import subprocess
import yaml
import requests
import json
import os
from omni.cli.config_transform import transform_deployment_config

def load_config(config_path):
    """åŠ è½½å¹¶è§£æ YAML é…ç½®æ–‡ä»¶"""
    with open(config_path, 'r') as f:
        return yaml.safe_load(f)


def run_ansible_playbook_with_config(config_path):
    """ä½¿ç”¨é…ç½®æ–‡ä»¶ä½œä¸º inventory æ‰§è¡Œ Ansible Playbook"""
    transform_deployment_config(config_path)
    command = f"ansible-playbook -i omni_infer_inventory.yml omni_infer_server.yml"
    process = subprocess.Popen(
        command,
        shell=True,
        stdout=subprocess.PIPE,
        stderr=subprocess.PIPE
    )
    stdout, stderr = process.communicate()

    if process.returncode != 0:
        print(f"éƒ¨ç½²å¤±è´¥: stdout:{stdout.decode()} stderr:{stderr.decode()}")
    else:
        print(f"éƒ¨ç½²æˆåŠŸ: {stdout.decode()}")


def check_service_health(config):
    """æ‰§è¡ŒæœåŠ¡å¥åº·æ£€æŸ¥"""
    try:
        # è§£æä»£ç†é…ç½®
        proxy_host = config['deployment']['proxy']['host']
        proxy_port = config['deployment']['proxy']['listen_port']
        model_path = config['services']['model_path']

        # æ„é€ è¯·æ±‚ URL
        url = f"http://{proxy_host}:{proxy_port}/v1/completions"

        # æ„é€ è¯·æ±‚å¤´
        headers = {
            "Content-Type": "application/json",
            "Authorization": "Bearer YOUR_API_KEY"  # æ›¿æ¢ä¸ºå®é™… API å¯†é’¥
        }

        # æ„é€ è¯·æ±‚ä½“
        payload = {
            "model": model_path,
            "prompt": "Alice is ",
            "max_tokens": 50,
            "temperature": 0
        }

        # å‘é€è¯·æ±‚
        response = requests.post(url, headers=headers, data=json.dumps(payload))

        # å¤„ç†å“åº”
        if response.status_code == 200:
            print("âœ… æœåŠ¡å¥åº·æ£€æŸ¥é€šè¿‡")
            print(f"å“åº”å†…å®¹: {response.json()}")
            return True
        else:
            print(f"âŒ æœåŠ¡å¼‚å¸¸ (çŠ¶æ€ç : {response.status_code})")
            print(f"é”™è¯¯ä¿¡æ¯: {response.text}")
            return False

    except KeyError as e:
        print(f"âŒ é…ç½®é”™è¯¯: ç¼ºå°‘å¿…è¦çš„é…ç½®é¡¹ {e}")
        return False
    except requests.exceptions.RequestException as e:
        print(f"âŒ ç½‘ç»œé”™è¯¯: {e}")
        return False
    except Exception as e:
        print(f"âŒ æœªçŸ¥é”™è¯¯: {e}")
        return False


def main():
    parser = argparse.ArgumentParser(description="Omni Inference æœåŠ¡ç®¡ç†")
    subparsers = parser.add_subparsers(dest="command", required=True)

    # æ–°å¢ serve å­å‘½ä»¤
    serve_parser = subparsers.add_parser("serve", help="éƒ¨ç½²æ¨ç†æœåŠ¡")
    serve_parser.add_argument("config", help="é…ç½®æ–‡ä»¶è·¯å¾„")

    # æ–°å¢ status å­å‘½ä»¤
    status_parser = subparsers.add_parser("status", help="æœåŠ¡å¥åº·æ£€æŸ¥")
    status_parser.add_argument("--config", default="omni_infer_deployment.yml", help="é…ç½®æ–‡ä»¶è·¯å¾„")

    args = parser.parse_args()

    if args.command == "serve":
        # æ‰§è¡Œ Ansible éƒ¨ç½²
        print(f"ğŸš€ å¼€å§‹éƒ¨ç½²æœåŠ¡ï¼Œä½¿ç”¨é…ç½®æ–‡ä»¶: {args.config}")
        run_ansible_playbook_with_config(args.config)
    elif args.command == "status":
        # æ‰§è¡Œå¥åº·æ£€æŸ¥
        print(f"ğŸ” å¼€å§‹æœåŠ¡å¥åº·æ£€æŸ¥ï¼Œä½¿ç”¨é…ç½®æ–‡ä»¶: {args.config}")
        config = load_config(args.config)
        check_service_health(config)


if __name__ == "__main__":
    main()
