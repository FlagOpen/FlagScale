
load_module /usr/local/openresty/nginx/modules/ngx_http_set_request_id_module.so;
load_module /usr/local/openresty/nginx/modules/ngx_http_prefill_module.so;
load_module /usr/local/openresty/nginx/modules/ngx_http_upstream_length_balance_module.so;
load_module /usr/local/openresty/nginx/modules/ngx_http_upstream_greedy_timeout_module.so;
 
error_log  /path/to/error.log  warn;

user  root;
worker_processes 16;
worker_rlimit_nofile 102400;

# pid        logs/nginx.pid;

events {
    use epoll;
    accept_mutex off;
    multi_accept on;
    worker_connections 102400;
}
 
http {
    # ---- Static Bucket ----
    #   http_content_length â‰¤ 12_000 byte => bucket_1
    #   http_content_length > 12_000 byte => bucket_2
    map $http_content_length $upstream {
        default                                     prefill_bucket1_servers;
        "~^(?:1[2-9][0-9]{3}|[2-9][0-9]{4,})$"      prefill_bucket2_servers;
    }
 
    lua_shared_dict req_cache    10m;
    lua_shared_dict bucket_shared 1m;
    lua_code_cache on;
 
    upstream prefill_bucket1_servers {
        keepalive 32;
        server 127.0.0.1:8090 max_fails=3 fail_timeout=10s;
    }
    upstream prefill_bucket2_servers {
        keepalive 32;
        server 127.0.0.1:8091 max_fails=3 fail_timeout=10s;
    }
    upstream decode_servers {
        #Turn on length_balance
	    #length_balance;
        # length_balance_merge_threshold 16;
        # length_balance_req_len_weight 0.5;
        # length_balance_decay_factor 2;
        #Turn on greedy_timeout by change "off" to "on"
        greedy_timeout           off; # change to "off" if using other modules(like length_balance, round robin).
        # greedy_timeout_warmup    5;
        # greedy_timeout_exp       1.8;
        keepalive 32;
        server 127.0.0.1:8092 max_fails=3 fail_timeout=10s;
        server 127.0.0.1:8093 max_fails=3 fail_timeout=10s;
        server 127.0.0.1:8094 max_fails=3 fail_timeout=10s;
        server 127.0.0.1:8095 max_fails=3 fail_timeout=10s;
        server 127.0.0.1:8096 max_fails=3 fail_timeout=10s;
        server 127.0.0.1:8097 max_fails=3 fail_timeout=10s;
    }

    subrequest_output_buffer_size 1m;
    proxy_read_timeout 600s;
    proxy_send_timeout 600s;
    proxy_connect_timeout 600s;
    open_file_cache max=102400 inactive=40s;
    open_file_cache_valid 50s;
    open_file_cache_min_uses 1;
    open_file_cache_errors on;
    client_max_body_size 100m;
    client_body_buffer_size 128K;
    server_names_hash_bucket_size 128;
    large_client_header_buffers 4 512k;
    client_header_buffer_size 512k;
    keepalive_requests 2000;
    sendfile_max_chunk 512k;
    tcp_nodelay	on;
    tcp_nopush on;
    # include       mime.types;
    default_type  application/octet-stream;

    # log_format main '$remote_addr - $remote_user [$time_local] "$request" '
    #             '$status $body_bytes_sent "$http_referer" '
    #             '"$http_user_agent" "$http_x_forwarded_for" '
    #             '"upstream: $upstream_addr" "content_length : $content_length " '
    #             '$request_time $upstream_response_time';

    #access_log  logs/access.log  main;

    sendfile        on;

    keepalive_timeout  65;
 
    server {
        listen 85;
        server_name localhost;
 
        location ~ ^/v1(/chat)?/completions$  {
            prefill /prefill_internal;
            proxy_pass  http://decode_servers;
            proxy_http_version 1.1;
            proxy_set_header Connection Keep-Alive;        
        }
 
        location /prefill_internal {
            internal;
            rewrite /prefill_internal/(.*) /$1 break;
            proxy_pass http://$upstream;
            proxy_http_version 1.1;
            proxy_set_header Connection Keep-Alive;
        }
    }
}