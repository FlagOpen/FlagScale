load_module /usr/local/openresty/nginx/modules/ngx_http_set_request_id_module.so;
load_module /usr/local/openresty/nginx/modules/ngx_http_prefill_module.so;
load_module /usr/local/openresty/nginx/modules/ngx_http_upstream_length_balance_module.so;
load_module /usr/local/openresty/nginx/modules/ngx_http_upstream_greedy_timeout_module.so;
 
error_log  /path/to/error.log  warn;

user  root;
worker_processes 16;
worker_rlimit_nofile 102400;

# pid        logs/nginx.pid;

events {
    use epoll;
    accept_mutex off;
    multi_accept on;
    worker_connections 102400;
}

http {
    # ----  Dynamic Bucket ----
    lua_shared_dict req_cache    10m;
    lua_shared_dict bucket_shared 1m;
    lua_code_cache on;
    init_by_lua_block {
        local smoothed      = 0
        local alpha         = 0.9
        local bucket_count  = 2
        local queue         = {}
        local bucket_dispatch = {}

        function bucket_dispatch.add_req(id, len)
            table.insert(queue, {id=id, len=len})
            table.sort(queue, function(a,b) return a.len < b.len end)
        end

        function bucket_dispatch.remove_req(id)
            for i,v in ipairs(queue) do
                if v.id == id then
                    table.remove(queue, i)
                    return
                end
            end
        end

        function bucket_dispatch.get_bucket(id)
            local total = 0
            for _,v in ipairs(queue) do total = total + v.len end
            if total == 0 then return "bucket_1" end

            smoothed = alpha * total + (1-alpha)*smoothed
            local thresholds = {}
            for i=1, bucket_count-1 do
                thresholds[i] = smoothed * (i)/(bucket_count)
            end

            local acc = 0
            for _,v in ipairs(queue) do
                acc = acc + v.len
                if v.id == id then
                    for i,thr in ipairs(thresholds) do
                        if acc > thr then
                            return "bucket_"..i
                        end
                    end
                    return "bucket_"..bucket_count
                end
            end

            return "bucket_1"
        end

        package.loaded["bucket_dispatch"] = bucket_dispatch
    }

    upstream prefill_bucket1_servers {
        keepalive 32;
        server 127.0.0.1:8090 max_fails=3 fail_timeout=10s;
    }
    upstream prefill_bucket2_servers {
        keepalive 32;
        server 127.0.0.1:8091 max_fails=3 fail_timeout=10s;
    }

    upstream decode_servers {
        #Turn on length_balance
	    # length_balance;
        # length_balance_merge_threshold 16;
        # length_balance_req_len_weight 0.5;
        # length_balance_decay_factor 2;
        #Turn on greedy_timeout by change "off" to "on"
        greedy_timeout           off; # change to "off" if using other modules(like length_balance, round robin).
        # greedy_timeout_warmup    5;
        # greedy_timeout_exp       1.8;
        keepalive 32;
        server 127.0.0.1:8092 max_fails=3 fail_timeout=10s;
        server 127.0.0.1:8093 max_fails=3 fail_timeout=10s;
        server 127.0.0.1:8094 max_fails=3 fail_timeout=10s;
        server 127.0.0.1:8095 max_fails=3 fail_timeout=10s;
        server 127.0.0.1:8096 max_fails=3 fail_timeout=10s;
        server 127.0.0.1:8097 max_fails=3 fail_timeout=10s;
    }

    subrequest_output_buffer_size 1m;
    proxy_read_timeout 600s;
    proxy_send_timeout 600s;
    proxy_connect_timeout 600s;
    open_file_cache max=102400 inactive=40s;
    open_file_cache_valid 50s;
    open_file_cache_min_uses 1;
    open_file_cache_errors on;
    client_max_body_size 100m;
    client_body_buffer_size 128K;
    server_names_hash_bucket_size 128;
    large_client_header_buffers 4 512k;
    client_header_buffer_size 512k;
    keepalive_requests 2000;
    sendfile_max_chunk 512k;
    tcp_nodelay	on;
    tcp_nopush on;
    # include       mime.types;
    default_type  application/octet-stream;

    # log_format main '$remote_addr - $remote_user [$time_local] "$request" '
    #             '$status $body_bytes_sent "$http_referer" '
    #             '"$http_user_agent" "$http_x_forwarded_for" '
    #             '"upstream: $upstream_addr" "content_length : $content_length " '
    #             '$request_time $upstream_response_time';

    #access_log  logs/access.log  main;

    sendfile        on;

    keepalive_timeout  65;

    server {
        listen 85;
        server_name localhost;

        location ~ ^/v1(/chat)?/completions$ {
            set $prefill_bucket "";
            set $upstream "";
            set $req_id "";
            rewrite_by_lua_block {
                local disp = require("bucket_dispatch")
                local len  = tonumber(ngx.var.http_content_length) or 0
                local id   = tostring(ngx.now()) .. "-" .. ngx.var.remote_addr
                disp.add_req(id, len)

                local bucket = disp.get_bucket(id)
                ngx.var.prefill_bucket = bucket
                ngx.var.req_id         = id

                ngx.log(ngx.ERR, "bucket ", bucket)
                if bucket == "bucket_2" then
                    ngx.var.upstream = "prefill_bucket2_servers"
                else
                    ngx.var.upstream = "prefill_bucket1_servers"
                end
            }

            prefill /prefill_internal;
            proxy_pass               http://decode_servers;
            proxy_http_version 1.1;
            proxy_set_header Connection Keep-Alive;

            log_by_lua_block {
                require("bucket_dispatch").remove_req(ngx.var.req_id)
            }
        }

        location ~ ^/prefill_internal/(?<rest>.*)$ {
            internal;
            rewrite /prefill_internal/(.*) /$1 break;
            proxy_pass http://$upstream;
            proxy_http_version 1.1;
            proxy_set_header Connection Keep-Alive;

        }
    }
}