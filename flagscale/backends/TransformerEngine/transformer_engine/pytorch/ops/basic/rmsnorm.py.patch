diff --git a/transformer_engine/pytorch/ops/basic/rmsnorm.py b/transformer_engine/pytorch/ops/basic/rmsnorm.py
index 8c3f0297..7bc4910e 100644
--- a/transformer_engine/pytorch/ops/basic/rmsnorm.py
+++ b/transformer_engine/pytorch/ops/basic/rmsnorm.py
@@ -26,6 +26,7 @@ from ...utils import (
 from ..op import BasicOperation, OperationContext
 from .._common import maybe_autocast_dtype, maybe_dequantize
 
+from ...module.gems_rms_norm import rms_norm_forward, rms_norm_backward
 
 class RMSNorm(BasicOperation):
     r"""Root Mean Square Layer Normalization
@@ -184,15 +185,23 @@ class RMSNorm(BasicOperation):
 
         # Compute RMSNorm
         sm_margin = self._sm_margins["forward" if ctx.requires_grad else "inference"]
-        y, _, rstdevs = rmsnorm_fwd(
+
+        # TODO(lixianduo): polish
+        # y, _, rstdevs = rmsnorm_fwd(
+        #     x,
+        #     w,
+        #     self.eps,
+        #     None,
+        #     next_op_input_quantizer,
+        #     TE_DType[dtype],
+        #     sm_margin,
+        #     self.zero_centered_gamma,
+        # )
+        y, rstdevs = rms_norm_forward(
             x,
+            [x.shape[-1]],
             w,
             self.eps,
-            None,
-            next_op_input_quantizer,
-            TE_DType[dtype],
-            sm_margin,
-            self.zero_centered_gamma,
         )
 
         # Save state for backward pass
@@ -224,14 +233,24 @@ class RMSNorm(BasicOperation):
         dy = maybe_dequantize(grad_output.contiguous(), dtype).view(x.size())
         w = maybe_dequantize(self.weight, dtype).view((inner_dim,))
 
+        # TODO(lixianduo): polish
         # Compute RMSNorm backward pass
-        dx, dw = rmsnorm_bwd(
+        # dx, dw = rmsnorm_bwd(
+        #     dy,
+        #     x,
+        #     rstdevs,
+        #     w,
+        #     self._sm_margins["backward"],
+        #     self.zero_centered_gamma,
+        # )
+
+        dx, dw = rms_norm_backward(
             dy,
             x,
             rstdevs,
+            [x.shape[-1]],
             w,
-            self._sm_margins["backward"],
-            self.zero_centered_gamma,
+            self.eps,
         )
 
         # Clear saved tensors if possible
@@ -250,3 +269,4 @@ class RMSNorm(BasicOperation):
         """Every operand in this function has a defined ONNX translation."""
         weight = self.weight + 1 if self.zero_centered_gamma else self.weight
         return torch.nn.functional.rms_norm(input_, input_.shape[-1:], weight, self.eps)
+
