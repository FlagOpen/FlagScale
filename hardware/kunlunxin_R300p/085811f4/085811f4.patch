From 386d12cbd04e6f55944abcb8879470eba2d36ef2 Mon Sep 17 00:00:00 2001
From: zhangsanfeng2022 <ludehui2022@163.com>
Date: Thu, 17 Oct 2024 14:51:56 +0800
Subject: [PATCH] [kunlunxin] llava 1.5 7b patch for checkpoint save.

---
 examples/llava/conf/config.yaml               | 26 ++++++++++++++++++-
 .../llava/conf/train/train_llava1.5_7b.yaml   |  6 +++--
 2 files changed, 29 insertions(+), 3 deletions(-)

diff --git a/examples/llava/conf/config.yaml b/examples/llava/conf/config.yaml
index e7b327ee..b73a8e5d 100644
--- a/examples/llava/conf/config.yaml
+++ b/examples/llava/conf/config.yaml
@@ -19,9 +19,33 @@ experiment:
     CUDA_DEVICE_MAX_CONNECTIONS: 1
     NVTE_APPLY_QK_LAYER_SCALING: 0
     NVTE_ALLOW_NONDETERMINISTIC_ALGO: 0
+    ALLGATHER_ASYNC: false
+    ALLREDUCE_ASYNC: false
+    ALLREDUCE_FUSION: 0
+    BKCL_CCIX_BUFFER_GM: 1
+    BKCL_CCIX_RING: 1
+    BKCL_ENABLE_XDR: 1
+    BKCL_FLAT_RING: 1
+    BKCL_KL3_TURBO_MODE: 1
+    BKCL_RDMA_FORCE_TREE: 1
+    BKCL_RDMA_NICS: ens11np0,ens11np0,ens13np0,ens13np0,ens15np0,ens15np0,ens17np0,ens17np0
+    BKCL_RDMA_PROXY_DISABLE: 1
+    BKCL_RING_BUFFER_GM: 1
+    BKCL_TIMEOUT: 360000
+    BKCL_TRANS_UNSUPPORTED_DATATYPE: 1
+    BKCL_TREE_THRESHOLD: 1
+    BKCL_XLINK_C2C: 1
+    BKCL_XLINK_D2D: 0
+    BKCL_XLINK_ETH: 0
+    CUDART_DUMMY_REGISTER: 1
+    FAST_SWIGLU_ENABLE: 1
+    USE_FAST_BF16_FC: true
+    USE_L3: 1
+    XDNN_USE_FAST_SWISH: true
+    XPU_ZEBU_MODE: 1

 action: run 

 hydra: 
   run:
-    dir: ${experiment.exp_dir}/hydra 
+    dir: ${experiment.exp_dir}/hydra
diff --git a/examples/llava/conf/train/train_llava1.5_7b.yaml b/examples/llava/conf/train/train_llava1.5_7b.yaml
index 040b73ca..6b400246 100644
--- a/examples/llava/conf/train/train_llava1.5_7b.yaml
+++ b/examples/llava/conf/train/train_llava1.5_7b.yaml
@@ -7,7 +7,9 @@ system:
   use_mcore_models: True
   transformer_impl: transformer_engine
   precision:
-    bf16: True
+    fp16: True
+    initial_loss_scale: 512
+    min_loss_scale: 1.0
     attention_softmax_in_fp32: True
   logging:
     log_interval: 1
@@ -19,7 +21,7 @@ system:
   checkpoint:
     save_interval: 1000
     pretrained_checkpoint: ${pretrained_checkpoint_path:??}
-    dataloader_save: ${experiment.exp_dir}/checkpoints/dataloader
+    dataloader_save: /share/project/PUBLIC/checkpoints/dataloader
     use_dist_ckpt: False
     ckpt_format: torch
     async_save: False
-- 
2.47.0