diff --git a/examples/deepseek_v3/conf/train.yaml b/examples/deepseek_v3/conf/train.yaml
index 86fa1e1d..bd6d5587 100644
--- a/examples/deepseek_v3/conf/train.yaml
+++ b/examples/deepseek_v3/conf/train.yaml
@@ -8,23 +8,37 @@ experiment:
   seed: 42
   save_steps: 10000
   load: None
-  exp_dir: /xxx
+  exp_dir: ./output_openseek
   ckpt_format: torch
   task:
     type: train
     backend: megatron
     entrypoint: flagscale/train/train_gpt.py
   runner:
-    per_node_task: false
+    # per_node_task: false
     no_shared_fs: false
     rdzv_backend: static
-    hostfile: null
-  cmds:
-    before_start: "ulimit -n 1048576 && source /root/miniconda3/bin/activate flagscale"
+    hostfile: ./hostfile
+    ssh_port: 62216
+  # cmds:
+  #   before_start: "ulimit -n 1048576 && source /root/miniconda3/bin/activate flagscale"
   envs:
     LOGLEVEL: "INFO"
-    CUDA_VISIBLE_DEVICES: "0,1,2,3,4,5,6,7"
+    MUSA_VISIBLE_DEVICES: "0,1,2,3,4,5,6,7"
     CUDA_DEVICE_MAX_CONNECTIONS: 1
+    MUSA_KERNEL_TIMEOUT: 3200000
+    ACCELERATOR_BACKEND: musa
+    MCCL_PROTOS: 2
+    MCCL_CHECK_POINTERS: 0
+    OMP_NUM_THREADS: 4
+    MCCL_ALGOS: 1
+    MCCL_BUFFSIZE: 41943040
+    MUSA_BLOCK_SCHEDULE_MODE: 1
+    MCCL_IB_GID_INDEX: 3
+    MCCL_NET_SHARED_BUFFERS: 0
+    GLOO_SOCKET_IFNAME: ens19f0np0
+    # ENABLE_ZERO_BUBBLE: 1
+    # PROFILER_FREQ: 4
 
 action: run
 
diff --git a/examples/deepseek_v3/conf/train/16b_a3b.yaml b/examples/deepseek_v3/conf/train/16b_a3b.yaml
index fe469de9..69d4ea18 100644
--- a/examples/deepseek_v3/conf/train/16b_a3b.yaml
+++ b/examples/deepseek_v3/conf/train/16b_a3b.yaml
@@ -1,10 +1,10 @@
 system:
   no_shared_fs: ${experiment.runner.no_shared_fs}
-  num_workers: 16
-  tensor_model_parallel_size: 2
+  num_workers: 8
+  tensor_model_parallel_size: 1
   pipeline_model_parallel_size: 2
-  decoder_first_pipeline_num_layers: 13
-  expert_model_parallel_size: 2
+  decoder_first_pipeline_num_layers: 14
+  expert_model_parallel_size: 8
   context_parallel_size: 1
   disable_bias_linear: true
   reset_position_ids: True
@@ -12,9 +12,9 @@ system:
   qk_layernorm: true
   sequence_parallel: true
   use_distributed_optimizer: true
-  overlap_grad_reduce: true
-  overlap_param_gather: true
-  finetune: false
+  overlap_grad_reduce: false
+  overlap_param_gather: false
+  finetune: true
   precision:
     bf16: true
     attention_softmax_in_fp32: true
@@ -22,8 +22,8 @@ system:
   logging:
     log_interval: 1
     tensorboard_log_interval: 1
-    wandb_project: ${experiment.exp_name}
-    wandb_exp_name: ${experiment.exp_name}
+    # wandb_project: ${experiment.exp_name}
+    # wandb_exp_name: ${experiment.exp_name}
     log_timers_to_tensorboard: true
     log_validation_ppl_to_tensorboard: true
     log_throughput: true
@@ -31,9 +31,10 @@ system:
     log_num_zeros_in_grad: true
     log_memory_to_tensorboard: true
   checkpoint:
-    save_interval: ${experiment.save_steps}
-    load: ${experiment.load}
-    ckpt_format: ${experiment.ckpt_format}
+    save_interval: 1000
+    load: /home/dist/project/haoran/tp1_pp2_ep2
+    ckpt_format: torch
+    # no_load_optim: true
 
 model:
   transformer_impl: transformer_engine
@@ -55,7 +56,9 @@ model:
   position_embedding_type: rope
   untie_embeddings_and_output_weights: true
   no_position_embedding: true
-  no_rope_fusion: true
+  no_rope_fusion: false
+  # fp8_format: hybrid
+  # fp8_param_gather: true
 
   # mla args ==================
   multi_latent_attention: true
@@ -82,19 +85,19 @@ model:
   moe_router_topk: 6
   moe_router_topk_scaling_factor: 2.446
   moe_token_dispatcher_type: "alltoall"
-  # moe_permute_fusion: true
+  moe_permute_fusion: true
 
   # mtp args ====================
-  mtp_num_layers: 1
-  mtp_loss_scaling_factor: 0.3
+  # mtp_num_layers: 1
+  # mtp_loss_scaling_factor: 0.3
 
   # training
   seed: ${experiment.seed}
   # finetune: false
   micro_batch_size: 1
-  global_batch_size: 2048
+  global_batch_size: 256
   eval_iters: 0
-  train_samples: 244141056 #1T #29297664 #120B tokens
+  train_samples: 768000 #1T #29297664 #120B tokens
 
   optimizer:
     weight_decay: 0.1
@@ -103,18 +106,20 @@ model:
     lr_scheduler:
       lr: 3.0e-3
       min_lr: 3.0e-4
-      lr_warmup_samples: 2048000
+      lr_warmup_samples: 76800
       lr_decay_style: WSD
       lr_wsd_decay_style: cosine
-      lr_wsd_decay_samples: 2048
+      lr_wsd_decay_samples: 768
 
 
 data:
-  data_path: /path
+  data_path: /home/dist/projset_public/perf_logs/XLC_2025_openseek/dataset/cosmopedia-v2-full_text_document
+  data_cache_path: /home/dist/project/mt_base/haoran/FlagScale/data
   split: 1
-  no_mmap_bin_files: true
   tokenizer:
-    tokenizer_type: QwenTokenizerFS
-    tokenizer_path: examples/aquila/qwentokenizer
+    tokenizer_type: HuggingFaceTokenizer
+    tokenizer_model: /home/dist/projset_public/perf_logs/XLC_2025_openseek/hf_ckpt
+    # tiktoken_pattern: v1
+    # tiktoken_special_tokens: None
     vocab_size: 151851
-    make_vocab_size_divisible_by: 64
+    make_vocab_size_divisible_by: 64
\ No newline at end of file
diff --git a/examples/llama3/combine_log.py b/examples/llama3/combine_log.py
new file mode 100644
index 00000000..7b6b73eb
--- /dev/null
+++ b/examples/llama3/combine_log.py
@@ -0,0 +1,131 @@
+import os
+import re
+from datetime import datetime
+import glob
+
+def find_latest_timestamp_directories(target_dir, pattern=None):
+    """
+    找出最晚和第二晚的时间戳目录
+    
+    参数:
+    target_dir - 要搜索的目录路径
+    pattern - 可选的时间戳正则表达式模式
+    
+    返回:
+    (latest_dir, second_latest_dir) 元组
+    """
+    # 验证目录存在
+    if not os.path.isdir(target_dir):
+        raise ValueError(f"目录不存在: {target_dir}")
+    
+    # 获取所有子目录
+    dirs = [d for d in os.listdir(target_dir) 
+            if os.path.isdir(os.path.join(target_dir, d))]
+    
+    # 如果没有目录，返回空
+    if not dirs:
+        return None, None
+    
+    # 尝试解析时间戳
+    timestamp_dirs = []
+    
+    for d in dirs:
+        try:
+            # 尝试作为数字时间戳解析
+            ts = float(d)
+            timestamp_dirs.append((d, ts))
+        except ValueError:
+            # 尝试作为日期字符串解析
+            try:
+                if pattern:
+                    # 使用自定义正则解析
+                    match = re.match(pattern, d)
+                    if not match:
+                        continue
+                    
+                    # 尝试解析匹配的组
+                    dt = datetime.strptime(match.group(), pattern)
+                else:
+                    # 尝试常见格式
+                    formats = [
+                        "%Y-%m-%d_%H-%M-%S",  # 2023-01-15_14-30-45
+                        "%Y%m%d%H%M%S",       # 20230115143045
+                        "%Y-%m-%d %H:%M:%S",  # 2023-01-15 14:30:45
+                        "%Y%m%d",             # 20230115
+                        "%Y-%m-%d"            # 2023-01-15
+                    ]
+                    
+                    for fmt in formats:
+                        try:
+                            dt = datetime.strptime(d, fmt)
+                            break
+                        except ValueError:
+                            continue
+                    else:
+                        continue  # 所有格式都失败
+                
+                timestamp_dirs.append((d, dt.timestamp()))
+            except Exception:
+                continue  # 无法解析的时间戳格式
+    
+    # 按时间戳排序
+    sorted_dirs = sorted(timestamp_dirs, key=lambda x: x[1], reverse=True)
+    
+    # 获取结果
+    latest = sorted_dirs[0][0] if sorted_dirs else None
+    second_latest = sorted_dirs[1][0] if len(sorted_dirs) > 1 else None
+    
+    return latest, second_latest
+
+def combine_log(bf16_log_path,fp8_log_path):
+    
+    p = bf16_log_path
+    t = open(p,'r').readlines()
+    t1 = t[:-2]
+    
+    p = fp8_log_path
+    t = open(p,'r').readlines()
+    
+    i = 0
+    for i,s in enumerate(t):
+        if s.strip().startswith('[2025'):
+            break
+    
+    t2 = t[i:]
+    t = t1 + t2
+    t = "".join(t)
+    
+    print(t)
+    
+    bak_path = fp8_log_path + '.bak'
+    os.system(f'cp {fp8_log_path} {bak_path}')
+    
+    with open(fp8_log_path,'w') as f:
+        f.write(t)
+        f.close()
+    
+if __name__ == "__main__":
+    
+    hostfile_path = 'hostfile'
+    target_ip = open(hostfile_path,'r').readlines()[-1].split(' ')[0].strip()
+    
+    target_directory = "outputs_llama3_70b/logs/details/host_3_{}".format(target_ip)  # 替换为你的目录路径
+    
+    # 可选：如果你的时间戳有特定格式，可以使用正则模式
+    # timestamp_pattern = r"\d{8}_\d{6}"  # 示例：YYYYMMDD_HHMMSS
+    
+    latest_dir, second_latest_dir = find_latest_timestamp_directories(
+        target_directory
+        # pattern=timestamp_pattern  # 如果需要自定义格式
+    )
+    
+    bf16_log_dir = os.path.join(target_directory,second_latest_dir)
+    fp8_log_dir = os.path.join(target_directory,latest_dir)
+    
+    fp8_log_path = list(glob.glob(f"{fp8_log_dir}/*/*/7/stdout.log"))[0]
+    bf16_log_path = list(glob.glob(f"{bf16_log_dir}/*/*/7/stdout.log"))[0]
+    
+    print(fp8_log_path,bf16_log_path)
+    
+    
+    combine_log(bf16_log_path,fp8_log_path)
\ No newline at end of file
diff --git a/examples/llama3/conf/train.yaml b/examples/llama3/conf/train.yaml
index 8b3acdfd..b9c14852 100644
--- a/examples/llama3/conf/train.yaml
+++ b/examples/llama3/conf/train.yaml
@@ -1,24 +1,43 @@
 defaults:
-  - train: 70b
+  - train: 70b_finetune
   - _self_
 
 experiment:
   exp_name: llama3
-  exp_dir: ./outputs_llama3_70b
+  exp_dir: ./outputs_llama3_70b_2
   task:
     type: train
     backend: megatron
     entrypoint: ./flagscale/train/train_gpt.py
   runner:
-    backend: torchrun
-    nnodes: 4
-    nproc_per_node: 8
-    hostfile: ${hostfile??}
+    per_node_task: false
+    no_shared_fs: false
+    rdzv_backend: static
+    hostfile: ./hostfile
+    ssh_port: 62216
+    # backend: torchrun
+    # nnodes: 4
+    # nproc_per_node: 8
+    # hostfile: ./hostfile
+    # ssh_port: 62216
+  # cmds:
+  #   before_start: "ulimit -n 1048576 && source /root/miniconda3/bin/activate flagscale"
   envs:
-    CUDA_VISIBLE_DEVICES: 0,1,2,3,4,5,6,7
+    LOGLEVEL: "INFO"
+    MUSA_VISIBLE_DEVICES: "0,1,2,3,4,5,6,7"
     CUDA_DEVICE_MAX_CONNECTIONS: 1
-    NVTE_APPLY_QK_LAYER_SCALING: 0
-    NVTE_ALLOW_NONDETERMINISTIC_ALGO: 0
+    MUSA_KERNEL_TIMEOUT: 3200000
+    ACCELERATOR_BACKEND: musa
+    MCCL_PROTOS: 1
+    MCCL_CHECK_POINTERS: 0
+    OMP_NUM_THREADS: 4
+    MCCL_ALGOS: 1
+    MCCL_BUFFSIZE: 20971520
+    MUSA_BLOCK_SCHEDULE_MODE: 1
+    MCCL_IB_GID_INDEX: 3
+    MCCL_NET_SHARED_BUFFERS: 0
+    MUSA_USERQ: 1
+  
 action: run
 
 hydra:
diff --git a/examples/llama3/conf/train/70b.yaml b/examples/llama3/conf/train/70b.yaml
index 8e4a06be..ad20e27d 100644
--- a/examples/llama3/conf/train/70b.yaml
+++ b/examples/llama3/conf/train/70b.yaml
@@ -1,28 +1,31 @@
 system:
   tensor_model_parallel_size: 8
-  pipeline_model_parallel_size: 4
-  make_vocab_size_divisible_by: 64
+  pipeline_model_parallel_size: 2
   disable_bias_linear: True
   sequence_parallel: True
   use_flash_attn: True
   use_distributed_optimizer: True
-  use_mcore_models: True
-  transformer_impl: transformer_engine
+
+  #fp8-param-gather: True
   precision:
     bf16: True
-    attention_softmax_in_fp32: True
-    accumulate_allreduce_grads_in_fp32: True
+    attention_softmax_in_fp32: true
+    accumulate_allreduce_grads_in_fp32: true
   logging:
     log_interval: 1
     tensorboard_log_interval: 1
-    wandb_project: "train-llama3-70B"
-    wandb_exp_name: "train-llama3-70B"
+    # wandb_project: "train-llama3-70B"
+    # wandb_exp_name: "train-llama3-70B"
   checkpoint:
-    ckpt_format: torch
-    save_interval: 100
+    save_interval: 10000
+    # ckpt_format: torch
+    # save_interval: 100
 
 model:
-  num_layers: 80
+  use_mcore_models: True
+  transformer_impl: transformer_engine
+  fp8-format: hybrid
+  num_layers: 40
   hidden_size: 8192
   num_attention_heads: 64
   group_query_attention: True
@@ -31,13 +34,14 @@ model:
   seq_length: 8192
   max_position_embeddings: 8192
   norm_epsilon: 1e-5
-  norm_init_weight: 0.02
+  #norm_init_weight: 0.02
   use_rotary_position_embeddings: True
   rotary_base: 500000
-  no_position_embedding: True
-  reset_position_ids: True
+  #no_position_embedding: True
+  #reset_position_ids: True
   add_qkv_bias: false
-  reset_attention_mask: True
+  #reset_attention_mask: True
+  position_embedding_type: rope
   swiglu: True
   normalization: RMSNorm
   untie_embeddings_and_output_weights: True
@@ -45,10 +49,9 @@ model:
   attention_dropout: 0.0
   hidden_dropout: 0.0
   clip_grad: 1.0
-
   train_samples: 6160066
   micro_batch_size: 1
-  global_batch_size: 1024
+  global_batch_size: 32
   seed: 42
 
   optimizer:
@@ -64,9 +67,11 @@ model:
       lr_decay_style: cosine
 
 data:
-  data_path: ${data_path:??}
+  data_path: /home/dist/haoran/perf_logs/XLC_2025_llama3/dataset/dedup-md5-pile-pile-cc_text_document
+  data_cache_path: /home/dist/haoran/FlagScale/llama3_data2
   split: 1
   tokenizer:
-    tokenizer_type: Llama3TokenizerFS
-    tokenizer_path: ${tokenizer_path:??}
+    tokenizer_type: HuggingFaceTokenizer
+    tokenizer_model: /home/dist/haoran/perf_logs/XLC_2025_llama3/tokenizer/
     vocab_size: 128256
+    make_vocab_size_divisible_by: 64
diff --git a/examples/llama3/conf/train/70b_finetune.yaml b/examples/llama3/conf/train/70b_finetune.yaml
index aca7f56b..fe2c0d91 100644
--- a/examples/llama3/conf/train/70b_finetune.yaml
+++ b/examples/llama3/conf/train/70b_finetune.yaml
@@ -1,6 +1,6 @@
 system:
-  tensor_model_parallel_size: 8
-  pipeline_model_parallel_size: 4
+  tensor_model_parallel_size: 4
+  pipeline_model_parallel_size: 8
   make_vocab_size_divisible_by: 64
   disable_bias_linear: True
   sequence_parallel: True
@@ -8,20 +8,28 @@ system:
   use_distributed_optimizer: True
   use_mcore_models: True
   transformer_impl: transformer_engine
+  fp8-format: hybrid
+  fp8-param-gather: True
+  use-precision-aware-optimizer: True
+  main-grads-dtype: bf16
+  main-params-dtype: fp16
+  exp-avg-sq-dtype: fp16
+  exp-avg-dtype: fp16
   precision:
     bf16: True
     attention_softmax_in_fp32: True
-    accumulate_allreduce_grads_in_fp32: True
+    # accumulate_allreduce_grads_in_fp32: True
   logging:
     log_interval: 1
     tensorboard_log_interval: 1
-    wandb_project: "train-llama3-70B"
-    wandb_exp_name: "train-llama3-70B"
+    log-throughput: True
+    # wandb_project: "train-llama3-70B"
+    # wandb_exp_name: "train-llama3-70B"
   checkpoint:
-    load: ${ckpt_path:??}
+    load: outputs_llama3_70b_2/checkpoints
     ckpt_format: torch
-    save_interval: 100
-    finetune: True
+    save_interval: 250
+    finetune: false
 
 model:
   num_layers: 80
@@ -33,7 +41,7 @@ model:
   seq_length: 8192
   max_position_embeddings: 8192
   norm_epsilon: 1e-5
-  norm_init_weight: 0.02
+  # norm_init_weight: 0.02
   use_rotary_position_embeddings: True
   rotary_base: 500000
   no_position_embedding: True
@@ -48,9 +56,9 @@ model:
   hidden_dropout: 0.0
   clip_grad: 1.0
 
-  train_samples: 6160066
+  train_samples: 256000
   micro_batch_size: 1
-  global_batch_size: 1024
+  global_batch_size: 512
   seed: 42
 
   optimizer:
@@ -62,13 +70,14 @@ model:
     lr_scheduler:
       lr: 5e-6
       min_lr: 0
-      lr_warmup_samples: 2048000
+      lr_warmup_samples: 25600
       lr_decay_style: cosine
 
 data:
-  data_path: ${data_path:??}
+  data_path: /home/dist/projset_public/perf_logs/XLC_2025_llama3/dataset/dedup-md5-pile-pile-cc_text_document
+  data_cache_path: /home/dist/project/mt_base/haoran/FlagScale/llama_data
   split: 1
   tokenizer:
-    tokenizer_type: Llama3TokenizerFS
-    tokenizer_path: ${tokenizer_path:??}
+    tokenizer_type: HuggingFaceTokenizer
+    tokenizer_model: /home/dist/projset_public/perf_logs/XLC_2025_llama3/tokenizer/
     vocab_size: 128256
diff --git a/examples/llama3/conf/train/70b_finetune_bf16.yaml b/examples/llama3/conf/train/70b_finetune_bf16.yaml
new file mode 100644
index 00000000..ccfa2523
--- /dev/null
+++ b/examples/llama3/conf/train/70b_finetune_bf16.yaml
@@ -0,0 +1,95 @@
+system:
+  tensor_model_parallel_size: 4
+  pipeline_model_parallel_size: 8
+  make_vocab_size_divisible_by: 64
+  disable_bias_linear: True
+  sequence_parallel: True
+  use_flash_attn: True
+  use_distributed_optimizer: True
+  use_mcore_models: True
+  transformer_impl: transformer_engine
+  #fp8-format: hybrid
+  #fp8-param-gather: True
+  use-precision-aware-optimizer: True
+  main-grads-dtype: bf16
+  #main-params-dtype: fp16
+  exp-avg-sq-dtype: fp16
+  exp-avg-dtype: fp16
+  #decoder-first-pipeline-num-layers: 7
+  #decoder-last-pipeline-num-layers: 7
+
+  # tp-comm-overlap: True
+  # disable-tp-comm-overlap-ag: True
+  # disable-tp-comm-overlap-rs: True
+
+  recompute-granularity: full 
+  recompute-method: block 
+  recompute-num-layers: 2 
+  precision:
+    bf16: True
+    attention_softmax_in_fp32: True
+    #accumulate_allreduce_grads_in_fp32: True
+  logging:
+    log_interval: 1
+    tensorboard_log_interval: 1
+    log-throughput: True
+    #wandb_project: "train-llama3-70B"
+    #wandb_exp_name: "train-llama3-70B"
+  checkpoint:
+    load: /home/dist/project/mt_base/haoran/70b_tp4pp8_ckpt_2
+    ckpt_format: torch
+    no_load_optim: true
+    save_interval: 30
+    exit_interval: 30
+    finetune: True
+
+model:
+  num_layers: 80
+  hidden_size: 8192
+  num_attention_heads: 64
+  group_query_attention: True
+  num_query_groups: 8
+  ffn_hidden_size: 28672
+  seq_length: 8192
+  max_position_embeddings: 8192
+  norm_epsilon: 1e-5
+  #norm_init_weight: 0.02
+  use_rotary_position_embeddings: True
+  rotary_base: 500000
+  no_position_embedding: True
+  reset_position_ids: True
+  add_qkv_bias: false
+  reset_attention_mask: True
+  swiglu: True
+  normalization: RMSNorm
+  untie_embeddings_and_output_weights: True
+  init_method_std: 0.02
+  attention_dropout: 0.0
+  hidden_dropout: 0.0
+  clip_grad: 1.0
+
+  train_samples: 256000
+  micro_batch_size: 1
+  global_batch_size: 512
+  seed: 42
+
+  optimizer:
+    start_weight_decay: 0
+    end_weight_decay: 5e-7
+    weight_decay_incr_style: cosine
+    adam_beta1: 0.9
+    adam_beta2: 0.95
+    lr_scheduler:
+      lr: 5e-6
+      min_lr: 0
+      lr_warmup_samples: 25600
+      lr_decay_style: cosine
+
+data:
+  data_path: /home/dist/projset_public/perf_logs/XLC_2025_llama3/dataset/dedup-md5-pile-pile-cc_text_document
+  data_cache_path: /home/dist/project/mt_base/haoran/FlagScale/llama_data
+  split: 1
+  tokenizer:
+    tokenizer_type: HuggingFaceTokenizer
+    tokenizer_model: /home/dist/projset_public/perf_logs/XLC_2025_llama3/tokenizer/
+    vocab_size: 128256
diff --git a/examples/llama3/conf/train/8b.yaml b/examples/llama3/conf/train/8b.yaml
index 41e3c1d8..2fe322a8 100644
--- a/examples/llama3/conf/train/8b.yaml
+++ b/examples/llama3/conf/train/8b.yaml
@@ -1,6 +1,6 @@
 system:
-  tensor_model_parallel_size: 4
-  pipeline_model_parallel_size: 2
+  tensor_model_parallel_size: 2
+  pipeline_model_parallel_size: 1
   disable_bias_linear: True
   use_flash_attn: True
   sequence_parallel: True
@@ -12,16 +12,18 @@ system:
   logging:
     log_interval: 1
     tensorboard_log_interval: 1
-    wandb_project: "train-llama3-8B"
-    wandb_exp_name: "train-test-8B"
+    # wandb_project: "train-llama3-8B"
+    # wandb_exp_name: "train-test-8B"
   checkpoint:
-    load: outputs_llama3/checkpoint_mc
-    save_interval: 10
-    finetune: True
+    # load: outputs_llama3/checkpoint_mc
+    save_interval: 10000
+    # finetune: True
 
 model:
   use_mcore_models: True
   transformer_impl: transformer_engine
+  fp8-format: hybrid
+  fp8-param-gather: True
   num_layers: 32
   hidden_size: 4096
   ffn_hidden_size: 14336
@@ -47,7 +49,7 @@ model:
   eval_iters: 100
   eval_interval: 1000
   micro_batch_size: 1
-  global_batch_size: 2048
+  global_batch_size: 128
 
   optimizer:
     weight_decay: 1e-2
@@ -60,10 +62,11 @@ model:
       lr_decay_style: cosine
 
 data:
-  data_path: examples/llama/pile-openwebtext_text_document/pile-openwebtext_text_document
+  data_path: /home/dist/haoran/perf_logs/XLC_2025_llama3/dataset/dedup-md5-pile-pile-cc_text_document
+  data_cache_path: /home/dist/haoran/FlagScale/llama3_data
   split: 1
   tokenizer:
-    tokenizer_type: Llama3TokenizerFS
-    tokenizer_path: meta-llama3/Meta-Llama-3-8B
+    tokenizer_type: HuggingFaceTokenizer
+    tokenizer_model: /home/dist/haoran/perf_logs/XLC_2025_llama3/tokenizer/
     vocab_size: 128256
     make_vocab_size_divisible_by: 64
diff --git a/examples/llama3/run_llama3_script.sh b/examples/llama3/run_llama3_script.sh
new file mode 100644
index 00000000..f270f18e
--- /dev/null
+++ b/examples/llama3/run_llama3_script.sh
@@ -0,0 +1,45 @@
+#!/bin/bash
+sed -i '/^[[:space:]]*-[[:space:]]*train:/s/70b_finetune/70b_finetune_bf16/' examples/llama3/conf/train.yaml
+
+python run.py --config-path ./examples/llama3/conf --config-name train action=run
+
+sleep 2m
+
+TRAIN_PROCESS_PATTERN="/usr/bin/python -u ./flagscale/train/train_gpt.py"
+wait_for_completion() {
+    local timeout=17280000  # 48小时超时（秒）
+    local start_time=$(date +%s)
+    
+    while true; do
+        # 检查所有匹配的python进程
+        count=$(pgrep -f "$TRAIN_PROCESS_PATTERN" | wc -l)
+        echo "$count"
+        if [ "$count" -eq 0 ]; then
+            echo "训练进程已结束"
+            break
+        fi
+        
+        # 检查超时
+        local current_time=$(date +%s)
+        if (( current_time - start_time > timeout )); then
+            echo "错误：训练任务超时！"
+            exit 1
+        fi
+        
+        # 显示进度信息
+        echo "[$(date '+%Y-%m-%d %H:%M:%S')] 训练进行中..."
+        sleep 60
+    done
+}
+
+wait_for_completion
+
+sed -i 's/\(train: *\)70b_finetune_bf16/\170b_finetune/' examples/llama3/conf/train.yaml
+
+python run.py --config-path ./examples/llama3/conf --config-name train action=run
+
+sleep 2m
+
+wait_for_completion
+
+python  ./examples/llama3/combine_log.py
\ No newline at end of file
diff --git a/examples/qwen2_5_vl/conf/train.yaml b/examples/qwen2_5_vl/conf/train.yaml
index 7159e1b1..f94f657c 100644
--- a/examples/qwen2_5_vl/conf/train.yaml
+++ b/examples/qwen2_5_vl/conf/train.yaml
@@ -4,28 +4,47 @@ defaults:
 
 experiment:
   exp_name: train_qwen2_5_vl_7b
-  exp_dir: ./${experiment.exp_name}
+  seed: 42
+  save_steps: 10000
+  load: None
+  exp_dir: ./outputs_qwen2.5
+  ckpt_format: torch
   task:
     type: train
     backend: megatron
     entrypoint: ./flagscale/train/train_qwen2_5_vl.py
   runner:
-    backend: torchrun
-    nnodes: 1
-    nproc_per_node: 8
+    # backend: torchrun
+    # nnodes: 1
+    # nproc_per_node: 8
+    per_node_task: false
+    no_shared_fs: false
     rdzv_backend: static
-  cmds:  
-    before_start: ulimit -n 1048576 && source /root/miniconda3/bin/activate flagscale-train
+    hostfile: ./hostfile
+    ssh_port: 62216
   envs:
-    # NCCL_DEBUG: INFO
-    # NCCL_DEBUG_SUBSYSTEM: ALL
-    CUDA_VISIBLE_DEVICES: 0,1,2,3,4,5,6,7
+    LOGLEVEL: INFO
+    MUSA_VISIBLE_DEVICES: 0,1,2,3,4,5,6,7
     CUDA_DEVICE_MAX_CONNECTIONS: 1
-    NVTE_APPLY_QK_LAYER_SCALING: 0
-    NVTE_ALLOW_NONDETERMINISTIC_ALGO: 0
+    MUSA_KERNEL_TIMEOUT: 3200000
+    ACCELERATOR_BACKEND: musa
+    MCCL_PROTOS: 2
+    MCCL_CHECK_POINTERS: 0
+    OMP_NUM_THREADS: 4
+    MCCL_ALGOS: 1
+    MCCL_BUFFSIZE: 20971520
+    MUSA_BLOCK_SCHEDULE_MODE: 1
+    MCCL_IB_GID_INDEX: 3
+    MCCL_NET_SHARED_BUFFERS: 0
+    MUSA_USERQ : 1
+    GLOO_SOCKET_IFNAME: ens19f0np0
+    #CUDA_VISIBLE_DEVICES: 0,1,2,3,4,5,6,7
+    #CUDA_DEVICE_MAX_CONNECTIONS: 1
+    #NVTE_APPLY_QK_LAYER_SCALING: 0
+    #NVTE_ALLOW_NONDETERMINISTIC_ALGO: 0
 
 action: run
 
 hydra:
   run:
-    dir: ${experiment.exp_dir}/hydra
+    dir: /home/dist/edison/FlagScale/outputs_qwen2.5/hydra
diff --git a/examples/qwen2_5_vl/conf/train/7b.yaml b/examples/qwen2_5_vl/conf/train/7b.yaml
index 62b2e072..504406c5 100644
--- a/examples/qwen2_5_vl/conf/train/7b.yaml
+++ b/examples/qwen2_5_vl/conf/train/7b.yaml
@@ -1,22 +1,20 @@
 system:
-  num_workers: 1
-  calculate_per_token_loss: true
-  tensor_model_parallel_size: 2
-  pipeline_model_parallel_size: 1
+  tensor_model_parallel_size: 1
+  pipeline_model_parallel_size: 2
   context_parallel_size: 1
-  # decoder_first_pipeline_num_layers: 12
+  # decoder_first_pipeline_num_layers: 10
   disable_bias_linear: True
   use_flash_attn: True
   use_distributed_optimizer: True
   sequence_parallel: True
   tp_comm_overlap: False
-  overlap_grad_reduce: False # if has text-only must be false
-  overlap_param_gather: False # if has text-only must be false
+  overlap_grad_reduce: False
+  overlap_param_gather: False
   use_mcore_models: True
   transformer_impl: transformer_engine
-  recompute_method: "uniform"
-  recompute_granularity: "full"
-  recompute_num_layers: 1
+  # recompute_method: "uniform"
+  # recompute_granularity: "full"
+  # recompute_num_layers: 1
   use_te: True
   precision:
     bf16: True
@@ -25,20 +23,19 @@ system:
     log_interval: 1
     tensorboard_log_interval: 1
     log_throughput: True
-    wandb_project: ${experiment.exp_name}
-    wandb_exp_name: ${experiment.exp_name}
+      #wandb_project: ${experiment.exp_name}
+      #wandb_exp_name: ${experiment.exp_name}
     log_params_norm: True
     log_num_zeros_in_grad: True
   checkpoint:
     save_interval: 1000
-    pretrained_checkpoint: xxxx
-    dataloader_save: ${experiment.exp_dir}/checkpoints/dataloader
+    pretrained_checkpoint: /home/dist/project/MT/flagscale_ckpt_tp1pp2
+    dataloader_save: /home/dist/project/mt_base/edison/FlagScale/outputs_qwen2.5/checkpoints/dataloader
     use_dist_ckpt: False
     ckpt_format: torch
     async_save: False
 
 model:
-  attention_backend: flash # don't use "auto(nvte_flash_attn)"
   disable_bias_linear: True
   add_qkv_bias: True
   num_layers: 28
@@ -46,22 +43,20 @@ model:
   ffn_hidden_size: 18944
   num_attention_heads: 28
   num_query_groups: 4
-  seq_length: 2048
-  max_padding_length: 2048 # (cutoff_len)max 32768, change according the dataset
-  # especial for qwen2.5-vl
-  enable_variable_seq_lengths: True
+  seq_length: 4096 # origin LLM 32768
+  max_padding_length: 4096 # real seq_length
   max_position_embeddings: 128000 # only useful for additional position embedding
   swiglu: True
   normalization: RMSNorm
   norm_epsilon: 1e-6
-  init_method_std: 0.02
+  init_method_std: 0.014
   attention_dropout: 0.0
   hidden_dropout: 0.0
   clip_grad: 1.0
-  train_iters: 62
-  eval_iters: 0 # no valid
+  train_iters: 5000
+  eval_iters: 0
   micro_batch_size: 1
-  global_batch_size: 16
+  global_batch_size: 256
   allow_missing_vision_projection_checkpoint: False
   apply_layernorm_1p: False
   group_query_attention: True
@@ -69,7 +64,7 @@ model:
   untie_embeddings_and_output_weights: True
 
   # position embedding
-  position_embedding_type: mrope
+  position_embedding_type: rope
   rotary_percent: 1.0
   rotary_base: 1000000
   rotary_seq_len_interpolation_factor: 1
@@ -77,6 +72,7 @@ model:
   mrope_section: [16, 24, 24]
   eod_mask_loss: False
 
+  fp8-format: hybrid
   # vision model
   freeze_LM: False
   freeze_ViT: False
@@ -84,24 +80,23 @@ model:
   seed: 42
 
   optimizer:
-    weight_decay: 0.1
+    weight_decay: 0.0
     adam_beta1: 0.9
-    adam_beta2: 0.999
+    adam_beta2: 0.95
     lr_scheduler:
       lr: 1.0e-5
       min_lr: 1.0e-6
-      # lr_warmup_fraction: .03
-      lr_warmup_iters: 10
+      lr_warmup_fraction: .03
       lr_decay_style: cosine
 
 data:
-  data_path: xxxx
-  vision_root: xxxx
+  data_path: /home/dist/projset_public/perf_logs/XLC_2025_qwen2.5_vl/dataset
   dataloader_type: external
   split: 100,0,0
   tokenizer:
     tokenizer_type: Qwen2VLTokenizer
-    tokenizer_path: xxxx
+      #tokenizer_model: /home/dist/edison/FlagScale/examples/qwen2_5_vl/conf/train/Qwen2.5-VL-7B-Instruct
+    tokenizer_model:  /home/dist/project/MT/flagscale_ckpt_tp1pp2
     vocab_size: 152064 # 7b
     extra_vocab_size: 421
     make_vocab_size_divisible_by: 64
diff --git a/flagscale/runner/runner_train.py b/flagscale/runner/runner_train.py
index aa8f2f7b..c0761f6f 100644
--- a/flagscale/runner/runner_train.py
+++ b/flagscale/runner/runner_train.py
@@ -280,7 +280,7 @@ def run_node(
     dryrun,
 ):
     cur_envs = add_decive_extra_config(user_envs, resource_info["type"])
-    visible_devices = cur_envs.get("CUDA_VISIBLE_DEVICES", None)
+    visible_devices = cur_envs.get("MUSA_VISIBLE_DEVICES", None)
     if visible_devices is not None and isinstance(visible_devices, str):
         visible_devices = visible_devices.split(",")
         num_visible_devices = len(visible_devices)
diff --git a/flagscale/train/extra_valid.py b/flagscale/train/extra_valid.py
index a9f199a1..2bb389aa 100644
--- a/flagscale/train/extra_valid.py
+++ b/flagscale/train/extra_valid.py
@@ -79,9 +79,9 @@ def build_extra_valid_datasets(build_extra_valid_dataset_provider):
     """Build extra_valid datasets."""
 
     args = get_args()
-
+    return [None]
     if args.extra_valid_data_path is None:
-        return [None]
+       return [None]
 
     assert (
         len(args.extra_valid_data_path) % 2 == 0
diff --git a/flagscale/train/models/qwen2_5_vl/language_module.py b/flagscale/train/models/qwen2_5_vl/language_module.py
index 81768fdd..88bd3af8 100644
--- a/flagscale/train/models/qwen2_5_vl/language_module.py
+++ b/flagscale/train/models/qwen2_5_vl/language_module.py
@@ -164,8 +164,8 @@ class QwenVLLanguageModel(GPTModel):
                          rope_scaling=rope_scaling,
                          rope_scaling_factor=rope_scaling_factor,
                          scatter_embedding_sequence_parallel=scatter_embedding_sequence_parallel,
-                         seq_len_interpolation_factor=seq_len_interpolation_factor,
-                         mtp_block_spec=mtp_block_spec)
+                         seq_len_interpolation_factor=seq_len_interpolation_factor)
+                         #mtp_block_spec=mtp_block_spec)
         if self.pre_process:
             self.embedding = QwenVLLanguageModelEmbedding(
                 config=self.config,
diff --git a/flagscale/train/models/qwen2_5_vl/qwen2_5_vl_model.py b/flagscale/train/models/qwen2_5_vl/qwen2_5_vl_model.py
index 5f0ce50e..93154cdf 100644
--- a/flagscale/train/models/qwen2_5_vl/qwen2_5_vl_model.py
+++ b/flagscale/train/models/qwen2_5_vl/qwen2_5_vl_model.py
@@ -199,7 +199,6 @@ class Qwen2_5VLModel(MegatronModule):
         Returns:
             output (torch.Tensor): Loss of shape [b, s] if labels are provided, otherwise logits of shape [b, s, vocab_size].
         """
-
         use_inference_kv_cache = (
             inference_params is not None
             and "image_tokens_count" in inference_params.key_value_memory_dict
@@ -210,11 +209,6 @@ class Qwen2_5VLModel(MegatronModule):
         if self.pre_process:
             vision_embeds = None
             if vision_grid_thw.shape[0] > 0:
-                # NOTE(lizhiyu): Reference https://github.com/huggingface/transformers/blob/40a493c7ed4f19f08eadb0639cf26d49bfa5e180/src/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py#L1612
-                if self.config.bf16:
-                    vision_data = vision_data.to(torch.bfloat16)
-                elif self.config.fp16:
-                    vision_data = vision_data.to(torch.float16)
                 vision_embeds = self.vision_model(
                     vision_data=vision_data, # If None, vision model should use intermediate outputs (EPP > 1)
                     grid_thw=vision_grid_thw # should provided in each EPP stage
@@ -268,6 +262,7 @@ class Qwen2_5VLModel(MegatronModule):
                 )  # [text_seq_len, b, h_language]
         else:
             combined_embeddings = None
+
         output = self.language_model(
             input_ids=None,
             position_ids=position_ids,              # None in encoder
diff --git a/flagscale/train/models/qwen2_5_vl/transformer_config.py b/flagscale/train/models/qwen2_5_vl/transformer_config.py
index c138dbef..3dc620f2 100644
--- a/flagscale/train/models/qwen2_5_vl/transformer_config.py
+++ b/flagscale/train/models/qwen2_5_vl/transformer_config.py
@@ -24,9 +24,9 @@ def get_vision_model_config(args, config):
     # mlp: hidden_size -> intermediate_size -> embed_dim, silu
     # NOTE: here we provide a workaround to solve the wrong layer amount when VPP of decoder is on
     if config.num_layers in[28, 36]:
-        config.ffn_hidden_size = 3420 # 7B 72B
+        config.ffn_hidden_size = 3420 # 7B num_layers: 28
     else:
-        config.ffn_hidden_size = 3456 # 32B
+        config.ffn_hidden_size = 3456
 
     if parallel_state.get_virtual_pipeline_model_parallel_world_size() is not None:
         config.num_layers = 32 * parallel_state.get_virtual_pipeline_model_parallel_world_size() # depth
@@ -67,10 +67,6 @@ def get_vision_model_config(args, config):
     config.first_pipeline_num_layers = None
     config.num_layers_in_first_pipeline_stage = None
     config.num_layers_in_last_pipeline_stage = None
-    if args.vision_recompute_layer_steps != 0:
-        config.recompute_method="uniform"
-        config.recompute_granularity="full"
-        config.recompute_num_layers=args.vision_recompute_layer_steps # 16 for 32B
     return config
 
 
diff --git a/flagscale/train/models/qwen2_5_vl/vision_attention.py b/flagscale/train/models/qwen2_5_vl/vision_attention.py
index f92a97b0..122c2aca 100644
--- a/flagscale/train/models/qwen2_5_vl/vision_attention.py
+++ b/flagscale/train/models/qwen2_5_vl/vision_attention.py
@@ -12,7 +12,7 @@ logger = logging.getLogger(__name__)
 import torch
 from torch import Tensor
 
-from megatron.core.inference.contexts import BaseInferenceContext
+from megatron.core.inference.contexts.base_context import BaseInferenceContext
 from megatron.core.packed_seq_params import PackedSeqParams
 from megatron.core.parallel_state import (
     get_data_parallel_group,
@@ -96,7 +96,7 @@ def _apply_rotary_pos_emb_bshd_vision(
     """
     rot_dim = freqs.shape[-1]
     input_dtype = t.dtype
-    t = t.float()
+    t = t.to(freqs.dtype)
     # ideally t_pass is empty so rotary pos embedding is applied to all tensor t
     t, t_pass = t[..., :rot_dim], t[..., rot_dim:]
 
@@ -107,8 +107,8 @@ def _apply_rotary_pos_emb_bshd_vision(
 
     # first part is cosine component
     # second part is sine component, need to change signs with _rotate_half method
-    cos_ = torch.cos(freqs).float()
-    sin_ = torch.sin(freqs).float()
+    cos_ = (torch.cos(freqs) * mscale)
+    sin_ = (torch.sin(freqs) * mscale)
     t = (t * cos_) + (_rotate_half(t, rotary_interleaved) * sin_)
     return torch.cat((t, t_pass), dim=-1).to(input_dtype)
 
@@ -128,16 +128,19 @@ def apply_rotary_pos_emb_vision(
     freqs of each token have been computed.
     """
 
+    #config.apply_rope_fusion = False
     if config.apply_rope_fusion:
-        return fused_apply_rotary_pos_emb(t.unsqueeze(1), freqs).squeeze(1)
+        return fused_apply_rotary_pos_emb(t, freqs)
+        #return fused_apply_rotary_pos_emb(t.unsqueeze(1), freqs).squeeze(1)
 
     return _apply_rotary_pos_emb_bshd_vision(
-        t.unsqueeze(1),
+        #t.unsqueeze(1),
+        t,
         freqs,
         rotary_interleaved=config.rotary_interleaved,
         multi_latent_attention=config.multi_latent_attention,
         mscale=mscale,
-    ).squeeze(1)
+    )#.squeeze(1)
 
 
 def apply_rotary_pos_emb_with_cos_sin_vision(
@@ -191,7 +194,7 @@ class VisionAttention(Attention):
         cp_comm_type: str = None,
         model_comm_pgs: ModelCommProcessGroups = None,
     ):
-        super().__init__(config=config, submodules=submodules, layer_number=layer_number, attn_mask_type=attn_mask_type, attention_type=attention_type, cp_comm_type=cp_comm_type, model_comm_pgs=model_comm_pgs)
+        super().__init__(config=config, submodules=submodules, layer_number=layer_number, attn_mask_type=attn_mask_type, attention_type=attention_type, cp_comm_type=cp_comm_type)#, model_comm_pgs=model_comm_pgs)
 
 
     def _adjust_key_value_for_inference(
@@ -496,6 +499,7 @@ class VisionAttention(Attention):
             )
         )
 
+        packed_seq_params = None
         if packed_seq_params is not None:
             query = query.squeeze(1)
             key = key.squeeze(1)
@@ -526,8 +530,8 @@ class VisionAttention(Attention):
                         query,
                         q_pos_emb,
                         config=self.config,
-                        cu_seqlens=cu_seqlens_q,
-                        cp_group=self.model_comm_pgs.cp,
+                        cu_seqlens=cu_seqlens_q
+                        #cp_group=self.model_comm_pgs.cp,
                     )
                 else:
                     query = inference_context.apply_rotary_emb_query(
@@ -539,7 +543,7 @@ class VisionAttention(Attention):
                     k_pos_emb,
                     config=self.config,
                     cu_seqlens=cu_seqlens_kv,
-                    cp_group=self.model_comm_pgs.cp,
+                    #cp_group=self.model_comm_pgs.cp,
                 )
 
             # TODO, can apply positional embedding to value_layer so it has
diff --git a/flagscale/train/models/qwen2_5_vl/vision_transformer_block.py b/flagscale/train/models/qwen2_5_vl/vision_transformer_block.py
index e573e708..808eedda 100644
--- a/flagscale/train/models/qwen2_5_vl/vision_transformer_block.py
+++ b/flagscale/train/models/qwen2_5_vl/vision_transformer_block.py
@@ -57,8 +57,8 @@ class VisionTransformerBlock(TransformerBlock):
         model_comm_pgs: ModelCommProcessGroups = None,
     ):
         super().__init__(config=config, spec=spec, post_layer_norm=post_layer_norm,
-                         pre_process=pre_process, post_process=post_process,
-                         model_comm_pgs=model_comm_pgs)
+                         pre_process=pre_process, post_process=post_process)
+                         #model_comm_pgs=model_comm_pgs)
 
     def _checkpointed_forward(
         self,
@@ -249,8 +249,8 @@ class VisionTransformerBlock(TransformerBlock):
         # if we are using other fp8 recipes, then the context manager enter&exit are free
         # we can wrap fp8_context within the for loop over layers, so that we can fine-grained
         # control which layer will be fp8 or bf16
-        use_outer_fp8_context = self.config.fp8 and self.config.fp8_recipe == Fp8Recipe.delayed
-        use_inner_fp8_context = self.config.fp8 and self.config.fp8_recipe != Fp8Recipe.delayed
+        use_outer_fp8_context = self.config.fp8 and True #self.config.fp8_recipe == Fp8Recipe.delayed
+        use_inner_fp8_context = self.config.fp8 and False #self.config.fp8_recipe != Fp8Recipe.delayed
         outer_fp8_context = get_fp8_context(self.config) if use_outer_fp8_context else nullcontext()
 
         with rng_context, outer_fp8_context:
@@ -288,7 +288,7 @@ class VisionTransformerBlock(TransformerBlock):
                             rotary_pos_cos=rotary_pos_cos,
                             rotary_pos_sin=rotary_pos_sin,
                             attention_bias=attention_bias,
-                            inference_context=inference_context,
+                            #inference_context=inference_context,
                             packed_seq_params=packed_seq_params_now,
                             sequence_len_offset=sequence_len_offset,
                         )
diff --git a/flagscale/train/models/qwen2_5_vl/vit_model.py b/flagscale/train/models/qwen2_5_vl/vit_model.py
index 2a21fe14..5de99a6a 100644
--- a/flagscale/train/models/qwen2_5_vl/vit_model.py
+++ b/flagscale/train/models/qwen2_5_vl/vit_model.py
@@ -62,15 +62,14 @@ class VisionRotaryEmbedding(nn.Module):
     """
     def __init__(self, dim: int, theta: float = 10000.0) -> None:
         super().__init__()
-        # NOTE(lizhiyu): print inv_freq to check it.
-        inv_freq = 1.0 / (theta ** (torch.arange(0, dim, 2, dtype=torch.bfloat16) / dim))
+        inv_freq = 1.0 / (theta ** (torch.arange(0, dim, 2, dtype=torch.float) / dim))
         self.register_buffer("inv_freq", inv_freq, persistent=False)
 
     def forward(self, seqlen: int) -> torch.Tensor:
         seq = torch.arange(seqlen, device=self.inv_freq.device, dtype=self.inv_freq.dtype)
         # freqs [seq_len, dim // 2]
         freqs = torch.outer(seq, self.inv_freq)
-        return freqs
+        return freqs.float()
 
 # reference from https://github.com/huggingface/transformers/blob/0ad3710d4767d4ac7ee95f33f8554373e59efade/src/transformers/models/qwen2_5_vl/modular_qwen2_5_vl.py#L243
 class Qwen2_5VisionModel(VisionModule):
diff --git a/flagscale/train/train.py b/flagscale/train/train.py
index bddcb2a5..9c931f85 100644
--- a/flagscale/train/train.py
+++ b/flagscale/train/train.py
@@ -11,7 +11,7 @@ import math
 import os
 import sys
 from typing import List
-
+# sys.path.append("/home/dist/haoran/FlagScale/Megatron-LM")
 import torch.distributed
 from megatron.training.log_handler import CustomHandler
 
@@ -40,12 +40,12 @@ from megatron.core.utils import (
     StragglerDetector,
     is_te_min_version,
 )
-from megatron.core.fp8_utils import correct_amax_history_if_needed
+# from megatron.core.fp8_utils import correct_amax_history_if_needed
 from megatron.training.checkpointing import load_checkpoint
 from megatron.training.checkpointing import save_checkpoint
 from megatron.training.checkpointing import checkpoint_exists
 from megatron.core.transformer.module import Float16Module
-from megatron.core.distributed import DistributedDataParallelConfig, TorchFullyShardedDataParallelConfig
+from megatron.core.distributed import DistributedDataParallelConfig #, TorchFullyShardedDataParallelConfig
 from megatron.core.distributed import DistributedDataParallel as DDP
 from megatron.core.distributed.custom_fsdp import FullyShardedDataParallel as custom_FSDP
 
@@ -73,7 +73,7 @@ from megatron.legacy.data.data_samplers import build_pretraining_data_loader
 from megatron.core.optimizer_param_scheduler import OptimizerParamScheduler
 from megatron.core.transformer.moe import upcycling_utils
 from megatron.core.transformer.moe.moe_utils import track_moe_metrics
-from megatron.core.transformer.multi_token_prediction import MTPLossLoggingHelper
+# from megatron.core.transformer.multi_token_prediction import MTPLossLoggingHelper
 from megatron.core.parallel_state import (
     destroy_global_memory_buffer,
     destroy_model_parallel,
@@ -81,11 +81,11 @@ from megatron.core.parallel_state import (
     model_parallel_is_initialized,
 )
 from megatron.core.pipeline_parallel import get_forward_backward_func
-from megatron.core.pipeline_parallel.schedules import (
-    convert_schedule_table_to_order,
-    get_pp_rank_microbatches,
-    get_schedule_table,
-)
+# from megatron.core.pipeline_parallel.schedules import (
+#     # convert_schedule_table_to_order,
+#     # get_pp_rank_microbatches,
+#     get_schedule_table,
+# )
 from megatron.core.num_microbatches_calculator import (
     destroy_num_microbatches_calculator,
     get_current_global_batch_size,
@@ -127,7 +127,11 @@ from flagscale.train.stablelm2_scheduler import StableLM2SchedulerConfig
 from flagscale.train.global_vars import get_parallel_context, get_spiky_loss_detector
 from flagscale.train.hetero.p2p_communication import get_device_type_for_comm
 from flagscale.train.theoretical_memory_usage import report_theoretical_memory as fs_report_theoretical_memory
-
+sys.path.append("/home/dist/haoran/FlagScale/megatron-lm-musa-patch")
+from musa_patch.profiling import (
+    maybe_enable_profiling,
+    maybe_enable_memory_snapshot
+)
 stimer = StragglerDetector()
 
 
@@ -401,6 +405,7 @@ def num_floating_point_operations(args, batch_size):
         return total_floating_point_operations
 
     # Main entrypoint for FLOPs calculation.
+    args.is_hybrid_model = False
     if args.is_hybrid_model:
         # Calculate the number of each type of layer.
         num_attn_layers, num_mamba_layers, num_mlp_layers = calculate_layer_counts()
@@ -1056,18 +1061,18 @@ def pretrain(
 
         print_datetime('after training is done')
 
-        if not args.auto_tune:
-            if args.save and iteration != 0 and iteration % args.save_interval != 0:
-                save_checkpoint(
-                    iteration,
-                    model,
-                    optimizer,
-                    opt_param_scheduler,
-                    num_floating_point_operations_so_far,
-                    checkpointing_context,
-                    train_data_iterator=train_data_iterator,
-                    preprocess_common_state_dict_fn=preprocess_common_state_dict,
-                )
+        #if not args.auto_tune:
+        # if args.save and iteration != 0 and iteration % args.save_interval != 0:
+        #     save_checkpoint(
+        #         iteration,
+        #         model,
+        #         optimizer,
+        #         opt_param_scheduler,
+        #         num_floating_point_operations_so_far,
+        #         checkpointing_context,
+        #         train_data_iterator=train_data_iterator,
+        #         preprocess_common_state_dict_fn=preprocess_common_state_dict,
+        #     )
 
         one_logger and one_logger.log_metrics(
             {'app_train_loop_finish_time': one_logger_utils.get_timestamp_in_ms()}
@@ -1291,7 +1296,7 @@ def get_model(model_provider_func, model_type=ModelType.encoder_or_decoder, wrap
     #               from the current fp8 param) to its amax_history. The below function will correct
     #               the amax_history back.
     # After TE2.x: Below function is an empty function and does nothing.
-    correct_amax_history_if_needed(model)
+    # correct_amax_history_if_needed(model)
 
     if wrap_with_ddp:
         if args.use_torch_fsdp2:
@@ -1426,7 +1431,7 @@ def get_optimizer_param_scheduler(optimizer):
         override_opt_param_scheduler=args.override_opt_param_scheduler,
         wsd_decay_steps=wsd_decay_steps,
         lr_wsd_decay_style=args.lr_wsd_decay_style,
-        stablelm2_scheduler_config=stablelm2_scheduler_config,
+        # stablelm2_scheduler_config=stablelm2_scheduler_config,
     )
 
     return opt_param_scheduler
@@ -1583,18 +1588,18 @@ def train_step(forward_step_func, data_iterator, model, optimizer, opt_param_sch
     timers = get_timers()
 
     # CUDA Graph capturing only executes once, when it's the first training iteration.
-    if args.curr_iteration == args.iteration and args.external_cuda_graph:
-        cuda_graph_capture(model, config, args)
-
-        # Set grad to zero.
-        for model_chunk in model:
-            model_chunk.zero_grad_buffer()
-        optimizer.zero_grad()
+    # if args.curr_iteration == args.iteration and args.external_cuda_graph:
+    #     cuda_graph_capture(model, config, args)
 
-        # Collect garbage and empty unused memory.
-        gc.collect()
-        torch.cuda.empty_cache()
+    #     # Set grad to zero.
+    #     for model_chunk in model:
+    #         model_chunk.zero_grad_buffer()
+    #     optimizer.zero_grad()
 
+    #     # Collect garbage and empty unused memory.
+    #     gc.collect()
+    #     torch.cuda.empty_cache()
+    iteration = args.iteration
     rerun_state_machine = get_rerun_state_machine()
     while rerun_state_machine.should_run_forward_backward(data_iterator):
         # Set grad to zero.
@@ -1602,13 +1607,13 @@ def train_step(forward_step_func, data_iterator, model, optimizer, opt_param_sch
             model_chunk.zero_grad_buffer()
         optimizer.zero_grad()
 
-        if has_nvidia_modelopt:
-            # [ModelOpt]: Pipeline-parallel Distillation stacks student and teacher tensors
-            adjust_tensor_shapes_fn = get_tensor_shapes_adjust_fn_for_distillation(
-                model, args.seq_length, args.micro_batch_size, args.decoder_seq_length
-            )
-        else:
-            adjust_tensor_shapes_fn = None
+        # if has_nvidia_modelopt:
+        #     # [ModelOpt]: Pipeline-parallel Distillation stacks student and teacher tensors
+        #     adjust_tensor_shapes_fn = get_tensor_shapes_adjust_fn_for_distillation(
+        #         model, args.seq_length, args.micro_batch_size, args.decoder_seq_length
+        #     )
+        # else:
+        #     adjust_tensor_shapes_fn = None
 
         # Forward pass.
         forward_backward_func = get_forward_backward_func()
@@ -1621,22 +1626,22 @@ def train_step(forward_step_func, data_iterator, model, optimizer, opt_param_sch
             micro_batch_size=args.micro_batch_size,
             decoder_seq_length=args.decoder_seq_length,
             forward_only=False,
-            adjust_tensor_shapes_fn=adjust_tensor_shapes_fn,
+            # adjust_tensor_shapes_fn=adjust_tensor_shapes_fn,
         )
     should_checkpoint, should_exit, exit_code = rerun_state_machine.should_checkpoint_and_exit()
     if should_exit:
         return {}, True, should_checkpoint, should_exit, exit_code, None, None
 
     ########## FlagScale Begin ##########
-    if args.auto_skip_spiky_loss and (args.consumed_train_samples > args.lr_warmup_samples and args.curr_iteration > args.lr_warmup_iters):
-        spiky_loss_detector = get_spiky_loss_detector()
-        loss_ = spiky_loss_detector.reduce_losses(losses_reduced)
-        is_spiky_loss = spiky_loss_detector.is_spkiy_loss(loss_)
-        is_spiky_loss_tensor = torch.tensor(is_spiky_loss, dtype=torch.int, device="cuda")
-        torch.distributed.all_reduce(is_spiky_loss_tensor, op=torch.distributed.ReduceOp.MAX)
-        is_spiky_loss = is_spiky_loss_tensor.item()
-        if is_spiky_loss > 0:
-            return {}, True, should_checkpoint, should_exit, exit_code, None, None
+    # if args.auto_skip_spiky_loss and (args.consumed_train_samples > args.lr_warmup_samples and args.curr_iteration > args.lr_warmup_iters):
+    #     spiky_loss_detector = get_spiky_loss_detector()
+    #     loss_ = spiky_loss_detector.reduce_losses(losses_reduced)
+    #     is_spiky_loss = spiky_loss_detector.is_spkiy_loss(loss_)
+    #     is_spiky_loss_tensor = torch.tensor(is_spiky_loss, dtype=torch.int, device="cuda")
+    #     torch.distributed.all_reduce(is_spiky_loss_tensor, op=torch.distributed.ReduceOp.MAX)
+    #     is_spiky_loss = is_spiky_loss_tensor.item()
+    #     if is_spiky_loss > 0:
+    #         return {}, True, should_checkpoint, should_exit, exit_code, None, None
     ########## FlagScale End ##########
 
     # Empty unused memory.
@@ -1681,9 +1686,9 @@ def train_step(forward_step_func, data_iterator, model, optimizer, opt_param_sch
         torch.cuda.empty_cache()
 
     # Set the manual hooks when CUDA Graphs are enabled.
-    if args.curr_iteration == args.iteration and args.external_cuda_graph:
-        if args.use_distributed_optimizer and args.overlap_param_gather:
-            cuda_graph_set_manual_hooks(model)
+    # if args.curr_iteration == args.iteration and args.external_cuda_graph:
+    #     if args.use_distributed_optimizer and args.overlap_param_gather:
+    #         cuda_graph_set_manual_hooks(model)
 
     if mpu.is_pipeline_last_stage(ignore_virtual=True):
         # Average loss across microbatches.
@@ -1865,29 +1870,29 @@ def training_log(
                 writer.add_scalar('params-norm vs samples', params_norm, args.consumed_train_samples)
             if wandb_writer:
                 wandb_writer.log({'params-norm': params_norm}, iteration)
-        if args.log_memory_to_tensorboard:
-            mem_stats = torch.cuda.memory_stats()
-            if writer:
-                writer.add_scalar(
-                    "mem-reserved-bytes", mem_stats["reserved_bytes.all.current"], iteration
-                )
-                writer.add_scalar(
-                    "mem-allocated-bytes", mem_stats["allocated_bytes.all.current"], iteration
-                )
-                writer.add_scalar(
-                    "mem-max-allocated-bytes", mem_stats["allocated_bytes.all.peak"], iteration
-                )
-                writer.add_scalar("mem-allocated-count", mem_stats["allocation.all.current"], iteration)
-            if wandb_writer:
-                wandb_writer.log(
-                    {"mem-reserved-bytes": mem_stats["reserved_bytes.all.current"]}, iteration
-                )
-                wandb_writer.log(
-                    {"mem-allocated-bytes": mem_stats["allocated_bytes.all.current"]}, iteration
-                )
-                wandb_writer.log(
-                    {"mem-allocated-count": mem_stats["allocation.all.current"]}, iteration
-                )
+        # if args.log_memory_to_tensorboard:
+        #     mem_stats = torch.cuda.memory_stats()
+        #     if writer:
+        #         writer.add_scalar(
+        #             "mem-reserved-bytes", mem_stats["reserved_bytes.all.current"], iteration
+        #         )
+        #         writer.add_scalar(
+        #             "mem-allocated-bytes", mem_stats["allocated_bytes.all.current"], iteration
+        #         )
+        #         writer.add_scalar(
+        #             "mem-max-allocated-bytes", mem_stats["allocated_bytes.all.peak"], iteration
+        #         )
+        #         writer.add_scalar("mem-allocated-count", mem_stats["allocation.all.current"], iteration)
+        #     if wandb_writer:
+        #         wandb_writer.log(
+        #             {"mem-reserved-bytes": mem_stats["reserved_bytes.all.current"]}, iteration
+        #         )
+        #         wandb_writer.log(
+        #             {"mem-allocated-bytes": mem_stats["allocated_bytes.all.current"]}, iteration
+        #         )
+        #         wandb_writer.log(
+        #             {"mem-allocated-count": mem_stats["allocation.all.current"]}, iteration
+        #         )
 
     if args.num_experts is not None:
         moe_loss_scale = 1 / get_num_microbatches()
@@ -1903,10 +1908,10 @@ def training_log(
             wandb_writer=wandb_writer,
             total_loss_dict=total_loss_dict,
             per_layer_logging=args.moe_per_layer_logging,
-            force_initialize=True,
-            track_names=track_names,
-            num_layers=args.num_layers,
-            moe_layer_freq=args.moe_layer_freq,
+            # force_initialize=True,
+            # track_names=track_names,
+            # num_layers=args.num_layers,
+            # moe_layer_freq=args.moe_layer_freq,
         )
     if args.mtp_num_layers is not None:
         mtp_loss_scale = 1 / get_num_microbatches()
@@ -1984,17 +1989,17 @@ def training_log(
         total_loss_dict[skipped_iters_key] = 0
         total_loss_dict[nan_iters_key] = 0
         print_rank_last(log_string)
-        if not args.auto_tune:
-            if report_memory_flag:
-                # Report memory after optimizer state has been initialized.
-                if torch.distributed.get_rank() == 0:
-                    num_microbatches = get_num_microbatches()
-                    report_theoretical_memory(args, num_microbatches=num_microbatches, verbose=True)
-                report_memory(f'(after {iteration} iterations)')
-                report_memory_flag = False
-        else:
-            report_memory(f'(after {iteration} iterations)')
-            report_memory_flag = False
+        # if not args.auto_tune:
+        #     if report_memory_flag:
+        #         # Report memory after optimizer state has been initialized.
+        #         if torch.distributed.get_rank() == 0:
+        #             num_microbatches = get_num_microbatches()
+        #             report_theoretical_memory(args, num_microbatches=num_microbatches, verbose=True)
+        #         report_memory(f'(after {iteration} iterations)')
+        #         report_memory_flag = False
+        # else:
+        report_memory(f'(after {iteration} iterations)')
+        report_memory_flag = False
         timers.log(timers_to_log, normalizer=args.log_interval)
 
     return report_memory_flag
@@ -2138,7 +2143,6 @@ def post_training_step_callbacks(
         check_adlr_autoresume_termination(iteration, model, optimizer, opt_param_scheduler)
 
     # Profiling.
-    torch.cuda.nvtx.range_pop() # for iteratrion
     if (
         args.profile
         and iteration == args.profile_step_end
@@ -2281,16 +2285,16 @@ def train(
     timers = get_timers()
     one_logger = get_one_logger()
 
-    if args.run_workload_inspector_server:
-        try:
-            from workload_inspector.utils.webserver import run_server
-            import threading
+    # if args.run_workload_inspector_server:
+    #     try:
+    #         from workload_inspector.utils.webserver import run_server
+    #         import threading
 
-            threading.Thread(
-                target=run_server, daemon=True, args=(torch.distributed.get_rank(),)
-            ).start()
-        except ModuleNotFoundError:
-            print_rank_0("workload inspector module not found.")
+    #         threading.Thread(
+    #             target=run_server, daemon=True, args=(torch.distributed.get_rank(),)
+    #         ).start()
+    #     except ModuleNotFoundError:
+    #         print_rank_0("workload inspector module not found.")
 
     # Write args to tensorboard
     write_args_to_tensorboard()
@@ -2299,6 +2303,72 @@ def train(
     for model_module in model:
         model_module.train()
 
+    def print_inf_name(name):
+        def check_inf_nan(grad):
+            if torch.isinf(grad).any():
+                print("Inf detected in gradients!", name)
+                print(grad)
+            elif torch.isnan(grad).any():
+                print("NaN detected in gradients!",name)
+                print(grad)
+            else:
+                print(name, grad)
+        return check_inf_nan
+
+    def forward_output(name):
+        def forward_hook(module, input, output):
+            print(f"Inside {module.__class__.__name__} forward hook")
+            print(f"Input: {input}")  # 假设输入是个张量
+            print(f"Output: {output}")
+            index = 0
+            if module.__class__.__name__ == "TERowParallelLinear" and index == 0:
+                global_rank = torch.distributed.get_rank()
+                if global_rank == 0:
+                    torch.save(input[0].cpu(), f'global-{global_rank}.{module.__class__.__name__}.input.pt')
+                    index += 1
+
+            try:
+                print(f"weight: {module.weight}")
+            except:
+                pass
+            # print("Output is all zero:", torch.all(output == 0))
+            # if torch.all(output == 0):
+            #     global_rank = torch.distributed.get_rank()
+            #     torch.save(input[0].cpu(), f'global-{global_rank}.{name}.all_zero.pt')
+        return forward_hook
+
+    def backward_output(name):
+       def print_backward_hook(module, grad_input, grad_output):
+           #torch.set_printoptions(profile='full')
+            if len(grad_output) > 0 and grad_output[0] != None :
+                for idx, output in enumerate(grad_output):
+                    if output is not None and (torch.isinf(output).any() or torch.isnan(output).any()):
+                        global_rank = torch.distributed.get_rank()
+                        print(module.__class__, 'backward ends', name, len(grad_output), len(grad_input))
+                        print("is_inf1:", torch.isinf(output).any(), "is_nan1:",torch.isnan(output).any(), output,'global_rank', global_rank)
+            if len(grad_input) > 0 and grad_input[0] !=None:
+                for idx, input in enumerate(grad_input):
+                    print(module.__class__, 'backward ends', name, grad_output, grad_input)
+                    # if input is not None and (torch.isinf(input).any() or torch.isnan(input).any()):
+                    #     global_rank = torch.distributed.get_rank()
+                    #     print(module.__class__, 'backward ends', name, len(grad_output), len(grad_input))
+                    #     print("is_inf2:", torch.isinf(input).any(), "is_nan2:",torch.isnan(input).any(),input, 'global_rank', global_rank, "idx:", idx)
+                    #     for idx1, output in enumerate(grad_output):
+                    #         torch.save(input.cpu(), f'global-{global_rank}.{name}.{idx1}.nan1.grad_output.pt')
+                    #     for idx2, input in enumerate(grad_input):
+                    #         torch.save(input.cpu(), f'global-{global_rank}.{name}.{idx2}.nan2.grad_input.pt')
+       return print_backward_hook
+    # print(model)
+    # for name, module in model[0].named_modules():
+
+    #     # print(name, model_module)
+    #    # module.register_forward_pre_hook(print_pre_forward_hook)
+    #    # module.register_forward_hook(print_forward_hook)
+    # #    if name == 'model.layers.2.self_attn.core_attention.pv' or name == 'model.layers.2.self_attn.core_attention.softmax':
+    #        #module.register_full_backward_pre_hook(print_pre_backward_hook)
+    #        #if name == 'model.layers.25.input_layernorm':
+    #     module.register_forward_hook(forward_output(name))
+    #     module.register_full_backward_hook(backward_output(name))
     # Tracking loss.
     total_loss_dict = {}
 
@@ -2453,30 +2523,108 @@ def train(
         print_rank_0(f">>> Weight hashes match after {iteration} iterations...")
 
     # Run training iterations till done.
-    while iteration < args.train_iters:
-        if args.profile and torch.distributed.get_rank() in args.profile_ranks:
-            if args.use_pytorch_profiler:
-                prof.step()
-            elif iteration == args.profile_step_start:
-                torch.cuda.cudart().cudaProfilerStart()
-                torch.autograd.profiler.emit_nvtx(record_shapes=True).__enter__()
-        torch.cuda.nvtx.range_push(f"iteration num {iteration}") # NOTE(lizhiyu): add iteration num tag for profile
-        ft_integration.on_checkpointing_start()
-        maybe_finalize_async_save(blocking=False)
-        ft_integration.on_checkpointing_end(is_async_finalization=True)
-
-        # Update number of microbatches first without consistency check to decide if a
-        # checkpoint should be saved. If the number of microbatches is different
-        # from the previous iteration, save a checkpoint. Then run consistency check
-        # to make sure training configuration is still valid.
-        update_num_microbatches(args.consumed_train_samples, consistency_check=False, verbose=True)
-        if get_num_microbatches() != num_microbatches and iteration != 0 \
-            and args.save_when_num_microbatches_change:
-            assert get_num_microbatches() > num_microbatches, (
-                f"Number of microbatches should be increasing due to batch size rampup; "
-                f"instead going from {num_microbatches} to {get_num_microbatches()}"
+    with maybe_enable_profiling(
+        args, global_step=iteration
+    ) as torch_profiler:
+        while iteration < args.train_iters:
+            print_rank_0(f"go in  after {iteration} iterations...")
+            if args.profile and torch.distributed.get_rank() in args.profile_ranks:
+                if args.use_pytorch_profiler:
+                    prof.step()
+                elif iteration == args.profile_step_start:
+                    torch.cuda.cudart().cudaProfilerStart()
+                    torch.autograd.profiler.emit_nvtx(record_shapes=True).__enter__()
+
+            ft_integration.on_checkpointing_start()
+            maybe_finalize_async_save(blocking=False)
+            ft_integration.on_checkpointing_end(is_async_finalization=True)
+
+            # Update number of microbatches first without consistency check to decide if a
+            # checkpoint should be saved. If the number of microbatches is different
+            # from the previous iteration, save a checkpoint. Then run consistency check
+            # to make sure training configuration is still valid.
+            update_num_microbatches(args.consumed_train_samples, consistency_check=False, verbose=True)
+            if get_num_microbatches() != num_microbatches and iteration != 0 \
+                and args.save_when_num_microbatches_change:
+                assert get_num_microbatches() > num_microbatches, (
+                    f"Number of microbatches should be increasing due to batch size rampup; "
+                    f"instead going from {num_microbatches} to {get_num_microbatches()}"
+                )
+                if args.save is not None:
+                    save_checkpoint_and_time(
+                        iteration,
+                        model,
+                        optimizer,
+                        opt_param_scheduler,
+                        num_floating_point_operations_so_far,
+                        checkpointing_context,
+                        train_data_iterator=train_data_iterator,
+                    )
+            num_microbatches = get_num_microbatches()
+            update_num_microbatches(args.consumed_train_samples, consistency_check=True, verbose=True)
+
+            # Completely skip iteration if needed.
+            if iteration in args.iterations_to_skip:
+                # Dummy train_step to fast forward train_data_iterator.
+                dummy_train_step(train_data_iterator)
+                iteration += 1
+                batch_size = (
+                    mpu.get_data_parallel_world_size() * args.micro_batch_size * get_num_microbatches()
+                )
+                args.consumed_train_samples += batch_size
+                args.skipped_train_samples += batch_size
+                continue
+
+            # Run training step.
+            args.curr_iteration = iteration
+
+            ########## FlagScale Begin ##########
+            args.skip_samples_range = None
+            args.skip_iters_range = None
+            if args.skip_samples_range or args.skip_iters_range:
+                current_global_batch_size = get_current_global_batch_size()
+                start_skip_iteration = 0
+                end_skip_iteration = 0
+                if args.skip_samples_range:
+                    if args.consumed_train_samples + current_global_batch_size > args.skip_samples_range[0] and args.consumed_train_samples < args.skip_samples_range[1]:
+                        num_skipped_iters = (args.skip_samples_range[1] - args.consumed_train_samples + current_global_batch_size - 1) // current_global_batch_size
+                        args.skip_samples_range[1] = args.consumed_train_samples + num_skipped_iters * current_global_batch_size
+                        start_skip_iteration = iteration
+                        end_skip_iteration = iteration + num_skipped_iters
+                else:
+                    if iteration >= args.skip_iters_range[0] and iteration < args.skip_iters_range[1]:
+                        start_skip_iteration = iteration
+                        end_skip_iteration = args.skip_iters_range[1]
+                while iteration >= start_skip_iteration and iteration < end_skip_iteration:
+                    if mpu.is_pipeline_first_stage() or mpu.is_pipeline_last_stage():
+                        for _ in range(get_num_microbatches()):
+                            _ = next(train_data_iterator)
+                    args.consumed_train_samples += mpu.get_data_parallel_world_size() * \
+                                            args.micro_batch_size * \
+                                            get_num_microbatches()
+                    update_num_microbatches(args.consumed_train_samples, consistency_check=True, verbose=True)
+                    iteration += 1
+
+                args.curr_iteration = iteration
+                if rerun_state_machine.current_iteration != iteration:
+                    print_rank_0(f"Setting rerun_state_machine.current_iteration to {iteration}...")
+                    rerun_state_machine.current_iteration = iteration
+            ########## FlagScale end ##########
+
+            ft_integration.on_training_step_start()
+            (
+                loss_dict,
+                skipped_iter,
+                should_checkpoint,
+                should_exit,
+                exit_code,
+                grad_norm,
+                num_zeros_in_grad,
+            ) = train_step(
+                forward_step_func, train_data_iterator, model, optimizer, opt_param_scheduler, config
             )
-            if args.save is not None:
+            ft_integration.on_training_step_end()
+            if should_checkpoint:
                 save_checkpoint_and_time(
                     iteration,
                     model,
@@ -2486,228 +2634,101 @@ def train(
                     checkpointing_context,
                     train_data_iterator=train_data_iterator,
                 )
-        num_microbatches = get_num_microbatches()
-        update_num_microbatches(args.consumed_train_samples, consistency_check=True, verbose=True)
-
-        # Completely skip iteration if needed.
-        if iteration in args.iterations_to_skip:
-            # Dummy train_step to fast forward train_data_iterator.
-            dummy_train_step(train_data_iterator)
+            if should_exit:
+                break
+
+            # Enable forward pre-hooks after first set of forward and backward passes.
+            # When running in fp16, skip all NaN iterations until steady-state loss scaling value
+            # is reached.
+            if iteration == start_iteration:
+                if skipped_iter:
+                    # Only enable forward pre-hook after a training step has successfully run. Relevant
+                    # for fp16 codepath where first XX iterations are skipped until steady-state loss
+                    # scale value is reached.
+                    start_iteration = iteration + 1
+                else:
+                    # Enable forward pre-hook after training step has successfully run. All subsequent
+                    # forward passes will use the forward pre-hook / `param_sync_func` in
+                    # `forward_backward_func`.
+                    if should_disable_forward_pre_hook(args):
+                        enable_forward_pre_hook(model)
+                        config.param_sync_func = param_sync_func
+                        pre_hook_enabled = True
+            if torch_profiler:
+                    torch_profiler.step()
             iteration += 1
             batch_size = (
                 mpu.get_data_parallel_world_size() * args.micro_batch_size * get_num_microbatches()
             )
             args.consumed_train_samples += batch_size
-            args.skipped_train_samples += batch_size
-            continue
-
-        # Run training step.
-        args.curr_iteration = iteration
-
-        ########## FlagScale Begin ##########
-        if args.skip_samples_range or args.skip_iters_range:
-            current_global_batch_size = get_current_global_batch_size()
-            start_skip_iteration = 0
-            end_skip_iteration = 0
-            if args.skip_samples_range:
-                if args.consumed_train_samples + current_global_batch_size > args.skip_samples_range[0] and args.consumed_train_samples < args.skip_samples_range[1]:
-                    num_skipped_iters = (args.skip_samples_range[1] - args.consumed_train_samples + current_global_batch_size - 1) // current_global_batch_size
-                    args.skip_samples_range[1] = args.consumed_train_samples + num_skipped_iters * current_global_batch_size
-                    start_skip_iteration = iteration
-                    end_skip_iteration = iteration + num_skipped_iters
-            else:
-                if iteration >= args.skip_iters_range[0] and iteration < args.skip_iters_range[1]:
-                    start_skip_iteration = iteration
-                    end_skip_iteration = args.skip_iters_range[1]
-            while iteration >= start_skip_iteration and iteration < end_skip_iteration:
-                if mpu.is_pipeline_first_stage() or mpu.is_pipeline_last_stage():
-                    for _ in range(get_num_microbatches()):
-                        _ = next(train_data_iterator)
-                args.consumed_train_samples += mpu.get_data_parallel_world_size() * \
-                                           args.micro_batch_size * \
-                                           get_num_microbatches()
-                update_num_microbatches(args.consumed_train_samples, consistency_check=True, verbose=True)
-                iteration += 1
-
-            args.curr_iteration = iteration
-            if rerun_state_machine.current_iteration != iteration:
-                print_rank_0(f"Setting rerun_state_machine.current_iteration to {iteration}...")
-                rerun_state_machine.current_iteration = iteration
-        ########## FlagScale end ##########
-
-        ft_integration.on_training_step_start()
-        (
-            loss_dict,
-            skipped_iter,
-            should_checkpoint,
-            should_exit,
-            exit_code,
-            grad_norm,
-            num_zeros_in_grad,
-        ) = train_step(
-            forward_step_func, train_data_iterator, model, optimizer, opt_param_scheduler, config
-        )
-        ft_integration.on_training_step_end()
-        if should_checkpoint:
-            save_checkpoint_and_time(
-                iteration,
-                model,
-                optimizer,
-                opt_param_scheduler,
-                num_floating_point_operations_so_far,
-                checkpointing_context,
-                train_data_iterator=train_data_iterator,
+            num_skipped_samples_in_batch = (
+                get_current_global_batch_size() - get_current_running_global_batch_size()
             )
-        if should_exit:
-            break
-
-        # Enable forward pre-hooks after first set of forward and backward passes.
-        # When running in fp16, skip all NaN iterations until steady-state loss scaling value
-        # is reached.
-        if iteration == start_iteration:
-            if skipped_iter:
-                # Only enable forward pre-hook after a training step has successfully run. Relevant
-                # for fp16 codepath where first XX iterations are skipped until steady-state loss
-                # scale value is reached.
-                start_iteration = iteration + 1
+            if args.decrease_batch_size_if_needed:
+                assert num_skipped_samples_in_batch >= 0
             else:
-                # Enable forward pre-hook after training step has successfully run. All subsequent
-                # forward passes will use the forward pre-hook / `param_sync_func` in
-                # `forward_backward_func`.
-                if should_disable_forward_pre_hook(args):
-                    enable_forward_pre_hook(model)
-                    config.param_sync_func = param_sync_func
-                    pre_hook_enabled = True
-
-        iteration += 1
-        batch_size = (
-            mpu.get_data_parallel_world_size() * args.micro_batch_size * get_num_microbatches()
-        )
-        args.consumed_train_samples += batch_size
-        num_skipped_samples_in_batch = (
-            get_current_global_batch_size() - get_current_running_global_batch_size()
-        )
-        if args.decrease_batch_size_if_needed:
-            assert num_skipped_samples_in_batch >= 0
-        else:
-            assert num_skipped_samples_in_batch == 0
-        args.skipped_train_samples += num_skipped_samples_in_batch
-        num_floating_point_operations_in_batch = num_floating_point_operations(args, batch_size)
-        num_floating_point_operations_so_far += num_floating_point_operations_in_batch
-        num_floating_point_operations_since_last_log_event += num_floating_point_operations_in_batch
-
-        # Logging.
-        if not optimizer.is_stub_optimizer:
-            loss_scale = optimizer.get_loss_scale().item()
-        else:
-            loss_scale = 1.0
-        params_norm = None
-
-        if args.log_params_norm:
-            params_norm = calc_params_l2_norm(model)
-        learning_rate = None
-        decoupled_learning_rate = None
-        for param_group in optimizer.param_groups:
-            if param_group['is_decoupled_lr']:
-                decoupled_learning_rate = param_group['lr']
+                assert num_skipped_samples_in_batch == 0
+            args.skipped_train_samples += num_skipped_samples_in_batch
+            num_floating_point_operations_in_batch = num_floating_point_operations(args, batch_size)
+            num_floating_point_operations_so_far += num_floating_point_operations_in_batch
+            num_floating_point_operations_since_last_log_event += num_floating_point_operations_in_batch
+
+            # Logging.
+            if not optimizer.is_stub_optimizer:
+                loss_scale = optimizer.get_loss_scale().item()
             else:
-                learning_rate = param_group['lr']
-        report_memory_flag = training_log(
-            loss_dict,
-            total_loss_dict,
-            learning_rate,
-            decoupled_learning_rate,
-            iteration,
-            loss_scale,
-            report_memory_flag,
-            skipped_iter,
-            grad_norm,
-            params_norm,
-            num_zeros_in_grad,
-        )
-
-        # Evaluation.
-        if args.eval_interval and iteration % args.eval_interval == 0 and args.do_valid:
-            timers('interval-time').stop()
-            if should_disable_forward_pre_hook(args):
-                disable_forward_pre_hook(model)
-                pre_hook_enabled = False
-            if args.manual_gc and args.manual_gc_eval:
-                # Collect all objects.
-                gc.collect()
-            prefix = f'iteration {iteration}'
-            timers('eval-time', log_level=0).start(barrier=True)
-            evaluate_and_print_results(
-                prefix,
-                forward_step_func,
-                valid_data_iterator,
-                model,
+                loss_scale = 1.0
+            params_norm = None
+
+            if args.log_params_norm:
+                params_norm = calc_params_l2_norm(model)
+            learning_rate = None
+            decoupled_learning_rate = None
+            for param_group in optimizer.param_groups:
+                if param_group['is_decoupled_lr']:
+                    decoupled_learning_rate = param_group['lr']
+                else:
+                    learning_rate = param_group['lr']
+            report_memory_flag = training_log(
+                loss_dict,
+                total_loss_dict,
+                learning_rate,
+                decoupled_learning_rate,
                 iteration,
-                process_non_loss_data_func,
-                config,
-                verbose=False,
-                write_to_tensorboard=True,
-                non_loss_data_func=non_loss_data_func,
+                loss_scale,
+                report_memory_flag,
+                skipped_iter,
+                grad_norm,
+                params_norm,
+                num_zeros_in_grad,
             )
-            eval_duration += timers('eval-time').elapsed()
-            eval_iterations += args.eval_iters
-            timers('eval-time').stop()
-            one_logger_utils.track_e2e_metrics()
-
-            if args.manual_gc and args.manual_gc_eval:
-                # Collect only the objects created and used in evaluation.
-                gc.collect(generation=0)
-            if should_disable_forward_pre_hook(args):
-                enable_forward_pre_hook(model)
-                pre_hook_enabled = True
-            timers('interval-time', log_level=0).start(barrier=True)
-
-
-        # Extra Evaluation =====================================================================
-        if args.extra_eval_interval and iteration % args.extra_eval_interval == 0:
-            # NOTE(zhaoyinglia): Must rebuild the dataloaders for extra validation here,
-            # to guarantee extra validation start from extra_iter=0 every time,
-            # but we don't need to rebuild the datasets.
-            if args.virtual_pipeline_model_parallel_size is not None:
-                extra_valid_data_iterator = []
-                for i in range(len(model)):
-                    mpu.set_virtual_pipeline_model_parallel_rank(i)
-                    extra_iterators = build_extra_valid_data_iterators(extra_valid_dataset_provider)
-                    extra_valid_data_iterator.append(extra_iterators)
-            else:
-                extra_valid_data_iterator = (
-                    build_extra_valid_data_iterators(extra_valid_dataset_provider)
-                )
-            timers('interval-time').stop()
-            # do_extra_valid flag is used to indicate that we are doing extra validation
-            # and is set in the build_extra_valid_data_iterators function
-            if getattr(args, "do_extra_valid", False):
+
+            # Evaluation.
+            if args.eval_interval and iteration % args.eval_interval == 0 and args.do_valid:
+                timers('interval-time').stop()
                 if should_disable_forward_pre_hook(args):
                     disable_forward_pre_hook(model)
                     pre_hook_enabled = False
                 if args.manual_gc and args.manual_gc_eval:
                     # Collect all objects.
                     gc.collect()
-                prefix = 'iteration {}'.format(iteration)
-                for extra_valid_index, extra_valid_data_itr in enumerate(extra_valid_data_iterator):
-                    timers('extra-eval-time', log_level=0).start(barrier=True)
-                    extra_eval_iters = args.extra_eval_iters_list[extra_valid_index]
-                    extra_evaluate_and_print_results(
-                        extra_valid_index,
-                        prefix,
-                        forward_step_func,
-                        extra_valid_data_itr,
-                        model,
-                        iteration,
-                        process_non_loss_data_func,
-                        config,
-                        verbose=False,
-                        write_to_tensorboard=True,
-                        non_loss_data_func=non_loss_data_func
-                    )
-                    extra_eval_duration += timers('extra-eval-time').elapsed()
-                    extra_eval_iterations += extra_eval_iters
-                    timers('extra-eval-time').stop()
+                prefix = f'iteration {iteration}'
+                timers('eval-time', log_level=0).start(barrier=True)
+                evaluate_and_print_results(
+                    prefix,
+                    forward_step_func,
+                    valid_data_iterator,
+                    model,
+                    iteration,
+                    process_non_loss_data_func,
+                    config,
+                    verbose=False,
+                    write_to_tensorboard=True,
+                    non_loss_data_func=non_loss_data_func,
+                )
+                eval_duration += timers('eval-time').elapsed()
+                eval_iterations += args.eval_iters
+                timers('eval-time').stop()
                 one_logger_utils.track_e2e_metrics()
 
                 if args.manual_gc and args.manual_gc_eval:
@@ -2717,31 +2738,88 @@ def train(
                     enable_forward_pre_hook(model)
                     pre_hook_enabled = True
                 timers('interval-time', log_level=0).start(barrier=True)
-        # =======================================================================================
 
-        # Miscellaneous post-training-step functions (e.g., FT heartbeats, GC).
-        # Some of these only happen at specific iterations.
-        post_training_step_callbacks(
-            model,
-            optimizer,
-            opt_param_scheduler,
-            iteration,
-            prof,
-            num_floating_point_operations_since_last_log_event,
-        )
 
-        # Checkpoint and decide whether to exit.
-        should_exit = checkpoint_and_decide_exit(
-            model,
-            optimizer,
-            opt_param_scheduler,
-            iteration,
-            num_floating_point_operations_so_far,
-            checkpointing_context,
-            train_data_iterator,
-        )
-        if should_exit:
-            break
+            # Extra Evaluation =====================================================================
+            args.extra_eval_interval = False
+            if args.extra_eval_interval and iteration % args.extra_eval_interval == 0:
+                # NOTE(zhaoyinglia): Must rebuild the dataloaders for extra validation here,
+                # to guarantee extra validation start from extra_iter=0 every time,
+                # but we don't need to rebuild the datasets.
+                if args.virtual_pipeline_model_parallel_size is not None:
+                    extra_valid_data_iterator = []
+                    for i in range(len(model)):
+                        mpu.set_virtual_pipeline_model_parallel_rank(i)
+                        extra_iterators = build_extra_valid_data_iterators(extra_valid_dataset_provider)
+                        extra_valid_data_iterator.append(extra_iterators)
+                else:
+                    extra_valid_data_iterator = (
+                        build_extra_valid_data_iterators(extra_valid_dataset_provider)
+                    )
+                timers('interval-time').stop()
+                # do_extra_valid flag is used to indicate that we are doing extra validation
+                # and is set in the build_extra_valid_data_iterators function
+                if getattr(args, "do_extra_valid", False):
+                    if should_disable_forward_pre_hook(args):
+                        disable_forward_pre_hook(model)
+                        pre_hook_enabled = False
+                    if args.manual_gc and args.manual_gc_eval:
+                        # Collect all objects.
+                        gc.collect()
+                    prefix = 'iteration {}'.format(iteration)
+                    for extra_valid_index, extra_valid_data_itr in enumerate(extra_valid_data_iterator):
+                        timers('extra-eval-time', log_level=0).start(barrier=True)
+                        extra_eval_iters = args.extra_eval_iters_list[extra_valid_index]
+                        extra_evaluate_and_print_results(
+                            extra_valid_index,
+                            prefix,
+                            forward_step_func,
+                            extra_valid_data_itr,
+                            model,
+                            iteration,
+                            process_non_loss_data_func,
+                            config,
+                            verbose=False,
+                            write_to_tensorboard=True,
+                            non_loss_data_func=non_loss_data_func
+                        )
+                        extra_eval_duration += timers('extra-eval-time').elapsed()
+                        extra_eval_iterations += extra_eval_iters
+                        timers('extra-eval-time').stop()
+                    one_logger_utils.track_e2e_metrics()
+
+                    if args.manual_gc and args.manual_gc_eval:
+                        # Collect only the objects created and used in evaluation.
+                        gc.collect(generation=0)
+                    if should_disable_forward_pre_hook(args):
+                        enable_forward_pre_hook(model)
+                        pre_hook_enabled = True
+                    timers('interval-time', log_level=0).start(barrier=True)
+            # =======================================================================================
+
+            # Miscellaneous post-training-step functions (e.g., FT heartbeats, GC).
+            # Some of these only happen at specific iterations.
+            post_training_step_callbacks(
+                model,
+                optimizer,
+                opt_param_scheduler,
+                iteration,
+                prof,
+                num_floating_point_operations_since_last_log_event,
+            )
+            # Checkpoint and decide whether to exit.
+            print_rank_0('go in checkpoint_and_decide_exit')
+            should_exit = checkpoint_and_decide_exit(
+                model,
+                optimizer,
+                opt_param_scheduler,
+                iteration,
+                num_floating_point_operations_so_far,
+                checkpointing_context,
+                train_data_iterator,
+            )
+            if should_exit:
+                break
 
     one_logger_utils.track_e2e_metrics()
 
diff --git a/flagscale/train/train_gpt.py b/flagscale/train/train_gpt.py
index c7b69cab..235447b0 100644
--- a/flagscale/train/train_gpt.py
+++ b/flagscale/train/train_gpt.py
@@ -6,6 +6,17 @@ from functools import partial
 from typing import List, Optional, Tuple, Union
 
 import torch
+import os 
+import sys
+sys.path.append(os.path.dirname(
+    os.path.dirname(os.path.abspath(__file__))))
+sys.path.append("./third_party/Megatron-LM/megatron-lm-musa-patch")
+# sys.path.append("/home/dist/haoran/FlagScale/Megatron-LM")
+
+if os.getenv("ACCELERATOR_BACKEND", "musa") == "musa":
+    import musa_patch
+else:
+    pass
 
 from megatron.core import parallel_state
 from megatron.core.datasets.blended_megatron_dataset_builder import BlendedMegatronDatasetBuilder
@@ -16,11 +27,11 @@ from megatron.core.models.gpt.gpt_layer_specs import (
     get_gpt_decoder_block_spec,
     get_gpt_layer_local_spec,
     get_gpt_layer_with_transformer_engine_spec,
-    get_gpt_mtp_block_spec,
-)
-from megatron.core.models.gpt.heterogeneous.heterogeneous_layer_specs import (
-    get_gpt_heterogeneous_layer_spec,
+    # get_gpt_mtp_block_spec,
 )
+# from megatron.core.models.gpt.heterogeneous.heterogeneous_layer_specs import (
+#     get_gpt_heterogeneous_layer_spec,
+# )
 from megatron.core.rerun_state_machine import get_rerun_state_machine
 from megatron.core.transformer.spec_utils import import_module
 from megatron.core.utils import StragglerDetector
@@ -127,10 +138,10 @@ def model_provider(
             if args.num_experts:
                 # Define the decoder block spec
                 transformer_layer_spec = get_gpt_decoder_block_spec(
-                    config, use_transformer_engine=use_te, normalization=args.normalization
+                    config, use_transformer_engine=use_te #, normalization=args.normalization
                 )
-            elif args.heterogeneous_layers_config_path is not None:
-                transformer_layer_spec = get_gpt_heterogeneous_layer_spec(config, use_te)
+            # elif args.heterogeneous_layers_config_path is not None:
+            #     transformer_layer_spec = get_gpt_heterogeneous_layer_spec(config, use_te)
             else:
                 # Define the decoder layer spec
                 if use_te:
@@ -151,6 +162,7 @@ def model_provider(
                         normalization=args.normalization,
                     )
         mtp_block_spec = None
+        args.mtp_num_layers = None
         if args.mtp_num_layers is not None:
             mtp_block_spec = get_gpt_mtp_block_spec(
                 config, transformer_layer_spec, use_transformer_engine=use_te
@@ -170,8 +182,8 @@ def model_provider(
             rotary_percent=args.rotary_percent,
             rotary_base=args.rotary_base,
             rope_scaling=args.use_rope_scaling,
-            mtp_block_spec=mtp_block_spec,
-            vp_stage=vp_stage,
+            # mtp_block_spec=mtp_block_spec,
+            # vp_stage=vp_stage,
         )
 
     return model
@@ -283,7 +295,7 @@ def forward_step(data_iterator, model: GPTModel):
             output_tensor = model(tokens, position_ids, attention_mask, labels=labels)
         else:
             output_tensor = model(
-                tokens, position_ids, attention_mask, labels=labels, loss_mask=loss_mask
+                tokens, position_ids, attention_mask, labels=labels#, loss_mask=loss_mask
             )
 
     # [ModelOpt]: model is needed to access ModelOpt distillation losses
@@ -319,8 +331,8 @@ def core_gpt_dataset_config_from_args(args):
         reset_attention_mask=args.reset_attention_mask,
         eod_mask_loss=args.eod_mask_loss,
         create_attention_mask=args.create_attention_mask_in_dataloader,
-        object_storage_cache_path=args.object_storage_cache_path,
-        mid_level_dataset_surplus=args.mid_level_dataset_surplus,
+        # object_storage_cache_path=args.object_storage_cache_path,
+        # mid_level_dataset_surplus=args.mid_level_dataset_surplus,
     )
 
 
@@ -362,7 +374,7 @@ def train_valid_test_datasets_provider(train_val_test_num_samples):
     para_ctx = get_parallel_context()
     if para_ctx is not None:
         config = para_ctx.get_dataset_config()
-
+    args.apply_sft_dataset_separated_loss_mask_if_existed = False
     if config is None:
         if args.apply_sft_dataset_separated_loss_mask_if_existed:
             config = core_sft_dataset_config_from_args(args)
diff --git a/flagscale/train/train_qwen2_5_vl.py b/flagscale/train/train_qwen2_5_vl.py
index 9befeec7..68e54455 100644
--- a/flagscale/train/train_qwen2_5_vl.py
+++ b/flagscale/train/train_qwen2_5_vl.py
@@ -16,10 +16,15 @@
 
 import os
 import sys
-import logging
 from functools import partial
 from copy import deepcopy
-from typing import List, Optional, Tuple, Union
+from typing import Union, Optional, Tuple
+sys.path.append("./third_party/Megatron-LM/megatron-lm-musa-patch")
+
+if os.getenv("ACCELERATOR_BACKEND", "musa") == "musa":
+    import musa_patch
+else:
+    pass
 
 import torch
 import torch._dynamo
@@ -29,54 +34,21 @@ from argparse import Namespace
 # # For pytorch 2.6
 # torch.serialization.add_safe_globals([Namespace])
 
+from megatron.core import mpu
+
 from megatron.core import parallel_state
-from megatron.core.datasets.blended_megatron_dataset_builder import BlendedMegatronDatasetBuilder
-from megatron.core.datasets.gpt_dataset import GPTDataset, GPTDatasetConfig, MockGPTDataset
-from megatron.training.checkpointing import get_checkpoint_name # for dataloder
+from megatron.training.checkpointing import get_checkpoint_name
 from megatron.core.enums import ModelType
-from megatron.core.models.gpt import GPTModel
-from megatron.core.models.gpt.gpt_layer_specs import (
-    get_gpt_decoder_block_spec,
-    get_gpt_layer_local_spec,
-    get_gpt_layer_with_transformer_engine_spec,
-    get_gpt_mtp_block_spec,
-)
-from megatron.core.models.gpt.heterogeneous.heterogeneous_layer_specs import (
-    get_gpt_heterogeneous_layer_spec,
-)
-from megatron.core.rerun_state_machine import get_rerun_state_machine
-from megatron.core.transformer.spec_utils import import_module
-from megatron.core.utils import StragglerDetector
-from megatron.training import get_args, get_timers, get_tokenizer, print_rank_0
+from megatron.training import get_args, get_timers, pretrain, print_rank_0
 from megatron.training.arguments import core_transformer_config_from_args
 from megatron.training.utils import (
-    get_batch_on_this_cp_rank,
-    get_batch_on_this_tp_rank,
-    get_blend_and_blend_per_split,
+    average_losses_across_data_parallel_group,
 )
-from megatron.training.yaml_arguments import core_transformer_config_from_yaml
-
-import megatron.legacy.model  # isort: skip
-
-# NOTE: Loading `megatron.legacy.model` earlier fails due to circular import
-
-try:
-    from megatron.post_training.arguments import add_modelopt_args, modelopt_args_enabled
-    from megatron.post_training.loss_func import loss_func as loss_func_modelopt
-    from megatron.post_training.model_provider import model_provider as model_provider_modelopt
-
-    has_nvidia_modelopt = True
-except ImportError:
-    has_nvidia_modelopt = False
+from megatron.core.num_microbatches_calculator import get_num_microbatches
 
-from flagscale.train.datasets.sft_dataset import SFTDatasetConfig, SFTDataset
-from flagscale.train.extra_valid import extra_valid_datasets_provider
-from flagscale.train.train import pretrain
-stimer = StragglerDetector()
 
-#### especially for qwen2.5-vl ####
-from megatron.core.num_microbatches_calculator import get_num_microbatches
 torch._dynamo.config.suppress_errors = True
+from megatron.core import mpu
 from megatron.core.parallel_state import get_tensor_model_parallel_rank, get_pipeline_model_parallel_world_size, get_pipeline_model_parallel_rank
 from megatron.energon import (
     LimitDataset,
@@ -104,10 +76,7 @@ from flagscale.train.models.qwen2_5_vl.transformer_config import (
     get_vision_projection_config
 )
 from tools.datasets.qwenvl.data.dataset_helpers import TaskEncoder, print_error_handler
-#### especially for qwen2.5-vl ####
-IGNORE_IDX=-100
-FIRST_MAX_PADDING_FLAG = True
-LAST_LARGE_IMG=False
+
 def model_provider(
     pre_process=True, post_process=True, add_encoder=True, add_decoder=True
 ) -> Union[Qwen2_5VLModel]:
@@ -135,37 +104,46 @@ def model_provider(
     transformer_layer_spec = get_gpt_layer_with_transformer_engine_spec(args.qk_layernorm)
     vision_model_spec = get_qwen2vl_vision_model_spec()
     vision_projector_spec = get_mlp_module_spec(add_norm=False).submodules
-    if args.enable_variable_seq_lengths:
-        config.variable_seq_lengths = True
 
+    #build_model_context_args = {}
+    #try:
+    #    import torch_musa
+    #    from transformer_engine.pytorch import fp8_model_init
+
+    #    build_model_context = fp8_model_init
+    #    build_model_context_args["enabled"] = True
+    #    build_model_context_args["preserve_high_precision_init_val"] = True
+    #except:
+    #    raise RuntimeError("--fp8-param-gather requires `fp8_model_init` from TransformerEngine, but not found.")
+    #with build_model_context(**build_model_context_args):
     model = Qwen2_5VLModel(
-        language_transformer_config=config,
-        language_transformer_layer_spec=transformer_layer_spec,
-        language_vocab_size=args.padded_vocab_size,
-        language_max_sequence_length=args.max_position_embeddings,
-
-        vision_transformer_config=vision_config,
-        vision_transformer_layer_spec=vision_model_spec,
-        drop_vision_class_token=False, # NOTE: no class token to drop?
-
-        vision_projection_config=vision_projector_config,
-        vision_projection_layer_spec=vision_projector_spec,
-        vision_projection_type='mlp',
-        allow_missing_vision_projection_checkpoint= args.allow_missing_vision_projection_checkpoint,
-
-        language_position_embedding_type=args.position_embedding_type,
-        language_rotary_percent=args.rotary_percent,
-        language_rotary_base=args.rotary_base,
-
-        pre_process=pre_process,
-        post_process=post_process,
-        add_decoder=add_decoder,
-        add_encoder=add_encoder,
-
-        fp16_lm_cross_entropy=args.fp16_lm_cross_entropy,
-        parallel_output=True,
-        language_share_embeddings_and_output_weights=not args.untie_embeddings_and_output_weights,
-    )
+            language_transformer_config=config,
+            language_transformer_layer_spec=transformer_layer_spec,
+            language_vocab_size=args.padded_vocab_size,
+            language_max_sequence_length=args.max_position_embeddings,
+
+            vision_transformer_config=vision_config,
+            vision_transformer_layer_spec=vision_model_spec,
+            drop_vision_class_token=False, # NOTE: no class token to drop?
+
+            vision_projection_config=vision_projector_config,
+            vision_projection_layer_spec=vision_projector_spec,
+            vision_projection_type='mlp',
+            allow_missing_vision_projection_checkpoint= args.allow_missing_vision_projection_checkpoint,
+
+            language_position_embedding_type=args.position_embedding_type,
+            language_rotary_percent=args.rotary_percent,
+            language_rotary_base=args.rotary_base,
+
+            pre_process=pre_process,
+            post_process=post_process,
+            add_decoder=add_decoder,
+            add_encoder=add_encoder,
+
+            fp16_lm_cross_entropy=args.fp16_lm_cross_entropy,
+            parallel_output=True,
+            language_share_embeddings_and_output_weights=not args.untie_embeddings_and_output_weights,
+        )
 
     model.freeze(
         freeze_language_model=args.freeze_LM,
@@ -175,7 +153,7 @@ def model_provider(
 
     return model
 
-# copy from https://github.com/huggingface/transformers/blob/40a493c7ed4f19f08eadb0639cf26d49bfa5e180/src/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py#L1404
+# Slightly modified from Qwen2_5VLForConditionalGeneration.get_rope_index
 def get_rope_index(
     input_ids: Optional[torch.LongTensor] = None,
     image_grid_thw: Optional[torch.LongTensor] = None,
@@ -401,16 +379,9 @@ def get_batch(data_iterator):
     torch.cuda.nvtx.range_push("get_data")
     if data_iterator is not None and get_tensor_model_parallel_rank() == 0:
         data = next(data_iterator)
-        # pad_token_id = get_tokenizer().pad_token_id
-        pad_token_id = IGNORE_IDX
-        # while (data["target"] == pad_token_id).all() or (data["target"].shape[-1] < 986 or data["target"].shape[-1] > 1000): # for debug
-        while (data["target"] == pad_token_id).all():
-            logging.getLogger(__name__).warning("The current data is invalid because the target is all pad_token_id! Get next data to avoid fail, but it's better to check the data!")
-            data = next(data_iterator)
     else:
         data = None
 
-
     data_text =  broadcast_data(["text"], data, torch.int64)["text"]
 
     target =  broadcast_data(["target"], data, torch.int64)["target"]
@@ -422,17 +393,6 @@ def get_batch(data_iterator):
 
     # shape: n_image_samples
     image_thw_grids = broadcast_data(["image_thw_grids"], data, torch.long)["image_thw_grids"]
-
-    # global LAST_LARGE_IMG
-    # if LAST_LARGE_IMG:
-    #     torch.cuda.empty_cache()
-    #     LAST_LARGE_IMG=False
-    # if image_thw_grids.prod(axis=-1).sum() // 4 > 3000:
-    #     torch.cuda.empty_cache()
-    #     LAST_LARGE_IMG = True
-    args = get_args()
-    if data_text.shape[-1] == args.max_padding_length and get_pipeline_model_parallel_rank() == 0:
-        torch.cuda.empty_cache()
     # shape: n_video_samples
     video_thw_grids = broadcast_data(["video_thw_grids"], data, torch.long)["video_thw_grids"]
     # shape: n_video_samples
@@ -455,7 +415,7 @@ def get_batch(data_iterator):
     # NOTE: no sequence packing in LLM inputs
     torch.cuda.nvtx.range_push("get_ltor_masks_and_position_ids")
     attention_mask, loss_mask, position_ids = get_ltor_masks_and_position_ids(
-        tokens, image_thw_grids, video_thw_grids, labels, IGNORE_IDX, second_per_grid_ts
+        tokens, image_thw_grids, video_thw_grids, labels, tokenizer.pad_token_id, second_per_grid_ts
     )
     torch.cuda.nvtx.range_pop()
 
@@ -473,71 +433,34 @@ def get_batch(data_iterator):
         video_input_mask
     )
 
-# define spiky loss as a loss that's 10x the max loss observed
-SPIKY_LOSS_FACTOR = 10
-
-
-def loss_func(
-    loss_mask: torch.Tensor, output_tensor: torch.Tensor, model: Optional[Qwen2_5VLModel] = None
-):
+def loss_func(loss_mask: torch.Tensor, output_tensor: torch.Tensor):
     """Loss function.
 
     Args:
         loss_mask (torch.Tensor): Used to mask out some portions of the loss
         output_tensor (torch.Tensor): The tensor with the losses
-        model (Qwen2_5VLModel, optional): The model (can be wrapped)
-
-    Returns:
-        the loss scalar for this micro-batch
-        the number of non-padded tokens in this microbatch
-        a dict containing reporting metrics on the loss and number of tokens across
-            the data parallel ranks
     """
     args = get_args()
 
-    if has_nvidia_modelopt and modelopt_args_enabled(args):  # [ModelOpt]
-        return loss_func_modelopt(loss_mask, output_tensor, model=model)
-
-    losses = output_tensor.view(-1).float()
+    losses = output_tensor.float()
     loss_mask = loss_mask.view(-1).float()
-    loss = torch.sum(losses * loss_mask)
+
+    loss = torch.stack([torch.sum(losses.view(-1) * loss_mask), loss_mask.sum()])
+    if args.context_parallel_size > 1:
+        torch.distributed.all_reduce(loss, group=mpu.get_context_parallel_group())
 
     # Check individual rank losses are not NaN prior to DP all-reduce.
-    rerun_state_machine = get_rerun_state_machine()
     if args.check_for_nan_in_loss_and_grad:
-        rerun_state_machine.validate_result(
-            result=loss,
-            rejection_func=torch.isnan,
-            message="found NaN in local forward loss calculation",
-            tolerance=0.0,  # forward pass calculations are determinisic
-            fatal=True,
-        )
-        rerun_state_machine.validate_result(
-            result=loss,
-            rejection_func=torch.isinf,
-            message="found Inf in local forward loss calculation",
-            tolerance=0.0,  # forward pass calculations are determinisic
-            fatal=True,
-        )
-    # Check for spiky loss
-    if args.check_for_spiky_loss:
-        rerun_state_machine.validate_result(
-            result=loss,
-            rejection_func=partial(
-                rerun_state_machine.is_unexpectedly_large,
-                threshold=SPIKY_LOSS_FACTOR,
-                context="loss",
-            ),
-            message="Spiky loss",
-            tolerance=0.0,  # forward pass calculations are determinisic
-            fatal=False,
+        global_rank = torch.distributed.get_rank()
+        assert not loss.isnan().any(), (
+            f"Rank {global_rank}: found NaN in local forward loss calculation. "
+            f"Device: {torch.cuda.current_device()}, node: {os.uname()[1]}"
         )
 
-    num_tokens = loss_mask.sum().clone().detach().to(torch.int)
-    reporting_loss = torch.cat([loss.clone().detach().view(1), num_tokens.view(1)])
-
-    return (loss, num_tokens, {'lm loss': reporting_loss})
+    averaged_loss = average_losses_across_data_parallel_group(loss)
+    averaged_loss = averaged_loss[0] / averaged_loss[1]
 
+    return loss[0] * args.context_parallel_size, {"lm loss": averaged_loss}
 
 def forward_step(data_iterator, model: Qwen2_5VLModel):
     """Forward training step.
@@ -546,43 +469,40 @@ def forward_step(data_iterator, model: Qwen2_5VLModel):
         data_iterator : Input data iterator
         model (GPTModel): The GPT Model
     """
-    args = get_args()
     timers = get_timers()
-
     # Get the batch.
-    timers('batch-generator', log_level=2).start()
-    global stimer
-    with stimer(bdata=True):
-        (
-            tokens,
-            labels,
-            loss_mask,
-            attention_mask,
-            position_ids,
-            imgs,
-            videos,
-            image_thw_grids,
-            video_thw_grids,
-            image_input_mask,
-            video_input_mask
-        ) = get_batch(data_iterator)
-    timers('batch-generator').stop()
+    timers("batch-generator", log_level=2).start()
+    (
+        tokens,
+        labels,
+        loss_mask,
+        attention_mask,
+        position_ids,
+        imgs,
+        videos,
+        image_thw_grids,
+        video_thw_grids,
+        image_input_mask,
+        video_input_mask
+    ) = get_batch(data_iterator)
+    timers("batch-generator").stop()
+
     vision_data = torch.cat([imgs, videos], dim=0)
     vision_grid = torch.cat([image_thw_grids, video_thw_grids], dim=0)
-    with stimer:
-        output_tensor = model(
-            input_ids = tokens,
-            position_ids = position_ids,
-            vision_data = vision_data,
-            vision_grid_thw =  vision_grid,
-            video_start_index = image_input_mask.sum().cpu().item(),
-            image_input_mask = image_input_mask,
-            video_input_mask = video_input_mask,
-            attention_mask = attention_mask,
-            labels = labels
-        )
 
-    return output_tensor, partial(loss_func, loss_mask, model=model)
+    output_tensor = model(
+        input_ids = tokens,
+        position_ids = position_ids,
+        vision_data = vision_data,
+        vision_grid_thw =  vision_grid,
+        video_start_index = image_input_mask.sum().cpu().item(),
+        image_input_mask = image_input_mask,
+        video_input_mask = video_input_mask,
+        attention_mask = attention_mask,
+        labels = labels
+    )
+
+    return output_tensor, partial(loss_func, loss_mask)
 
 def run_online_eval(model):
     """Run an evaluation benchmark during training."""
@@ -607,36 +527,34 @@ def datasets_provider(worker_config=None):
         batch_size=args.micro_batch_size,
         task_encoder=TaskEncoder(),
         worker_config=worker_config,
-        virtual_epoch_length=0,
-        max_samples_per_sequence=args.max_samples_per_sequence, # sequential shuffle in a tar
-        shuffle_buffer_size=args.shuffle_buffer_size, # shuffle in a sequential
+        virtual_epoch_length=1000,
+        max_samples_per_sequence=100,
+        shuffle_buffer_size=100,
         handler=print_error_handler,
-        repeat=True,
         image_decode="pil",
     )
-    val_datasets_without_source_datasets = None
-    if args.eval_iters > 0:
-        val_datasets = get_val_datasets(
-            dname,
-            batch_size=args.micro_batch_size,
-            # This is the total number over all workers
-            # limit=args.eval_iters * get_num_microbatches(),
-            task_encoder=TaskEncoder(),
+
+    val_datasets = get_val_datasets(
+        dname,
+        batch_size=args.micro_batch_size,
+        # This is the total number over all workers
+        # limit=args.eval_iters * get_num_microbatches(),
+        task_encoder=TaskEncoder(),
+        worker_config=worker_config,
+        handler=print_error_handler,
+        image_decode="pil",
+    )
+    val_datasets_without_source_datasets = [
+        # Limit the dataset to eval_iters * num_microbatches
+        LimitDataset(
+            # Repeat the inner dataset in case it's too short
+            RepeatDataset(val_ds, worker_config=worker_config),
+            length=args.eval_iters * get_num_microbatches(),
             worker_config=worker_config,
-            handler=print_error_handler,
-            image_decode="pil",
+            reset_after_epoch=True,
         )
-        val_datasets_without_source_datasets = [
-            # Limit the dataset to eval_iters * num_microbatches
-            LimitDataset(
-                # Repeat the inner dataset in case it's too short
-                RepeatDataset(val_ds, worker_config=worker_config),
-                length=args.eval_iters * get_num_microbatches(),
-                worker_config=worker_config,
-                reset_after_epoch=True,
-            )
-            for val_ds, _src_ds in val_datasets
-        ]
+        for val_ds, _src_ds in val_datasets
+    ]
 
     return train_dataset, val_datasets_without_source_datasets, None
 
@@ -663,9 +581,8 @@ def is_dataloader_rank(encoder_pipeline_model_parallel_size):
     # Run dataloader only on the first tensor parallel rank (will be broadcasted to others).
     is_first_rank = get_tensor_model_parallel_rank() == 0
 
-    # NOTE(lizhiyu): when pp_size > 2
-    # pp_size = get_pipeline_model_parallel_world_size()
-    # is_first_rank = is_first_rank and is_first_or_last_stage(pp_size, encoder_pipeline_model_parallel_size)
+    pp_size = get_pipeline_model_parallel_world_size()
+    is_first_rank = is_first_rank and is_first_or_last_stage(pp_size, encoder_pipeline_model_parallel_size)
 
     return is_first_rank
 
@@ -711,13 +628,10 @@ def train_valid_test_dataloaders_provider(train_val_test_num_samples):
                 except Exception as e:
                     print_rank_0("loading dataloader checkpoint failed. Skipping. " + str(e))
 
-    if valid_ds1 is not None:
-        valid_dataloader = [
-            EnergonDataloader(get_loader(valid_ds, worker_config=worker_config))
-            for valid_ds in valid_ds1
-        ]
-    else:
-        valid_dataloader = EnergonDataloader(None)
+    valid_dataloader = [
+        EnergonDataloader(get_loader(valid_ds, worker_config=worker_config))
+        for valid_ds in valid_ds1
+    ]
     test_dataloader = None # NOTE: no test
 
     return EnergonDataloader(train_dataloader), valid_dataloader, EnergonDataloader(test_dataloader)
@@ -758,17 +672,6 @@ def add_multimodal_extra_args(parser):
     group.add_argument("--temporal-patch-size", type=int, default=2)
     group.add_argument("--patch-size", type=int, default=14)
     group.add_argument("--max-padding-length", type=int, default=2048)
-    group.add_argument("--enable-variable-seq-lengths", action="store_true", default=False, help="Enable variable sequence lengths")
-    group.add_argument("--vision-root", type=str, default = None, help="The vision dirctory root path.")
-    group.add_argument("--max-samples-per-sequence", type=int, default=2**31-1, help="max sequencial seqence samples in a slice")
-    group.add_argument("--shuffle-buffer-size", type=int, default=0, help="the buffer size to shuffle the samples in a seqence")
-    # learning rate
-    group.add_argument("--vision-ration", type=float, default=0.1, help="the learning rate ration of vision(inlude merger) compared with llm")
-    group.add_argument("--image-max-pixels", type=int, default=768*768, help="the maximum pixels of a single image")
-    group.add_argument("--image-min-pixels", type=int, default=32*32, help="the minimum pixels of a single image")
-    group.add_argument("--vision-recompute-layer-steps", type=int, default=0, help="the recmoute layers for vision using uniform method. 0 is disable.")
-
-
 
     # just for checkpoint conversion
     group.add_argument(
diff --git a/tools/datasets/qwenvl/data/dataset_helpers.py b/tools/datasets/qwenvl/data/dataset_helpers.py
index 93930ac9..846fddee 100644
--- a/tools/datasets/qwenvl/data/dataset_helpers.py
+++ b/tools/datasets/qwenvl/data/dataset_helpers.py
@@ -14,9 +14,6 @@
 # limitations under the License.
 import dataclasses
 import json
-import logging
-import math
-import os
 import re
 import sys
 import traceback
@@ -26,10 +23,8 @@ from dataclasses import dataclass
 from typing import Any, Dict, List, Optional, Tuple, Union
 
 import numpy as np
-import PIL
 import torch
 
-from PIL import Image
 from torchvision import transforms as T
 
 from megatron.energon import Batch, DefaultTaskEncoder, VQASample
@@ -38,11 +33,6 @@ from megatron.training.global_vars import get_tokenizer
 from tools.datasets.qwenvl.data.energon.chatml import ChatMLSample
 from tools.datasets.qwenvl.data.image_processing import get_visual_transform
 
-dataset_logger = logging.getLogger(__name__)
-FIRST_MAX_PADDING_FLAG = True
-IGNORE_IDX = -100
-MAX_IMG_THRESHHOLD = 5000
-
 
 # Type for intermediate batch, after batch()
 @dataclass
@@ -98,9 +88,8 @@ def convert_to_qwen2vl_content(
     mm_idx = defaultdict(int)
     for matched in re.finditer(pattern, user_input):
         start, end = matched.span()
-        text = user_input[cur:start]
-        if text:
-            contents.append({"type": "text", "text": text})
+        if start > cur:
+            contents.append({"type": "text", "text": user_input[cur:start].strip()})
 
         contents.append(
             {
@@ -113,7 +102,7 @@ def convert_to_qwen2vl_content(
         mm_idx[matched.string[start:end][1:-1]] += 1
 
     if cur < len(user_input):
-        contents.append({"type": "text", "text": user_input[cur : len(user_input)]})
+        contents.append({"type": "text", "text": user_input[cur : len(user_input)].strip()})
 
     return contents
 
@@ -129,9 +118,6 @@ class TaskEncoder(
         super().__init__()
 
         self.args = get_args()
-        self.tp_size = self.args.tensor_model_parallel_size
-        self.cp_size = self.args.context_parallel_size
-        self.sequence_parallel = self.args.sequence_parallel
 
         self.tokenizer = get_tokenizer()
 
@@ -141,9 +127,6 @@ class TaskEncoder(
 
         self.seq_len = self.args.max_padding_length
 
-        self.vision_root = self.args.vision_root
-        assert self.vision_root is not None, "Please give the vision root."
-
     def encode_sample(self, sample: Union[VQASample, ChatMLSample]):
         if isinstance(sample, VQASample):
             is_llava_training = (
@@ -201,100 +184,17 @@ class TaskEncoder(
             thw_grids.append((grid_t, grid_h, grid_w))
         return flattened, np.array(thw_grids)
 
-    # copy from
-    def _preprocess_image(
-        self, image: PIL.Image, image_max_pixels: int = 768 * 768, image_min_pixels: int = 32 * 32
-    ) -> PIL.Image:
-        r"""
-        Pre-processes a single image.
-        """
-        if (image.width * image.height) > image_max_pixels:
-            resize_factor = math.sqrt(image_max_pixels / (image.width * image.height))
-            width, height = int(image.width * resize_factor), int(image.height * resize_factor)
-            image = image.resize((width, height))
-
-        if (image.width * image.height) < image_min_pixels:
-            resize_factor = math.sqrt(image_min_pixels / (image.width * image.height))
-            width, height = int(image.width * resize_factor), int(image.height * resize_factor)
-            image = image.resize((width, height))
-
-        if image.mode != "RGB":
-            image = image.convert("RGB")
-
-        if min(image.width, image.height) < 28:
-            width, height = max(image.width, 28), max(image.height, 28)
-            image = image.resize((width, height), resample=Image.Resampling.NEAREST)
-
-        if image.width / image.height > 200:
-            width, height = image.height * 180, image.height
-            image = image.resize((width, height), resample=Image.Resampling.NEAREST)
-
-        if image.height / image.width > 200:
-            width, height = image.width, image.width * 180
-            image = image.resize((width, height), resample=Image.Resampling.NEAREST)
-
-        return image
-
     def encode_chatml(self, sample: ChatMLSample):
-        # # TODO: modify get_visual_transform to add more augmentations
-        # imgs = [get_visual_transform(os.path.join(self.vision_root, img))[0] for img in sample.imgs]
-        # videos = [
-        #     [get_visual_transform(os.path.join(self.vision_root, frame))[0] for frame in video]
-        #     for video in sample.videos
-        # ]
-        # # NOTE: make n_frames even foreach video
-        # for i, video in enumerate(videos):
-        #     videos[i] = video[: len(video) // 2 * 2]
-
-        # # NOTE: flatten all images
-        # flattened_imgs, image_thw_grids = self._flatten_visual_inputs(imgs, is_image=True)
-        # flattened_videos, video_thw_grids = self._flatten_visual_inputs(videos, is_image=False)
-
-        #######################################################################################
-        # NOTE(lizhiyu): use the transformers processor
-        if sample.imgs is not None and len(sample.imgs) > 0:
-            imgs = []
-            for img in sample.imgs:
-                img_path = os.path.join(self.vision_root, img)
-                try:
-                    image = PIL.Image.open(img_path)
-                    image = self._preprocess_image(
-                        image=image,
-                        image_max_pixels=self.args.image_max_pixels,
-                        image_min_pixels=self.args.image_min_pixels,
-                    )
-                    imgs.append(image)
-                except Exception as e:
-                    raise ValueError(
-                        f"Failed to open image: {img_path}. Error: {e} of smaple[{sample.__key__}]"
-                    )
-                    # raise InternalWarning(
-                    #     f"Failed to open image: {img_path}. Error: {e} of smaple[{sample.__key__}]"
-                    # )
-            imgs_info = self.tokenizer.processor.image_processor(imgs, return_tensors="np")
-            flattened_imgs = imgs_info["pixel_values"]
-            image_thw_grids = imgs_info["image_grid_thw"]
-        else:
-            flattened_imgs = []
-            image_thw_grids = []
-
-        if sample.videos is not None and len(sample.videos) > 0:
-            videos = [
-                [PIL.Image.open(os.path.join(self.vision_root, frame)) for frame in video]
-                for video in sample.videos
-            ]
-            # NOTE: make n_frames even foreach video
-            for i, video in enumerate(videos):
-                videos[i] = video[: len(video) // 2 * 2]
-            videos_info = self.tokenizer.processor.image_processor(
-                images=None, videos=videos, return_tensors="pt"
-            )
-            flattened_videos = videos_info["pixel_values_videos"]
-            video_thw_grids = videos_info["video_grid_thw"]
-        else:
-            flattened_videos = []
-            video_thw_grids = []
-        #######################################################################################
+        # TODO: modify get_visual_transform to add more augmentations
+        imgs = [get_visual_transform(img)[0] for img in sample.imgs]
+        videos = [[get_visual_transform(frame)[0] for frame in video] for video in sample.videos]
+        # NOTE: make n_frames even foreach video
+        for i, video in enumerate(videos):
+            videos[i] = video[: len(video) // 2 * 2]
+
+        # NOTE: flatten all images
+        flattened_imgs, image_thw_grids = self._flatten_visual_inputs(imgs, is_image=True)
+        flattened_videos, video_thw_grids = self._flatten_visual_inputs(videos, is_image=False)
 
         # NOTE: generate qwen2vl conversations
         conversation = (
@@ -312,8 +212,6 @@ class TaskEncoder(
         content_key = "value" if "from" in conversation[0] else "content"
 
         # NOTE: assume the conversation format is: [System]? (User Assistant)+
-        # convert text message to standand format
-        #  add system as first item, refercence: https://huggingface.co/Qwen/Qwen2.5-VL-7B-Instruct/blob/main/chat_template.json
         converted_conversation = []
         if len(conversation) % 2 == 0:
             # Default Prompt
@@ -321,19 +219,11 @@ class TaskEncoder(
                 {"role": "system", "content": "You are a helpful assistant."}
             )
         else:
-            dataset_logger.warning(
-                f"The sample [{sample.__key__}] has odd number of conversation turns, and we will use the first turn as system prompt. BUT this may be wrong. Pelase check the sample."
-            )
             converted_conversation.append(
                 {"role": "system", "content": conversation[0][content_key]}
             )
-            ## NOTE(lizhiyu): Force set system Prompt: "You are a helpful assistant."
-            # converted_conversation.append(
-            #     {"role": "system", "content": "You are a helpful assistant."}
-            # )
             conversation = conversation[1:]
 
-        # add QA conversion as the left items
         EXPECTED_ROLE = ["human", "gpt"]
         for turn_idx, turn in enumerate(conversation):
             role = turn[role_key]
@@ -361,10 +251,9 @@ class TaskEncoder(
         system_prompt_prefix = len(
             self.tokenizer.apply_chat_template([conversation[0]], tokenize=True)
         )
-        assistant_generation_prefix = 3  # <im_start>assistant\n
-        # pad_token_id = self.tokenizer.pad_token_id
-        # NOTE(lizhiyu): Align to llama-f
-        pad_token_id = IGNORE_IDX
+        assistant_generation_prefix = 3
+        pad_token_id = self.tokenizer.pad_token_id
+
         target[:system_prompt_prefix] = pad_token_id
         offset = system_prompt_prefix
         for turn_idx, turn in enumerate(conversation[1:]):
@@ -381,13 +270,11 @@ class TaskEncoder(
             elif turn["role"] == "assistant":
                 target[offset : offset + assistant_generation_prefix] = pad_token_id
             offset += n_tokens
-        # current "target" don't pad vision token.
 
         # NOTE: expand image_pad & video_pad
-        merge_length = self.merge_size**2  # 2**2 = 4
+        merge_length = self.merge_size**2
         image_token_id, video_token_id = self.tokenizer.encode(["<|image_pad|>", "<|video_pad|>"])
 
-        # get the indices of the origin <|image_pad|> and <|video_pad|>
         image_token_indices = np.where(input_ids == image_token_id)[0]
         assert len(image_token_indices) == len(
             image_thw_grids
@@ -400,8 +287,6 @@ class TaskEncoder(
             video_thw_grids, dtype=np.int64
         )
 
-        # video_thw_grids shape: [n, 3]
-        # origin_seq_len + (all_image_token - 1) + (all_vision_token - 1)  ----> -1 because the pad token in origin text
         target_length = (
             input_ids.shape[0]
             - image_thw_grids.shape[0]
@@ -410,17 +295,13 @@ class TaskEncoder(
             + video_thw_grids.prod(axis=-1).sum() // merge_length
         )
         if target_length > self.seq_len:
-            # raise InternalWarning(f"Long sequence with length {target_length} found, dropped...")
-            dataset_logger.warning(
-                f"Samle id [{sample.__key__}] has long sequence with length {target_length}, cutoff to max [self.seq_len+64={self.seq_len}] in batch function..."
-            )
+            raise InternalWarning(f"Long sequence with length {target_length} found, dropped...")
         final_input_ids = np.zeros(target_length, dtype=input_ids.dtype)
         final_input_masks = final_input_ids.copy()
 
         image_idx, video_idx = 0, 0
         indices = np.sort(np.concatenate([image_token_indices, video_token_indices]))
 
-        # cur_x: origin text token idx,  cur_y: final text token idx
         cur_x, cur_y = 0, 0
         for idx in indices:
             token_id = input_ids[idx]
@@ -448,15 +329,11 @@ class TaskEncoder(
         target = np.roll(final_input_masks, shift=-1)
         target[-1] = pad_token_id
 
-        # NOTE(lizhiyu): we also check it in the train scripts.
         if (target == pad_token_id).all():
-            raise InternalWarning(
-                f"Sample id [{sample.__key__}] with all masked label, the data is invalid! Dropped!"
-            )
+            raise InternalWarning("Sample with all masked label, dropped.")
 
         image_input_mask = final_input_ids == self.tokenizer.image_token_id
         video_input_mask = final_input_ids == self.tokenizer.video_token_id
-
         # collect data
         return ImageTaskSample(
             __key__=sample.__key__,
@@ -530,14 +407,14 @@ class TaskEncoder(
         if len(input_ids) > self.seq_len:
             raise InternalWarning(f"Long sequence with length {len(input_ids)} found, dropped...")
 
-        target = np.array(input_ids[1:] + [IGNORE_IDX])
+        target = np.array(input_ids[1:] + [self.tokenizer.pad_token_id])
         if len(user_input_ids) >= len(input_ids):
             raise InternalWarning(f"Sample not supported, dropped...")
         # ensure user inputs is a prefix of full text
         if not (np.array(user_input_ids) == np.array(input_ids[: len(user_input_ids)])).all():
             raise InternalWarning(f"Sample not supported, dropped...")
         # mask input
-        target[: len(user_input_ids) - 1] = IGNORE_IDX
+        target[: len(user_input_ids) - 1] = self.tokenizer.pad_token_id
 
         img_token_id = self.tokenizer.image_token_id
         image_input_mask = np.array(input_ids) == img_token_id
@@ -559,12 +436,7 @@ class TaskEncoder(
 
     def batch(self, samples: List[ImageTaskSample]) -> VQATaskBatch:
         # Stack images to [num_tiles, c, h, w]. If there are no images (text-only), then use a dummy image.
-        # imgs = [img for s in samples for img in s.imgs]
-
-        ####################################################
-        # NOTE(lizhiyu): use the transformers processor
-        imgs = [s.imgs for s in samples if isinstance(s.imgs, np.ndarray) and s.imgs.size > 0]
-        ####################################################
+        imgs = [img for s in samples for img in s.imgs]
         if len(imgs) > 0:
             imgs = torch.cat([torch.from_numpy(img) for img in imgs])
         else:
@@ -581,14 +453,7 @@ class TaskEncoder(
             image_thw_grids = torch.empty([0, 3], dtype=torch.long)
 
         # Stack videos to [num_tiles, c, h, w]. If there are no videos (text-only), then use a dummy video.
-        # videos = [video for s in samples for video in s.videos]
-
-        ####################################################
-        # NOTE(lizhiyu): use the transformers processor
-        videos = [
-            s.videos for s in samples if isinstance(s.videos, np.ndarray) and s.videos.size > 0
-        ]
-        ####################################################
+        videos = [video for s in samples for video in s.videos]
         if len(videos) > 0:
             videos = torch.cat([torch.from_numpy(video) for video in videos])
         else:
@@ -612,30 +477,16 @@ class TaskEncoder(
         else:
             video_thw_grids = torch.empty([0, 3], dtype=torch.long)
 
-        global FIRST_MAX_PADDING_FLAG, MAX_IMG_THRESHHOLD
-        # NOTE(lizhiyu): Clear the cache only when the current image length is longer than the past maxisum length.
-        if image_thw_grids.prod(axis=-1).sum() // 4 > MAX_IMG_THRESHHOLD:
-            MAX_IMG_THRESHHOLD = image_thw_grids.prod(axis=-1).sum() // 4
-            FIRST_MAX_PADDING_FLAG = True
+        # If the user hasn't defined a target sequence length, then use the max along the sample lengths.
+        max_seq_len = self.seq_len
+        if not max_seq_len:
+            max_seq_len = max(len(s.text) for s in samples)
 
-        if not self.args.enable_variable_seq_lengths:
-            max_seq_len = self.seq_len
-        else:
-            # NOTE: this is a hack to get the max padding length for the first batch to avoid OOM because of cached memory in torch
-            if FIRST_MAX_PADDING_FLAG:
-                max_seq_len = self.seq_len
-                FIRST_MAX_PADDING_FLAG = False
-            else:
-                max_seq_len = max(len(s.text) for s in samples)
-                max_seq_len = min(max_seq_len, self.seq_len)
-        # NOTE: we need to make sure the max_seq_len is divisible by tp_size * cp_size
-        if self.cp_size > 1 or self.sequence_parallel:
-            max_seq_len = math.ceil(max_seq_len / (self.tp_size * self.cp_size)) * (
-                self.tp_size * self.cp_size
-            )
         text_mat = np.full((len(samples), max_seq_len), self.tokenizer.pad_token_id, dtype=np.int64)
         # +1 to accommodate shift to left by one later.
-        target_mat = np.full((len(samples), max_seq_len), IGNORE_IDX, dtype=np.int64)
+        target_mat = np.full(
+            (len(samples), max_seq_len), self.tokenizer.pad_token_id, dtype=np.int64
+        )
 
         image_input_masks = np.zeros_like(text_mat, dtype=bool)
         video_input_masks = np.zeros_like(text_mat, dtype=bool)
diff --git a/tools/datasets/qwenvl/data/energon/chatml.py b/tools/datasets/qwenvl/data/energon/chatml.py
index 7c71e91e..643968e4 100644
--- a/tools/datasets/qwenvl/data/energon/chatml.py
+++ b/tools/datasets/qwenvl/data/energon/chatml.py
@@ -9,7 +9,7 @@ from typing import List, Union
 
 import torch
 
-from webdataset.autodecode import Decoder
+from webdataset.autodecode import Decoder, imagehandler
 
 from megatron.energon.epathlib.epath import EPath
 from megatron.energon.flavors.base_dataset import Sample
@@ -20,12 +20,12 @@ from megatron.energon.flavors.webdataset import DefaultDecoderWebdatasetFactory
 class ChatMLSample(Sample):
     """multi-turn complex samples with images and videos"""
 
-    imgs: List[str]
-    videos: List[List[str]]
+    imgs: List[torch.Tensor]
+    videos: List[List[torch.Tensor]]
     conversation: str  # JSON string of GPT-format conversations
 
 
-class NestedImagesPathHandler:
+class NestedImagesHandler:
     def __init__(self, imagespec):
         """Create an image handler.
 
@@ -33,6 +33,7 @@ class NestedImagesPathHandler:
         """
         self.extensions = ["jpgs", "videos"]
         self.extensions_mapping = {"jpgs": "jpg", "videos": "jpg"}
+        self.image_handler = imagehandler(imagespec)
 
     def __call__(self, key, data):
         """Perform nested image decoding.
@@ -44,34 +45,24 @@ class NestedImagesPathHandler:
         if extension.lower() not in self.extensions:
             return None
         data = pickle.loads(data)
+        key = self.extensions_mapping[extension]
+        if extension.lower() == "jpgs":
+            data = [self.image_handler(key, d) for d in data]
+        else:
+            data = [[self.image_handler(key, d) for d in video] for video in data]
         return data
 
 
-# During training, data is automatically decoded to from default webdataset to 'ChatMLSample' when loaded using energon-dataloader,
-# and this is not done during preparation!!!
-# After decoding, the data is passed into the TaskEncoder for further processing.
 class ChatMLWebdataset(DefaultDecoderWebdatasetFactory[ChatMLSample]):
     __sample_type__ = ChatMLSample
 
-    def __init__(
-        self,
-        path: EPath,
-        *,
-        auto_decode: bool = True,
-        image_decode="torchrgb",
-        ignore_decoder_errors: bool = False,
-        av_decode="AVDecoder",
-        video_decode_audio: bool = False,
-        **kwargs,
-    ):
-        super().__init__(
-            path,
-            auto_decode=auto_decode,
-            image_decode=image_decode,
-            ignore_decoder_errors=ignore_decoder_errors,
-            av_decode=av_decode,
-            video_decode_audio=video_decode_audio,
-            **kwargs,
-        )
+    def __init__(self, path: EPath, *, auto_decode: bool = True, **kwargs):
+        super().__init__(path, auto_decode=auto_decode, **kwargs)
         if auto_decode:
-            self._decoder = Decoder([NestedImagesPathHandler(self.image_decode)])
+            self._decoder = Decoder(
+                [
+                    imagehandler(self.image_decode),
+                    NestedImagesHandler(self.image_decode),
+                    self._video_decoder,
+                ]
+            )
diff --git a/tools/datasets/qwenvl/data/image_processing.py b/tools/datasets/qwenvl/data/image_processing.py
index 822b3fc3..2b446613 100644
--- a/tools/datasets/qwenvl/data/image_processing.py
+++ b/tools/datasets/qwenvl/data/image_processing.py
@@ -11,24 +11,17 @@ from PIL import Image, ImageDraw
 from torchvision import transforms as T
 from torchvision.transforms import Compose, RandAugment, RandomResizedCrop, Resize, ToPILImage
 
-# config :https://huggingface.co/Qwen/Qwen2.5-VL-7B-Instruct/blob/main/preprocessor_config.json
 # Imagenet's mean and std.
-pixel_mean = [0.48145466, 0.4578275, 0.40821073]
-pixel_std = [0.26862954, 0.26130258, 0.27577711]
+pixel_mean = [123.675, 116.28, 103.53]
+pixel_std = [58.395, 57.12, 57.375]
 
 # Reshape for broadcasting.
 pixel_mean = torch.Tensor(pixel_mean).view(-1, 1, 1)
 pixel_std = torch.Tensor(pixel_std).view(-1, 1, 1)
 
 
-# https://github.com/QwenLM/Qwen2.5-VL/blob/477fd9d4317266508705366ce36cac5b68d70936/qwen-vl-utils/src/qwen_vl_utils/vision_process.py#L89C1-L95C40
-def convert_to_rgb(pil_image: Image.Image) -> Image.Image:
-    if pil_image.mode == 'RGBA':
-        white_background = Image.new("RGB", pil_image.size, (255, 255, 255))
-        white_background.paste(pil_image, mask=pil_image.split()[3])  # Use alpha channel as mask
-        return white_background
-    else:
-        return pil_image.convert("RGB")
+def convert_to_rgb(image):
+    return image.convert("RGB")
 
 
 def _transform_train_aug():
@@ -64,20 +57,24 @@ def _transform_test():
 
 def standardize_image(img):
     """Standardize image pixel values."""
-    return (T.ToTensor()(img) - pixel_mean) / pixel_std
+    return (torch.Tensor(np.array(img)).permute(2, 0, 1) - pixel_mean) / pixel_std
 
 
 def get_visual_transform(
-    img,  # Path
+    img,
     factor: int = 28,
-    min_pixels: int = 4 * 28 * 28,
-    max_pixels: int = 16384 * 28 * 28,
+    min_pixels: int = 56 * 56,
+    max_pixels: int = 14 * 14 * 4 * 1280,
     augment=False,
 ):
-    # TODO(lizhiyu): Need to limit the aspect ratio of the image.
-    # (reference https://github.com/QwenLM/Qwen2.5-VL/blob/477fd9d4317266508705366ce36cac5b68d70936/qwen-vl-utils/src/qwen_vl_utils/vision_process.py#L72)
-    img = Image.open(img)
-    img = convert_to_rgb(img)
+    img = np.array(img)
+
+    if augment:
+        visual_transform = _transform_train_aug()
+    else:
+        visual_transform = _transform_test()
+
+    img = visual_transform(img)
     w, h = img.size
     h_bar, w_bar = smart_resize(h, w, factor, min_pixels, max_pixels)
     img = img.resize((w_bar, h_bar))
@@ -93,8 +90,8 @@ def smart_resize(
     height: int,
     width: int,
     factor: int = 28,
-    min_pixels: int = 4 * 28 * 28,
-    max_pixels: int = 16384 * 28 * 28,
+    min_pixels: int = 56 * 56,
+    max_pixels: int = 14 * 14 * 4 * 1280,
 ):
     """Rescales the image so that the following conditions are met:
 
