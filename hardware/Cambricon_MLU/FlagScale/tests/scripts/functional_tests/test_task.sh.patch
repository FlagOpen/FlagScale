diff --git a/tests/scripts/functional_tests/test_task.sh b/tests/scripts/functional_tests/test_task.sh
index 0dc5ba35..0af5c2b7 100755
--- a/tests/scripts/functional_tests/test_task.sh
+++ b/tests/scripts/functional_tests/test_task.sh
@@ -1,5 +1,7 @@
 #!/bin/bash
 
+set -eo pipefail
+
 echo "The current directory is: $(pwd)"
 
 # Function to execute a command and handle failures
@@ -9,7 +11,7 @@ run_command() {
   local command_status=$?  # Capture the command's exit status
   local attempt_i=$2       # Capture the attempt number from the second argument
   local type_name=$3       # Capture the test type name from the third argument
-  local task_name=$4    # Capture the test task name from the fourth argument
+  local task_name=$4       # Capture the test task name from the fourth argument
   local case_name=$5       # Capture the test case name from the fifth argument
 
   # If the command status is not equal to 0, it indicates failure
@@ -37,7 +39,7 @@ test_task() {
   # Check if _cases is not an empty list
   if [ ${#_cases[@]} -eq 0 ]; then
     echo "No test cases found for task '$_task' with test type '$_type'. Exiting."
-    exit 0
+    exit 1
   fi
 
   # Loop through each test case, remove leading '-', and run the test
@@ -55,29 +57,33 @@ test_task() {
       wait_for_gpu
 
       # Remove previous results if they exist
-      result_path="tests/functional_tests/test_cases/${_type}/${_task}/results_test/${_case}"
-      if [ -d "$result_path" ]; then
-        rm -r "$result_path"
+      if [ "${_type}" = "train" ] || [ "${_type}" = "hetero_train" ] || [ "${_type}" = "inference" ] || [ "${_type}" = "rl" ] || [ "${_type}" = "serve" ]; then
+        result_path="tests/functional_tests/test_cases/${_type}/${_task}/results_test/${_case}"
+        if [ -d "$result_path" ]; then
+          rm -r "$result_path"
+        fi
       fi
 
       if [ "${_type}" = "train" ] || [ "${_type}" = "hetero_train" ]; then
         run_command "python run.py --config-path tests/functional_tests/test_cases/${_type}/${_task}/conf --config-name ${_case} action=test" $attempt_i $_task $_type $_case
-        run_command "pytest tests/functional_tests/test_utils/test_equal.py::test_train_equal --test_path=tests/functional_tests/test_cases --test_type=${_type} --test_task=${_task} --test_case=${_case}" $attempt_i $_task $_type $_case
+        run_command "pytest tests/functional_tests/test_utils/test_result.py::test_train_equal --test_path=tests/functional_tests/test_cases --test_type=${_type} --test_task=${_task} --test_case=${_case}" $attempt_i $_task $_type $_case
       fi
 
       if [ "${_type}" = "inference" ]; then
-        # TODO: rm when fix bug about "before start"
-        source /root/miniconda3/bin/activate flagscale-inference
         run_command "python run.py --config-path tests/functional_tests/test_cases/${_type}/${_task}/conf --config-name ${_case} action=test" $attempt_i $_task $_type $_case
-        run_command "pytest -s tests/functional_tests/test_utils/test_equal.py::test_inference_equal --test_path=tests/functional_tests/test_cases --test_type=${_type} --test_task=${_task} --test_case=${_case}" $attempt_i $_task $_type $_case
+        run_command "pytest -s tests/functional_tests/test_utils/test_result.py::test_inference_equal --test_path=tests/functional_tests/test_cases --test_type=${_type} --test_task=${_task} --test_case=${_case}" $attempt_i $_task $_type $_case
+      fi
+
+      if [ "${_type}" = "serve" ]; then
+         run_command "python run.py --config-path tests/functional_tests/test_cases/${_type}/${_task}/conf --config-name ${_case} action=test; sleep 1m" $attempt_i $_task $_type $_case
+         run_command "pytest -s tests/functional_tests/test_utils/test_result.py::test_serve_equal --test_path=tests/functional_tests/test_cases --test_type=${_type} --test_task=${_task} --test_case=${_case}" $attempt_i $_task $_type $_case
+         run_command "python run.py --config-path tests/functional_tests/test_cases/${_type}/${_task}/conf --config-name ${_case} action=stop" $attempt_i $_task $_type $_case
       fi
 
-      # todo: open this case
-      # if [ "${_type}" = "serve" ]; then
-      #   run_command "python run.py --config-path tests/functional_tests/test_cases/${_type}/${_task}/conf --config-name ${_case} action=run; sleep 1m" $attempt_i $_task $_type $_case
-      #   run_command "pytest tests/functional_tests/test_utils/test_call.py --test_path=tests/functional_tests/test_cases --test_type=${_type} --test_task=${_task} --test_case=${_case}" $attempt_i $_task $_type $_case
-      #   run_command "python run.py --config-path tests/functional_tests/test_cases/${_type}/${_task}/conf --config-name ${_case} action=stop" $attempt_i $_task $_type $_case
-      # fi
+      if [ "${_type}" = "rl" ]; then
+        run_command "python run.py --config-path tests/functional_tests/test_cases/${_type}/${_task}/conf --config-name ${_case} action=test" $attempt_i $_task $_type $_case
+        run_command "pytest -s tests/functional_tests/test_utils/test_result.py::test_rl_equal --test_path=tests/functional_tests/test_cases --test_type=${_type} --test_task=${_task} --test_case=${_case}" $attempt_i $_task $_type $_case
+      fi
 
       # Ensure that pytest check is completed before deleting the folder
       sleep 10s
@@ -107,5 +113,9 @@ if [ -z "$task" ]; then
   exit 1
 fi
 
+# Print final parameter values for confirmation
+echo "Type: $type"
+echo "Task: $task"
+
 # Run the tests based on the provided test type and test task
 test_task "$type" "$task"

