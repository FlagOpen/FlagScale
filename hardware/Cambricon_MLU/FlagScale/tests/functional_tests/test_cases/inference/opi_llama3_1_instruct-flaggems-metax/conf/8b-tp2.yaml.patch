diff --git a/tests/functional_tests/test_cases/inference/qwen3_flaggems/conf/tp2.yaml b/tests/functional_tests/test_cases/inference/opi_llama3_1_instruct-flaggems-metax/conf/8b-tp2.yaml
similarity index 64%
rename from tests/functional_tests/test_cases/inference/qwen3_flaggems/conf/tp2.yaml
rename to tests/functional_tests/test_cases/inference/opi_llama3_1_instruct-flaggems-metax/conf/8b-tp2.yaml
index 00716ec8..2eec0bd7 100644
--- a/tests/functional_tests/test_cases/inference/qwen3_flaggems/conf/tp2.yaml
+++ b/tests/functional_tests/test_cases/inference/opi_llama3_1_instruct-flaggems-metax/conf/8b-tp2.yaml
@@ -1,10 +1,10 @@
 defaults:
   - _self_
-  - inference: tp2
+  - inference: 8b-tp2
 
 experiment:
-  exp_name: qwen3_flaggems
-  exp_dir: tests/functional_tests/test_cases/inference/qwen3_flaggems/results_test/tp2
+  exp_name: opi_llama3_1_instruct-flaggems-metax
+  exp_dir: tests/functional_tests/test_cases/inference/opi_llama3_1_instruct-flaggems-metax/results_test/8b-tp2
   task:
     type: inference
     backend: vllm
@@ -13,13 +13,13 @@ experiment:
     hostfile: null
   cmds:
     before_start:
-      source /root/miniconda3/bin/activate flagscale-inference
+      source /opt/conda/bin/activate flagscale-inference
   envs:
     HYDRA_FULL_ERROR: 1
-    CUDA_VISIBLE_DEVICES: "0,1,2,3,4,5,6,7"
+    CUDA_VISIBLE_DEVICES: "0,1"
     CUDA_DEVICE_MAX_CONNECTIONS: 1
     CUBLAS_WORKSPACE_CONFIG: ":4096:8"
-    NCCL_ALGO: "Tree"
+    NCCL_ALGO: "Ring"
     NVTE_APPLY_QK_LAYER_SCALING: 0
     NVTE_ALLOW_NONDETERMINISTIC_ALGO: 0
     NVTE_FLASH_ATTN: 0
@@ -27,6 +27,7 @@ experiment:
     CUDNN_BENCHMARK: "false"
     CUDNN_DETERMINISTIC: "true"
     USE_FLAGGEMS: "true"
+    GEMS_VENDOR: "metax"
 
 action: run
 

