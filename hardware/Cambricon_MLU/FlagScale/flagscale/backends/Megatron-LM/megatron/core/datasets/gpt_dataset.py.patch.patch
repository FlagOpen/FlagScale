diff --git a/flagscale/backends/Megatron-LM/megatron/core/datasets/gpt_dataset.py.patch b/flagscale/backends/Megatron-LM/megatron/core/datasets/gpt_dataset.py.patch
new file mode 100644
index 00000000..782924c4
--- /dev/null
+++ b/flagscale/backends/Megatron-LM/megatron/core/datasets/gpt_dataset.py.patch
@@ -0,0 +1,22 @@
+diff --git a/megatron/core/datasets/gpt_dataset.py b/megatron/core/datasets/gpt_dataset.py
+index b80caaf6..933b8582 100644
+--- a/megatron/core/datasets/gpt_dataset.py
++++ b/megatron/core/datasets/gpt_dataset.py
+@@ -14,7 +14,7 @@ from megatron.core.datasets.indexed_dataset import IndexedDataset
+ from megatron.core.datasets.megatron_dataset import MegatronDataset
+ from megatron.core.datasets.megatron_tokenizer import MegatronTokenizer
+ from megatron.core.datasets.object_storage_utils import ObjectStorageConfig, is_object_storage_path
+-from megatron.core.datasets.utils import Split
++from megatron.core.datasets.utils import Split, is_built_on_zero_rank
+ from megatron.core.utils import log_single_rank
+ 
+ logger = logging.getLogger(__name__)
+@@ -355,7 +355,7 @@ class GPTDataset(MegatronDataset):
+ 
+         if not path_to_cache or (
+             not cache_hit
+-            and (not torch.distributed.is_initialized() or torch.distributed.get_rank() == 0)
++            and (not torch.distributed.is_initialized() or is_built_on_zero_rank())
+         ):
+             log_single_rank(
+                 logger,

