diff --git a/examples/qwen2_5_vl/conf/train/7b.yaml b/examples/qwen2_5_vl/conf/train/7b.yaml
index c9c12fc0..62b2e072 100644
--- a/examples/qwen2_5_vl/conf/train/7b.yaml
+++ b/examples/qwen2_5_vl/conf/train/7b.yaml
@@ -1,20 +1,22 @@
 system:
+  num_workers: 1
+  calculate_per_token_loss: true
   tensor_model_parallel_size: 2
   pipeline_model_parallel_size: 1
   context_parallel_size: 1
-  # decoder_first_pipeline_num_layers: 10
+  # decoder_first_pipeline_num_layers: 12
   disable_bias_linear: True
   use_flash_attn: True
   use_distributed_optimizer: True
   sequence_parallel: True
   tp_comm_overlap: False
-  overlap_grad_reduce: True
-  overlap_param_gather: True
+  overlap_grad_reduce: False # if has text-only must be false
+  overlap_param_gather: False # if has text-only must be false
   use_mcore_models: True
   transformer_impl: transformer_engine
-  # recompute_method: "uniform"
-  # recompute_granularity: "full"
-  # recompute_num_layers: 1
+  recompute_method: "uniform"
+  recompute_granularity: "full"
+  recompute_num_layers: 1
   use_te: True
   precision:
     bf16: True
@@ -29,13 +31,14 @@ system:
     log_num_zeros_in_grad: True
   checkpoint:
     save_interval: 1000
-    pretrained_checkpoint: xxx/Qwen2.5-VL-7B-Instruct_mc
+    pretrained_checkpoint: xxxx
     dataloader_save: ${experiment.exp_dir}/checkpoints/dataloader
     use_dist_ckpt: False
     ckpt_format: torch
     async_save: False
 
 model:
+  attention_backend: flash # don't use "auto(nvte_flash_attn)"
   disable_bias_linear: True
   add_qkv_bias: True
   num_layers: 28
@@ -43,20 +46,22 @@ model:
   ffn_hidden_size: 18944
   num_attention_heads: 28
   num_query_groups: 4
-  seq_length: 4096 # origin LLM 32768
-  max_padding_length: 4096 # real seq_length
+  seq_length: 2048
+  max_padding_length: 2048 # (cutoff_len)max 32768, change according the dataset
+  # especial for qwen2.5-vl
+  enable_variable_seq_lengths: True
   max_position_embeddings: 128000 # only useful for additional position embedding
   swiglu: True
   normalization: RMSNorm
   norm_epsilon: 1e-6
-  init_method_std: 0.014
+  init_method_std: 0.02
   attention_dropout: 0.0
   hidden_dropout: 0.0
   clip_grad: 1.0
-  train_iters: 20000
-  eval_iters: 0
+  train_iters: 62
+  eval_iters: 0 # no valid
   micro_batch_size: 1
-  global_batch_size: 320
+  global_batch_size: 16
   allow_missing_vision_projection_checkpoint: False
   apply_layernorm_1p: False
   group_query_attention: True
@@ -79,22 +84,24 @@ model:
   seed: 42
 
   optimizer:
-    weight_decay: 0.0
+    weight_decay: 0.1
     adam_beta1: 0.9
-    adam_beta2: 0.95
+    adam_beta2: 0.999
     lr_scheduler:
       lr: 1.0e-5
       min_lr: 1.0e-6
-      lr_warmup_fraction: .03
+      # lr_warmup_fraction: .03
+      lr_warmup_iters: 10
       lr_decay_style: cosine
 
 data:
-  data_path: xxx/data/llava-datasets/wds
+  data_path: xxxx
+  vision_root: xxxx
   dataloader_type: external
   split: 100,0,0
   tokenizer:
     tokenizer_type: Qwen2VLTokenizer
-    tokenizer_path: xxx/Qwen2.5-VL-7B-Instruct_mc
+    tokenizer_path: xxxx
     vocab_size: 152064 # 7b
     extra_vocab_size: 421
     make_vocab_size_divisible_by: 64

