diff --git a/megatron/core/optimizer/__init__.py b/megatron/core/optimizer/__init__.py
index 5ecc707ce..2ef1d245c 100644
--- a/megatron/core/optimizer/__init__.py
+++ b/megatron/core/optimizer/__init__.py
@@ -3,6 +3,7 @@ import logging
 import warnings
 from typing import Callable, Dict, List, Optional, Tuple
 
+from functools import wraps
 import torch
 from torch.optim import SGD as CPUSGD
 from torch.optim import AdamW as CPUAdam
@@ -53,6 +54,7 @@ def _get_param_groups(
     min_lr: float,
     decoupled_lr: Optional[float],
     decoupled_min_lr: Optional[float],
+    vision_ration,
 ) -> List[Dict]:
     """Create parameter groups for optimizer.
 
@@ -108,6 +110,8 @@ def _get_param_groups(
             else:
                 # Do not regularize biases and norm parameters.
                 no_wd = name.endswith(".bias") or len(param.shape) == 1
+                # NOTE(lizhiyu): hack for qwen2.5vl
+                # no_wd = name.endswith(".bias")
 
             if scale_lr_cond is not None:
                 scale_lr = scale_lr_cond(name, param)
@@ -131,7 +135,13 @@ def _get_param_groups(
             ):
                 is_decoupled_lr = True
 
-            key = (wd_mult, _lr_mult, is_expert_parallel, is_decoupled_lr)
+            is_vision_model_param = False
+            if "vision_model" in name:
+                is_vision_model_param = True
+            else:
+                is_vision_model_param = False
+
+            key = (wd_mult, _lr_mult, is_expert_parallel, is_decoupled_lr, is_vision_model_param)
             if key not in params_map:
                 params_map[key] = []
             if (
@@ -143,7 +153,7 @@ def _get_param_groups(
                 params_map[key].append(param)
 
     param_groups = []
-    for (wd_mult, _lr_mult, is_expert_parallel, is_decoupled_lr), params in params_map.items():
+    for (wd_mult, _lr_mult, is_expert_parallel, is_decoupled_lr, is_vision_model_param), params in params_map.items():
         assert len(params) > 0
         param_group = {
             'params': params,
@@ -151,6 +161,7 @@ def _get_param_groups(
             'lr_mult': _lr_mult,
             'is_expert_parallel': is_expert_parallel,
             'is_decoupled_lr': is_decoupled_lr,
+            'is_vision_model_param': is_vision_model_param,
         }
         # Ensure param_group has required keys for matching when loading optimizer state
         # See MegatronOptimizer._filter_and_reorder_param_groups.
@@ -163,6 +174,7 @@ def _get_param_groups(
         min_lr=min_lr,
         decoupled_lr=decoupled_lr,
         decoupled_min_lr=decoupled_min_lr,
+        vision_ration=vision_ration,
     )
 
     return param_groups
@@ -174,6 +186,7 @@ def _update_min_and_max_lr_in_param_groups(
     min_lr: float,
     decoupled_lr: Optional[float],
     decoupled_min_lr: Optional[float],
+    vision_ration = 0.1,
 ) -> List[Dict]:
     """
     Updates `max_lr` and `min_lr` values in each parameter group, and returns new list.
@@ -202,7 +215,7 @@ def _update_min_and_max_lr_in_param_groups(
             param_group['max_lr'] = decoupled_lr
             param_group['min_lr'] = decoupled_min_lr
         else:
-            param_group['max_lr'] = lr
+            param_group['max_lr'] = lr if not param_group['is_vision_model_param'] else lr * vision_ration # NOTE(lizhiyu): change the ration here
             param_group['min_lr'] = min_lr
     return param_groups
 
@@ -247,6 +260,7 @@ def _get_param_groups_and_buffers(
         min_lr=config.min_lr,
         decoupled_lr=config.decoupled_lr,
         decoupled_min_lr=config.decoupled_min_lr,
+        vision_ration=config.vision_ration, # NOTE(lizhiyu): The vision ration is used to scale the learning rate for vision model parameters. Added by FlagScale.
     )
     param_groups = list(filter(filter_fn, param_groups))
     buffers = {}
@@ -448,7 +462,55 @@ def _get_megatron_optimizer_based_on_param_groups(
 
     return optimizer
 
+def get_megatron_optimizer_wrapper(func):
+    @wraps(func)
+    def wrapper(*args, **kwargs):
+
+        chained_optimizer = func(*args, **kwargs)
 
+        if hasattr(chained_optimizer, 'chained_optimizers'):
+            if 'model_chunks' in kwargs:
+                model_chunks = kwargs['model_chunks']
+            elif len(args) > 1:
+                model_chunks = args[1]
+            else:
+                return chained_optimizer
+
+            for optimizer in chained_optimizer.chained_optimizers:
+                optimizer.is_moe_param = 'dense'
+
+            is_expert_parallel = False
+            for model_chunk in model_chunks:
+                ddp_config = model_chunk.ddp_config
+                if ddp_config.use_custom_fsdp:
+                    named_parameters = model_chunk.optimizer_named_parameters()
+                else:
+                    named_parameters = model_chunk.named_parameters()
+
+                for name, param in named_parameters:
+                    if (
+                        ddp_config.use_custom_fsdp
+                        and ddp_config.data_parallel_sharding_strategy == "optim_grads_params"
+                    ):
+                        param_shard = param
+                        param = param.orig_param
+
+                    if not param.requires_grad:
+                        continue
+
+                    is_expert_parallel = not getattr(param, 'allreduce', True)
+                    if is_expert_parallel:
+                        break
+                if is_expert_parallel:
+                    break
+
+            if is_expert_parallel:
+                chained_optimizer.chained_optimizers[-1].is_moe_param = 'moe'
+
+        return chained_optimizer
+    return wrapper
+
+@get_megatron_optimizer_wrapper
 def get_megatron_optimizer(
     config: OptimizerConfig,
     model_chunks: List[MegatronModule],
@@ -486,7 +548,9 @@ def get_megatron_optimizer(
     else:
         all_dense_model_chunks = [model_chunks]
         overlap_param_gather_with_optimizer_step_flags = [False]
-    model_parallel_rank = mpu.get_model_parallel_group().rank()
+    mp_group = mpu.get_model_parallel_group()
+    mp_group = [mp_group] if not isinstance(mp_group, list) else mp_group
+    model_parallel_rank = mp_group[0].rank()
 
     if (
         mpu.get_data_parallel_group(with_context_parallel=True, partial_data_parallel=False).size()
@@ -597,7 +661,12 @@ def get_megatron_optimizer(
         buffer_name='expert_parallel_buffers',
     )
     if len(moe_param_groups) > 0:
-        model_parallel_rank = mpu.get_expert_tensor_model_pipeline_parallel_group().rank()
+        expert_mp_group = mpu.get_expert_tensor_model_pipeline_parallel_group()
+        if not isinstance(expert_mp_group, list):
+            model_parallel_rank = mpu.get_expert_tensor_model_pipeline_parallel_group().rank()
+        else:
+            model_parallel_rank = expert_mp_group[0].rank()
+
         # Pass Gloo process groups into optimizer only if needed.
         if use_gloo_process_groups:
             data_parallel_group_gloo = mpu.get_expert_data_parallel_group_gloo(

