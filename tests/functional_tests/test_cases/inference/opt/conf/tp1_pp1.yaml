defaults:
  - _self_
  - inference: tp1_pp1

experiment:
  exp_name: tp1_pp1
  exp_dir: tests/functional_tests/test_cases/inference/opt/results_test/tp1_pp1
  task:
    type: inference
    backend: vllm
    entrypoint: ./flagscale/inference/inference_aquila.py
  runner:
    hostfile: null
  shell_cmds: null 
  ssh_port: null
  envs:
    CUDA_VISIBLE_DEVICES: 0
    CUDA_DEVICE_MAX_CONNECTIONS: 1

action: run

hydra:
  run:
    dir: ${experiment.exp_dir}/hydra 
