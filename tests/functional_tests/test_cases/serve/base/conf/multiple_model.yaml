defaults:
  - _self_
  - serve: multiple_model

experiment:
  exp_name: multiple_model
  exp_dir: tests/functional_tests/test_cases/serve/base/results_test/multiple_model
  task:
    type: serve
    entrypoint: null
  runner:
    hostfile: null
    deploy:
      port: 6701
      use_fs_serve: true
      enable_composition: true
      name: /generate
      request:
        args:
          - prompt
        types:
          - str
  envs:
    CUDA_DEVICE_MAX_CONNECTIONS: 1
  cmds:
    before_start: ulimit -n 65535 && export no_proxy="127.0.0.1,localhost" && source /root/miniconda3/bin/activate flagscale-inference

action: run

hydra:
  run:
    dir: ${experiment.exp_dir}/hydra
