defaults:
  - _self_
  - serve: config

experiment:
  exp_name: multiple_model
  exp_dir: outputs/${experiment.exp_name}
  task:
    type: serve
    entrypoint: null
  runner:
    hostfile: null
  envs:
    CUDA_VISIBLE_DEVICES: 0,1,2,3
    CUDA_DEVICE_MAX_CONNECTIONS: 1
  cmds:
    before_start: ulimit -n 65535 && source /root/miniconda3/bin/activate flagscale-inference

action: run
