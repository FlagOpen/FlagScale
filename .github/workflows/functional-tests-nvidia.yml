name: Functional Tests Nvidia

on:
  workflow_call:
    inputs:
      type:
        required: true
        type: string
      task:
        required: true
        type: string
      image:
        required: true
        type: string

jobs:
  functional-test:
    runs-on: [self-hosted, Linux, X64, nvidia-0, gpus-8]
    container:
      image: ${{ inputs.image }}
      ports:
        - 80
      volumes:
        - /home/flagscale_cicd/flask/static:/workspace/report
        - /home/flagscale_cicd/docker/docker_build/docker_data:/home/gitlab-runner/data
        - /home/flagscale_cicd/docker/docker_build/docker_tokenizers:/home/gitlab-runner/tokenizers
        - /home/flagscale_cicd/sccache:/root/.cache/sccache
      options: --gpus all --shm-size=500g --hostname flagscale_cicd --user root --ulimit nofile=65535:65535

    steps:
      - name: Checkout Code
        uses: actions/checkout@v4
        with:
          repository: ${{ github.event.pull_request.head.repo.full_name }}
          ref: ${{ github.event.pull_request.head.ref }}
          ssh-strict: true
          ssh-user: git
          persist-credentials: true
          clean: true
          sparse-checkout-cone-mode: true
          fetch-tags: false
          show-progress: true
          lfs: false
          submodules: false
          set-safe-directory: true
          retry-on-intr: fail=5,delay=180000

      - name: Run Functional Test
        timeout-minutes: 90  # Automatically terminate the current step after 90 minutes
        run: |
          git config --global --add safe.directory /__w/FlagScale/FlagScale

          TMP_DIR=$(mktemp -d)
          echo "Copying source to temporary directory: $TMP_DIR"
          cp -r /__w/FlagScale/FlagScale/. $TMP_DIR
          cd $TMP_DIR
          trap 'echo "Cleaning up temporary directory..."; rm -rf "$TMP_DIR"' EXIT

          if [ "${{ inputs.type }}" = "train" ] || [ "${{ inputs.type }}" = "hetero_train" ]; then
            PYTHONPATH=./:$PYTHONPATH pip install . --no-build-isolation --verbose --config-settings=device="gpu" --config-settings=backend="Megatron-LM"
            if [ "${{ inputs.task }}" = "llava_onevision" ]; then
              python tools/patch/unpatch.py --backend Megatron-Energon
              # PYTHONPATH=./:$PYTHONPATH pip install . --no-build-isolation --verbose --config-settings=device="gpu" --config-settings=backend="Megatron-Energon"
              cp -r third_party/Megatron-Energon/src/megatron/energon third_party/Megatron-LM/megatron
            fi
          elif [ "${{ inputs.type }}" = "inference" ] || [ "${{ inputs.type }}" = "serve" ]; then
            source /root/miniconda3/bin/activate flagscale-inference
            export SCCACHE_DIR=/root/.cache/sccache
            sccache --start-server
            sccache --show-stats

            #modify for support 0.5b_multiple_instance ci test because of ray version issue
            pip install ray==2.49.1
            pip install gymnasium
            pip install dm-tree

            echo "[INFO] Install VLLM and its dependencies ..."
            MAX_RETRIES=5
            DELAYS=(1 1.5 2 2.5 3)
            COMMANDS=(
              "pip install scikit-build scikit-build-core"
              "pip install git+https://github.com/FlagOpen/FlagGems.git@v3.0"
              "PYTHONPATH=./:$PYTHONPATH pip install . --config-settings=backend="vllm" --verbose --no-build-isolation"
            )

            # Initialize state array
            declare -A command_status
            declare -A retry_count
            declare -A delay_index

            # Traverse all commands and initialize variables
            for i in "${!COMMANDS[@]}"; do
              command_status[$i]=false
              retry_count[$i]=0
              delay_index[$i]=0
            done

            # Continuously check if there are any unsuccessful commands that need to be retried
            while true; do
              all_successful=true

              for i in "${!COMMANDS[@]}"; do
                cmd="${COMMANDS[$i]}"

                if ! ${command_status[$i]} && [ ${retry_count[$i]} -lt $MAX_RETRIES ]; then
                  echo "Attempt to execute command (${retry_count[$i]}/$MAX_RETRIES times): ${cmd}"

                  START_TIME=$(date +%s.%N)

                  if ! eval "$cmd"; then
                    echo "Command execution failed! We will retry in ${DELAYS[delay_index[$i]} minutes ..."
                    sleep $((${DELAYS[delay_index[$i]]} * 60))
                    ((retry_count[$i]++))
                    ((delay_index[$i]++))
                  else
                    command_status[$i]=true
                  fi
                  END_TIME=$(date +%s.%N)
                  all_successful=false
                else
                  echo "Skip commands that have been successfully/have reached the maximum retry count: ${cmd}"
                fi
              done
              if [ "$all_successful" = true ]; then
                echo "All commands have been executed"
                break
              fi
            done

            if [ "$all_successful" = false ]; then
              exit 1
            fi

            # computation time
            ELAPSED_SECONDS=$(awk "BEGIN {print $END_TIME - $START_TIME}")
            ELAPSED_MINUTES=$(awk "BEGIN {print int($ELAPSED_SECONDS / 60)}")
            REMAINING_SECONDS=$(awk "BEGIN {print $ELAPSED_SECONDS - $ELAPSED_MINUTES * 60}")

            # Format time display
            FORMATTED_START=$(date -d "@$START_TIME" "+%Y-%m-%d %H:%M:%S")
            FORMATTED_END=$(date -d "@$END_TIME" "+%Y-%m-%d %H:%M:%S")

            sccache --show-stats

            echo "================================"
            echo "Build time statistics"
            echo "================================"
            echo "Start time: ${FORMATTED_START}"
            echo "End time: ${FORMATTED_END}"
            echo "Total time taken: ${ELAPSED_MINUTES} minutes ${REMAINING_SECONDS} seconds"
            echo "================================"
            conda deactivate
          elif [ "${{ inputs.type }}" = "rl" ]; then
            python tools/patch/unpatch.py --backend verl
            cd third_party/verl
            pip install --no-deps -e .
            cd ../..
          else
            echo "Unknown backend type: ${{ inputs.type }}"
            exit 1
          fi
          tests/scripts/functional_tests/test_task.sh --type ${{ inputs.type }} --task ${{ inputs.task }}
          exit_code=$?
          echo "Exit code: $exit_code"
          exit $exit_cod
        shell: bash
