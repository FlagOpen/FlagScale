{
    "experiment": {
        "log_dir": null, 
        "hostfile": "",
        "ssh_port": 22
    },
    "launch": {
        "nnodes": 1,
        "nproc_per_node": 8,
        "node_rank": 0,
        "master_addr": "127.0.0.1",
        "master_port": 23461
    },
    "env_vars": {
        "XDNN_FC_GEMM_DTYPE": "float32",
        "CUDA_DEVICE_MAX_CONNECTIONS": "1",
        "NCCL_SOCKET_IFNAME": "bond0",
        "NCCL_IB_DISABLE": "0",
        "NCCL_IB_CUDA_SUPPORT": "1",
        "NCCL_IB_GID_INDEX": "0",
        "NCCL_IB_TIMEOUT": "23",
        "NCCL_IB_RETRY_CNT": "7",
        "OMP_NUM_THREADS": "4",
        "GLOO_SOCKET_IFNAME": "bond0",
        "NCCL_IB_HCA": "mlx5_2,mlx5_5"
    },
    "distributed": {
        "tensor_model_parallel_size": 8,
        "pipeline_model_parallel_size": 1
    },
    "training": {
        "micro_batch_size": 1,
        "global_batch_size": 64,
        "train_iters": 5,
        "dataloader_type": "cyclic",
        "log_interval": 1,
        "use_flash_attn": false,
        "disable_bias_linear": true,
        "sequence_parallel": true 
    },
    "validation": {
        "eval_iters": 0,
        "eval_interval": 2000
    },
    "network": {
        "num_layers": 2,
        "hidden_size": 6144,
        "num_attention_heads": 48,
        "group_query_attention": true,
        "num_query_groups": 48,
        "max_position_embeddings": 4096,
        "use_rotary_position_embeddings": true,
        "no_position_embedding": true,
        "make_vocab_size_divisible_by": 64,
        "layernorm_epsilon": 1e-05,
        "layernorm_init_weight": 0.3,
        "apply_layernorm_rms": true,
        "swiglu": true,
        "multiple_of": 4096,
        "hidden_dim_multiplier": 1.3,
        "distributed_backend": "nccl",
        "untie_embeddings_and_output_weights": true
    },
    "recompute":{
        "recompute_granularity": "full",
        "recompute_method": "uniform",
        "recompute_num_layers": 1 
    },
    "mixed_precision": {
        "bf16": false,
        "no_gradient_accumulation_fusion": true,
        "embedding_weights_in_fp32": true,
        "attention_softmax_in_fp32": true,
        "rotary_position_embeddings_in_fp32": true,
        "accumulate_allreduce_grads_in_fp32": true
    },
    "data": {
        "train_data_path": ["/XMLIR/cudakey/FlagScale/megatron/data/train_convo_samples.jsonl"
        ],
        "valid_data_path":  ["/XMLIR/cudakey/FlagScale/megatron/data/val_convo_samples.jsonl"
        ],
        "vocab_size": 100008,
        "vocab_file": "/XMLIR/cudakey/FlagScale/examples/aquila/tokenizer/vocab.json",
        "merge_file": "/XMLIR/cudakey/FlagScale/examples/aquila/tokenizer/merges.txt",
        "special_tokens_file": "/XMLIR/cudakey/FlagScale/examples/aquila/tokenizer/special_tokens.txt",
        "seq_length": 4096,
        "tokenizer_type": "AquilaTokenizer"
    },
    "regularization": {
        "attention_dropout": 0.0,
        "hidden_dropout": 0.0,
        "weight_decay": 0.1,
        "adam_beta1": 0.9,
        "adam_beta2": 0.95,
        "clip_grad": 1.0
    },
    "initialization": {
        "seed": 42,
        "init_method_std": 0.02
    },
    "learning_rate": {
        "lr": 9.65e-6,
        "min_lr": 0.0,
        "lr_decay_style": "cosine",
        "lr_warmup_fraction": 0.1
    },
    "checkpoint": {
        "save": "/XMLIR/cudakey/FlagScale/checkpoints/aquila_34b_exp4zhiyuan_save",
        "load": "/XMLIR/cudakey/FlagScale/checkpoints/aquila_34b_exp4zhiyuan",
        "save_interval": 200,
        "no_load_optim": true,
        "no_load_rng": true,
        "finetune": true
    },
    "logging": {
        "tensorboard_log_interval": 1
    }
}
