model_args:
  LLMActor:
    model: /models/Qwen2.5-7B-Instruct
    tensor_parallel_size: 1
    pipeline_parallel_size: 1
    gpu_memory_utilization: 0.9
    max_model_len: 32768
    max_model_len: 256
    trust_remote_code: True
    enable_chunked_prefill: True
    port: 4567

deploy:
  models:
    LLMActor:
      num_replicas: 8
      num_gpus: 1
