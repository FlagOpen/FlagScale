model_args:
  LLMActor:
    model: /models/Qwen2.5-7B-Instruct
    tensor-parallel-size: 1
    gpu-memory-utilization: 0.9
    max-model-len: 32768
    max-num-seqs: 256
    port: 4567
    action-args:
      - trust-remote-code
      - enable-chunked-prefill

deploy:
  models:
    LLMActor:
      num_replicas: 8
      num_gpus: 1
