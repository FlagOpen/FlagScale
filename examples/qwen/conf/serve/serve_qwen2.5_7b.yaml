model_args:
  vllm_model:
    model-tag: /models/Qwen2.5-7B-Instruct
    tensor-parallel-size: 1
    gpu-memory-utilization: 0.9
    max-model-len: 32768
    max-num-seqs: 256
    port: 4567
    action-args:
      - trust-remote-code
      - enable-chunked-prefill

deploy:
  command-line-mode: true
  keep-backend: true
  models:
    vllm_model:
      num_gpus: 1
