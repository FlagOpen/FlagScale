model_args:
  vllm_model:
    model_tag: /models/Qwen2.5-72B-Instruct
    tensor_parallel_size: 4
    gpu-memory-utilization: 0.9
    max-model-len: 32768
    max-num-seqs: 256
    port: 4567
    action_args:
      - trust_remote_code
      - enable_chunked_prefill

deploy:
  use_fs_serve: false
