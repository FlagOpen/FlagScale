defaults:
  - _self_
  - serve: serve_qwen2.5_7b

experiment:
  exp_name: qwen2.5_7b
  exp_dir: outputs/${experiment.exp_name}
  task:
    type: serve
    backend: vllm
    entrypoint: null
  runner:
    hostfile: /workspace/ip108/hostfile.txt
  ssh_port: 2222
  envs:
    CUDA_VISIBLE_DEVICES: 0
    CUDA_DEVICE_MAX_CONNECTIONS: 1

action: run

hydra:
  run:
    dir: ${experiment.exp_dir}/hydra
