llm:
  model: /models/Qwen2.5-7B-Instruct
  tensor_parallel_size: 4
  pipeline_parallel_size: 1
  gpu_memory_utilization: 0.9
  enforce_eager: true
  trust_remote_code: true
  disable_log_stats: false

generate:
  prompts: "Please introduce BAAI."

  sampling:
    top_k: 2048
    max_tokens: 1000
