defaults:
  - train: 7b
  - _self_

experiment:
  exp_name: train_qwen2_5_vl_7b
  exp_dir: ./${experiment.exp_name}
  task:
    type: train
    backend: megatron
    entrypoint: ./flagscale/train/train_qwen2_5_vl.py
  runner:
    backend: torchrun
    nnodes: 1
    nproc_per_node: 8
    hostfile: null
  cmds:  
    before_start: ulimit -n 1048576
  envs:
    CUDA_VISIBLE_DEVICES: 0,1,2,3,4,5,6,7
    CUDA_DEVICE_MAX_CONNECTIONS: 1
    NVTE_APPLY_QK_LAYER_SCALING: 0
    NVTE_ALLOW_NONDETERMINISTIC_ALGO: 0
    NCCL_P2P_LEVEL: NVL
    GLOO_SOCKET_IFNAME: eth0
    NCCL_SOCKET_IFNAME: eth0
    # NCCL_IB_DISABLE: 1
    # CUDA_LAUNCH_BLOCKING: 1
    # NCCL_IB_GID_INDEX: 7

action: run

hydra:
  run:
    dir: ${experiment.exp_dir}/hydra
