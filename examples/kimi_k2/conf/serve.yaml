defaults:
- _self_
- serve: 1t

experiment:
  exp_name: k2_1t
  exp_dir: outputs/${experiment.exp_name}
  task:
    type: serve
  runner:
    hostfile: examples/kimi_k2/conf/hostfile.txt
    nnodes: 2
    nproc_per_node: 8
    docker: flagos
    ssh_port: 22
  deploy:
    use_fs_serve: false
  envs:
    CUDA_VISIBLE_DEVICES: 0,1,2,3,4,5,6,7
    CUDA_DEVICE_MAX_CONNECTIONS: 1
    USE_FLAGGEMS: false
    RAY_CGRAPH_get_timeout: 60 # should be set when USE_FLAGGEMS=true, default is 10 from ray
  cmds:
    before_start: source /root/miniconda3/bin/activate flagscale-inference

action: run

hydra:
  run:
    dir: ${experiment.exp_dir}/hydra
