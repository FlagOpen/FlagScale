model_args:
  vllm_model:
    model-tag: /models/deepseek_r1 # path of weight of deepseek r1
    tensor-parallel-size: 8
    pipeline-parallel-size: 4
    gpu-memory-utilization: 0.9
    max-num-seqs: 256
    port: 9010 # port to serve
    action-args:
      - trust-remote-code
      - enable-chunked-prefill
deploy:
  command_line_mode: True
  use_native_serve: False
