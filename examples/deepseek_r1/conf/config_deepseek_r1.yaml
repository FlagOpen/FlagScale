defaults:
  - _self_
  - serve: deepseek_r1
experiment:
  exp_name: deepseek_r1
  exp_dir: outputs/${experiment.exp_name}
  task:
    type: serve
    inference_engine: vllm
  runner:
    hostfile: examples/deepseek_r1/conf/hostfile.txt
    docker: flagrelease_nv
    ssh_port: 22
  envs:
    CUDA_DEVICE_MAX_CONNECTIONS: 1
  cmds:
    before_start: source /root/miniconda3/bin/activate flagscale-inference && export GLOO_SOCKET_IFNAME=bond0 # replace "bond0" with your own network card
action: run
hydra:
  run:
    dir: ${experiment.exp_dir}/hydra
