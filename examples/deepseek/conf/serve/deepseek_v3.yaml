model_args:
  vllm_model:
    model_tag: /models/deepseek_v3/model # path of weight of deepseek v3
    tensor_parallel_size: 8
    pipeline-parallel-size: 2
    gpu-memory-utilization: 0.9
    max-num-seqs: 256
    port: 9010 # port to serve
    action_args:
      - trust_remote_code
      - enable_chunked_prefill

deploy:
  use_fs_serve: false
