engine:
  model: Wan-AI/Wan2.1-T2V-1.3B-Diffusers
  loader: diffusers
  pipeline:
    class: diffusers.WanPipeline
    from_pretrained:
      torch_dtype: bfloat16
  components:
    vae:
      class: diffusers.AutoencoderKLWan
      from_pretrained:
        subfolder: vae
        torch_dtype: float32
  device: cuda
  results_path: ${experiment.exp_dir}/results
  output_format: "video"
  transformations:
    TaylorSeerTransformation:
      order: 1
      warmup_steps: 4
      skip_interval_steps: 3
      targets:
        # Matches the taylorseer official implementation at https://github.com/Shenyi-Z/TaylorSeer/tree/main/TaylorSeer-Wan2.1/wan/taylorseer/forwards
        by_name: ["*blocks.*.attn1", "*blocks.*.attn2", "*blocks.*.ffn"]
      use_timestep_delta: true
    TimestepTrackerTransformation:
      {}
    StateScopeTransformation:
      {}
  state_scopes:
    ["cond", "uncond"]

generate:
  prompts: ["A cat walks on the grass, realistic"]
  negative_prompt: "Bright tones, overexposed, static, blurred details, subtitles, style, works, paintings, images, static, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, misshapen limbs, fused fingers, still picture, messy background, three legs, many people in the background, walking backwards"
  height: 480
  width: 832
  num_frames: 81
  guidance_scale: 5.0
  generator:
    seed: 42
    device: cuda