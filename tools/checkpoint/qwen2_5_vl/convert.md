### ğŸ“ Reference

Mainly based on official [Pai-Megatron-Patch](https://github.com/alibaba/Pai-Megatron-Patch/tree/main/examples/qwen2_5_vl),with necessary modifications for integration into the current training framework.

### ä¸‹è½½æ¨¡å‹
```bash
mkdir -p /mnt/qwen2.5-vl-ckpts
cd /mnt/qwen2.5-vl-ckpts
git clone https://huggingface.co/Qwen/Qwen2.5-VL-7B-Instruct
cd Qwen2.5-VL-7B-Instruct
git lfs pull
```

### Megatron-Coreæ¨¡å‹æ ¼å¼è½¬æ¢
è¿è¡Œ`hf2mcore_qwen2.5_vl_convertor.sh`è„šæœ¬ï¼Œéœ€è¦ä¼ å…¥çš„å‚æ•°åˆ—è¡¨å¦‚ä¸‹
```bash
MODEL_SIZE=$1                 # æ¨¡å‹å‚æ•°ï¼š2B/7B/72B
SOURCE_CKPT_PATH=$2           # æºllm checkpointè·¯å¾„
TARGET_CKPT_PATH=$3           # ç›®æ ‡checkpointè·¯å¾„
TP=$4                         # è§£ç å™¨æ¨¡å‹å¹¶è¡Œåº¦
PP=$5                         # è§£ç å™¨æµæ°´å¹¶è¡Œåº¦
mg2hf=$6                      # æ˜¯å¦æ‰§è¡Œmcore2hfè½¬æ¢
PR=$7                         # ç²¾åº¦è®¾ç½®ï¼Œfp16/bf16/fp32
HF_CKPT_PATH=$8               # HFçš„CKPTçš„è·¯å¾„ã€å¯é€‰ï¼Œmg2hf=trueæ—¶å¿…é¡»æä¾›ã€‘
```
ä¾‹å¦‚ï¼Œä½¿ç”¨ä¸‹è¿°è„šæœ¬å°†checkpointè½¬æ¢åˆ°MCore-Denseå¹¶æ£€æŸ¥è¾“å‡º

```bash
cd /workspace/FlagScale/tools/checkpointing/qwen2_5_vl
bash hf2mcore_qwen2.5_vl_convertor.sh \
7B \
/mnt/qwen2.5-vl-ckpts/Qwen2.5-VL-7B-Instruct \
/mnt/qwen2.5-vl-ckpts/Qwen2.5-VL-7B-Instruct-tp2pp2 \
2  \
2  \
false \
bf16
```

å½“æ‚¨éœ€è¦å°†è®­ç»ƒå¥½çš„checkpointè½¬æ¢å›huggingfaceæ ¼å¼ç”¨äºæ¨ç†æ—¶ï¼Œæ‰§è¡Œ

```bash
cd /workspace/FlagScale/tools/checkpointing/qwen2_5_vl
bash hf2mcore_qwen2.5_vl_convertor.sh \
7B \
/mnt/qwen2.5-vl-ckpts/Qwen2.5-VL-7B-Instruct-tp2pp2 \
/mnt/qwen2.5-vl-ckpts/Qwen2.5-VL-7B-Instruct-tp2pp2-back \
2  \
2  \
true \
bf16 \
/mnt/qwen2.5-vl-ckpts/Qwen2.5-VL-7B-Instruct
```

æ­¤å¤–ï¼Œå¦‚æœæ‚¨éœ€è¦åœ¨ç»§ç»­é¢„è®­ç»ƒæ—¶è®¾ç½®ä¸å¯¹ç§°PPåˆ‡åˆ†æ¥è¾¾åˆ°æœ€ä½³ååï¼Œåœ¨å‡†å¤‡æ¨¡å‹æƒé‡æ—¶ï¼Œä¸è®­ç»ƒé˜¶æ®µç±»ä¼¼ï¼Œæ‚¨éœ€è¦æ‰‹åŠ¨è°ƒæ•´ä»¥ä¸‹ç¯å¢ƒå˜é‡æ¥ç¡®å®šç¬¬ä¸€ä¸ªpipeline stageä¸­çš„Transformerå±‚æ•°
```bash
export MP_PP0_LAYERS=16
```
